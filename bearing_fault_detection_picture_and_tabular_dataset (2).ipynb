{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install natsort"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GH6uYngGtEo8",
        "outputId": "7fa4d083-0f47-4305-ec33-5438e0951d5d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: natsort in /usr/local/lib/python3.10/dist-packages (8.4.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install scipy==1.12.0\n",
        "!pip install scikit-plot==0.3.7"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wl8N640lOo__",
        "outputId": "ecedf6e2-2d7a-44aa-827e-316cedf10f6b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: scipy==1.12.0 in /usr/local/lib/python3.10/dist-packages (1.12.0)\n",
            "Requirement already satisfied: numpy<1.29.0,>=1.22.4 in /usr/local/lib/python3.10/dist-packages (from scipy==1.12.0) (1.26.4)\n",
            "Requirement already satisfied: scikit-plot==0.3.7 in /usr/local/lib/python3.10/dist-packages (0.3.7)\n",
            "Requirement already satisfied: matplotlib>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from scikit-plot==0.3.7) (3.8.0)\n",
            "Requirement already satisfied: scikit-learn>=0.18 in /usr/local/lib/python3.10/dist-packages (from scikit-plot==0.3.7) (1.5.2)\n",
            "Requirement already satisfied: scipy>=0.9 in /usr/local/lib/python3.10/dist-packages (from scikit-plot==0.3.7) (1.12.0)\n",
            "Requirement already satisfied: joblib>=0.10 in /usr/local/lib/python3.10/dist-packages (from scikit-plot==0.3.7) (1.4.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=1.4.0->scikit-plot==0.3.7) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=1.4.0->scikit-plot==0.3.7) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=1.4.0->scikit-plot==0.3.7) (4.55.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=1.4.0->scikit-plot==0.3.7) (1.4.7)\n",
            "Requirement already satisfied: numpy<2,>=1.21 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=1.4.0->scikit-plot==0.3.7) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=1.4.0->scikit-plot==0.3.7) (24.2)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=1.4.0->scikit-plot==0.3.7) (11.0.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=1.4.0->scikit-plot==0.3.7) (3.2.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=1.4.0->scikit-plot==0.3.7) (2.8.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.18->scikit-plot==0.3.7) (3.5.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib>=1.4.0->scikit-plot==0.3.7) (1.16.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KX7l2rWG0S5R",
        "outputId": "45fd9367-1623-4004-c7b9-52e7452848c1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-3CkQXV3Deks"
      },
      "outputs": [],
      "source": [
        "import joblib\n",
        "import sys\n",
        "from natsort import natsorted\n",
        "sys.modules['sklearn.externals.joblib'] = joblib\n",
        "import pandas as pd\n",
        "from sklearn.metrics import f1_score\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import zipfile\n",
        "import os\n",
        "import cv2\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn import preprocessing\n",
        "########################################################\n",
        "from tensorflow.keras.layers import MultiHeadAttention\n",
        "from tensorflow.keras.models import Model, load_model\n",
        "from tensorflow.keras.layers import Dense, Dropout, Activation, Reshape, Flatten, \\\n",
        "    LSTM, Dense, Dropout, Embedding, Bidirectional, GRU,Flatten, Activation,\\\n",
        "    BatchNormalization, UpSampling2D,Conv1D, Input, Concatenate,multiply, add,\\\n",
        "    AveragePooling1D, UpSampling1D,Lambda, Average, Dense, Flatten,GRU,Attention\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint,\\\n",
        "    ReduceLROnPlateau, LearningRateScheduler, CSVLogger\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.layers import Lambda, Conv2D, Activation,\\\n",
        "    BatchNormalization, UpSampling2D, multiply, add\n",
        "from tensorflow.keras import backend as K\n",
        "from tensorflow.keras import initializers, regularizers, optimizers\n",
        "#from keras.engine.topology import Layer\n",
        "from tensorflow.keras.layers import Layer, InputSpec\n",
        "from tensorflow.keras import constraints\n",
        "from tensorflow.keras.layers import BatchNormalization\n",
        "import tensorflow as tf\n",
        "########################################################\n",
        "from random import  randint\n",
        "from random import choice\n",
        "from random import uniform\n",
        "from random import  randint\n",
        "from random import choice\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from random import uniform\n",
        "import scipy"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir defect_bearing_saved_pictures"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eYx-0qZ10q_s",
        "outputId": "9e696982-4cbd-4067-ee0e-12976a81a48c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mkdir: cannot create directory ‘defect_bearing_saved_pictures’: File exists\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cp /content/drive/MyDrive/defect_bearing_saved_pictures/defect_bearing_saved_pictures1.zip /content/sample_data"
      ],
      "metadata": {
        "id": "Mx2RfCdz0P4f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "with zipfile.ZipFile(\"/content/sample_data/defect_bearing_saved_pictures1.zip\",\"r\") as zip_ref:\n",
        "    zip_ref.extractall(\"/content/defect_bearing_saved_pictures\")\n"
      ],
      "metadata": {
        "id": "d-ffkdfe0wmH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "class reading_data_picture():\n",
        "    def __init__(self, path, img_size_x, img_size_y):\n",
        "        self.path = path\n",
        "        self.img_size_x = img_size_x\n",
        "        self.img_size_y = img_size_y\n",
        "    def get_data(self):\n",
        "        data = []\n",
        "        picture_list = os.listdir(self.path)\n",
        "        picture_list = natsorted(picture_list)\n",
        "        for x in picture_list:\n",
        "            picture_path = os.path.join(self.path,x)\n",
        "            out = cv2.imread(picture_path)\n",
        "            out_resize = cv2.resize(out,(self.img_size_x, self.img_size_y))\n",
        "            data.append(out_resize)\n",
        "        data_out = np.array(data) /255\n",
        "        return data_out"
      ],
      "metadata": {
        "id": "B4ZbISsc2EkZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_total  = reading_data_picture('/content/defect_bearing_saved_pictures', 224, 224)\n",
        "data_picture = data_total.get_data()"
      ],
      "metadata": {
        "id": "KCc-lB9z2bCb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class reading_data():\n",
        "  def __init__(self, path):\n",
        "    self.path = path\n",
        "  def reading_data(self):\n",
        "    df = pd.read_csv(self.path)\n",
        "    print(df.isnull().sum())\n",
        "    if df.isnull().sum().all():\n",
        "      df = df.fillna(df.iloc[0])\n",
        "    else:\n",
        "      df = df\n",
        "    return df\n",
        "  def visualization_pearson(self):\n",
        "    df = pd.read_csv(self.path)\n",
        "    corr =df.corr()\n",
        "    return sns.heatmap(\n",
        "        corr, annot=True,\n",
        "        vmin=-1, vmax=1, center=0,\n",
        "        cmap=sns.diverging_palette(5, 220, n=50),\n",
        "        square=True)\n",
        "  def visualization_kendas(self):\n",
        "    df = pd.read_csv(self.path)\n",
        "    corr =df.corr(method='kendall')\n",
        "    return sns.heatmap(\n",
        "        corr, annot=True,\n",
        "        center=0,\n",
        "        cmap=sns.diverging_palette(5, 220, n=50),\n",
        "        square=True)\n",
        "  def visualization_spearman(self):\n",
        "    df = pd.read_csv(self.path)\n",
        "    corr =df.corr(method='spearman')\n",
        "    return sns.heatmap(\n",
        "        corr, annot=True,\n",
        "        center=0,\n",
        "        cmap=sns.diverging_palette(5, 220, n=50),\n",
        "        square=True)\n",
        "\n"
      ],
      "metadata": {
        "id": "bTQyLpaZ2ygg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = reading_data(\"/content/bearing-failure.csv\")\n",
        "df = data.reading_data()\n",
        "target = df['Label']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XkHoBkyO2kxa",
        "outputId": "7818245d-7744-4313-8b67-6f9d8ce45e62"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "COMP_NAME                  0\n",
            "Vel, Rms (RMS)             0\n",
            "Acc, Rms (RMS)             0\n",
            "Crest (RMS)                0\n",
            "Kurt (RMS)                 0\n",
            "Vel, Peak (RMS)            0\n",
            "Vel, Peak to peak (RMS)    0\n",
            "MP_LOC                     0\n",
            "Label                      0\n",
            "dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import OneHotEncoder\n",
        "encoder = OneHotEncoder(sparse_output=False)\n",
        "traina , trainb, target_train, testa , testb, target_test =   data_picture[0:1100], np.array(df.iloc[0:1100]).reshape(1100,9,1), encoder.fit_transform(np.array(target.iloc[0:1100]).reshape(-1,1)), data_picture[1100:],np.array(df.iloc[1100:]).reshape(284, 9, 1) , encoder.fit_transform(np.array(target.iloc[1100:]).reshape(-1,1))\n",
        "print(\"The training size for tabular is: \",trainb.shape)\n",
        "print(\"The training size for picture data is: \",traina.shape)\n",
        "print(\"The training target size for picture is: \",target_train.shape)\n",
        "print(\"The testing size for tabular is: \",testb.shape )\n",
        "print(\"The testing size for picture data is: \",testa.shape )\n",
        "print(\"The testing target size for picture is: \",target_test.shape )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tonxhodrKvHz",
        "outputId": "2864a29e-c093-4bf4-deef-2aadec26a39b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The training size for tabular is:  (1100, 9, 1)\n",
            "The training size for picture data is:  (1100, 224, 224, 3)\n",
            "The training target size for picture is:  (1100, 3)\n",
            "The testing size for tabular is:  (284, 9, 1)\n",
            "The testing size for picture data is:  (284, 224, 224, 3)\n",
            "The testing target size for picture is:  (284, 3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "MH_layer = MultiHeadAttention(num_heads=8, key_dim=4)\n",
        "target = tf.keras.Input(shape=[200, 4])\n",
        "source = tf.keras.Input(shape=[200, 4])"
      ],
      "metadata": {
        "id": "7zkS1O7qWE21"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "MH_layer_EEG = MultiHeadAttention(num_heads=8, key_dim=4)\n",
        "target_EEG = tf.keras.Input(shape=[21,21,2])\n",
        "source_EEG = tf.keras.Input(shape=[25,25,1])"
      ],
      "metadata": {
        "id": "G341peAfXIdX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def perf_measure(y_actual, y_hat):\n",
        "    TP = 0\n",
        "    FP = 0\n",
        "    TN = 0\n",
        "    FN = 0\n",
        "\n",
        "    for i in range(len(y_hat)):\n",
        "        if y_actual[i]==y_hat[i]==1:\n",
        "           TP += 1\n",
        "        if y_hat[i]==1 and y_actual[i]!=y_hat[i]:\n",
        "           FP += 1\n",
        "        if y_actual[i]==y_hat[i]==0:\n",
        "           TN += 1\n",
        "        if y_hat[i]==0 and y_actual[i]!=y_hat[i]:\n",
        "           FN += 1\n",
        "\n",
        "    return(TP, FP, TN, FN)"
      ],
      "metadata": {
        "id": "rQY3j8NqdBKN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#time in hospital\n",
        "class Net:\n",
        "    def __init__(self):\n",
        "        self.ep = randint(100, 200)               # epoch\n",
        "        self.u1 = randint(800, 1682)\n",
        "        self.d1 = choice([0.15, 0.20, 0.25])         #  dropout 1\n",
        "        self.a1 = choice([('relu'),('elu'),('tanh'),('leaky_relu'),('selu'), ('swish')])                      # activation 1\n",
        "        self.a2 = choice([('relu'),('elu'),('tanh'),('leaky_relu'),('selu'), ('swish')])                      # activation 2\n",
        "        self.a3 = choice([('relu'),('elu'),('tanh'),('leaky_relu'),('selu'), ('swish')])                      # activation 3\n",
        "        self.a4 = 'softmax'                                                                                   # activation\n",
        "        self.pretrain =  choice([(tf.keras.applications.MobileNetV2(input_shape=(224,224,3),include_top=False,weights='imagenet')),\n",
        "                                 (tf.keras.applications.ResNet50V2(input_shape=(224,224,3),include_top=False,weights='imagenet')),\n",
        "                                 (tf.keras.applications.VGG19(input_shape=(224,224,3),include_top=False,weights='imagenet')),\n",
        "                                 (tf.keras.applications.Xception(input_shape=(224,224,3),include_top=False,weights='imagenet')),\n",
        "                                 (tf.keras.applications.DenseNet201(input_shape=(224,224,3),include_top=False,weights='imagenet'))])\n",
        "\n",
        "\n",
        "\n",
        "        self.lf = choice([('categorical_crossentropy'), ('categorical_focal_crossentropy')])  # loss function\n",
        "        self.op = choice([('adam'),('Nadam'),('adamax')])                  # optimization\n",
        "        self.ac = 0                        # accuracy\n",
        "        self.losss=np.inf\n",
        "\n",
        "    def init_params(self):\n",
        "        params = {'epochs': self.ep,\n",
        "                  'activation1': self.a1,\n",
        "                  'activation2': self.a2,\n",
        "                  'activation3': self.a3,\n",
        "                  'activation4': self.a4,\n",
        "                  'pretrain': self.pretrain,\n",
        "                  'dropout1': self.d1,\n",
        "                  'unit1': self.u1,\n",
        "                  'loss': self.lf,\n",
        "                  'optimizer': self.op,\n",
        "                  'accuracy': self.ac,\n",
        "                  'losss': self.losss}\n",
        "        return params\n",
        "\n",
        "\n",
        "def init_net(p):\n",
        "    return [Net() for _ in range(p)]\n",
        "\n",
        "\n",
        "def fitness(n, n_c, x, y, b, x_test, y_test):\n",
        "    a=[]\n",
        "    l=[]\n",
        "    f=[]\n",
        "    for cnt, i in enumerate(n):\n",
        "        p = i.init_params()\n",
        "        ep = p['epochs']\n",
        "        d1 = p['dropout1']\n",
        "        u1 = p['unit1']\n",
        "        a1 = p['activation1']\n",
        "        a2 = p['activation2']\n",
        "        a3 = p['activation3']\n",
        "        a4 = p['activation4']\n",
        "        pr = p['pretrain']\n",
        "        lf = p['loss']\n",
        "        op = p['optimizer']\n",
        "        losss=p['losss']\n",
        "        ac=p['accuracy']\n",
        "        print('optimizer',op)\n",
        "        print('activation1',a1)\n",
        "        print('activation2',a2)\n",
        "        print('dropout1',d1)\n",
        "        print('number of neuron in unit1',u1)\n",
        "        print('Loss function is :',lf )\n",
        "        print(\"Pretraining model is: \", pr)\n",
        "        print(\"The number of epochs is :\", ep)\n",
        "\n",
        "\n",
        "        try:                                # Parameter name    # Suggested value\n",
        "            m = net_model(ep=ep,            # epoch number             12\n",
        "                          a1=a1,            # activation 1           'relu'\n",
        "                          a2=a2,            # activation 2           'relu'\n",
        "                          a3=a3,            # activation 3           'relu'\n",
        "                          a4=a4,            # activation 4           'softmax'\n",
        "                          d1=d1,            # dropout 1                0.2\n",
        "                          u1=u1,            # neuron number            256\n",
        "                          op=op,            # optimizer               'adadelta'\n",
        "                          lf=lf,            # loss function           'categorical crossentropy'\n",
        "                          n_c=n_c,          # number of channel\n",
        "                          x=x,              # train data\n",
        "                          y=y,              # train label\n",
        "                          b=b,              # bias value\n",
        "                          x_test=x_test,    # test data\n",
        "                          y_test=y_test,\n",
        "                          pr = pr)    # test label\n",
        "\n",
        "            # # Current best: 88%\n",
        "            s = m.evaluate(x=[testb,testa], y=target_test, verbose=2)\n",
        "\n",
        "\n",
        "            Y_pred = m.predict([testb,testa])\n",
        "            y_pred = np.argmax(Y_pred, axis=1)\n",
        "            target_test1 = np.argmax(target_test, axis=1)\n",
        "            print('Confusion Matrix')\n",
        "            (TP, FP, TN, FN) = perf_measure(target_test1, y_pred)\n",
        "            print(\"The value for TP is: \", TP)\n",
        "            print(\"The value for TN is: \", TN)\n",
        "            print(\"The value for FP is: \", FP)\n",
        "            print(\"The value for FN is: \", FN)\n",
        "            print(\"The value for F1score is: \", f1_score(target_test1, y_pred, average='micro'))\n",
        "            print(confusion_matrix(target_test1, y_pred))\n",
        "            print('Classification Report')\n",
        "            plt.show()\n",
        "            i.ac = s[1]\n",
        "            i.losss=s[0]\n",
        "\n",
        "            print('Accuracy: {}'.format(i.ac * 100))\n",
        "            print('loss: {}'.format(i.losss ))\n",
        "            y_true0 = K.constant(target_test, dtype=tf.float32)\n",
        "            y_pred0 = K.constant(Y_pred, dtype=tf.float32)\n",
        "            print(\"***********************************\")\n",
        "            if i.losss>1:\n",
        "              f1 = 0.1*i.ac + (0.9/i.losss)\n",
        "            else:\n",
        "              f1= 0.9*i.ac +(0.1/i.losss)\n",
        "\n",
        "            f.append(f1)\n",
        "            a.append(i.ac * 100)\n",
        "            l.append(i.losss)\n",
        "            print(\"The value for the fitness function is :\", f)\n",
        "            print(\"The accuracy  is :\", f)\n",
        "            print(\"The loss  is :\", f)\n",
        "        except Exception as e:\n",
        "            print(e)\n",
        "    best_ac=np.argmax(a)\n",
        "    best_l=np.argmin(l)\n",
        "    best_f=np.argmax(f)\n",
        "    if best_f:\n",
        "      n=n[best_f]\n",
        "    elif best_ac==best_l:\n",
        "      n=n[best_ac]\n",
        "    else:\n",
        "      n=n[best_l]\n",
        "    print(best_ac,best_l)\n",
        "    return [n]\n",
        "\n",
        "\n",
        "early_stopping_cb =  tf.keras.callbacks.EarlyStopping(patience=50,restore_best_weights=True)\n",
        "lr_scheduler1 = tf.keras.callbacks.ReduceLROnPlateau(factor=0.333, patience=50)\n",
        "checkpoint_cb = tf.keras.callbacks.ModelCheckpoint(\"Fused_bearing_fault.keras\",save_best_only=True)\n",
        "def net_model(ep, a1, a2, a3, a4, d1, u1, op, lf, n_c, x, y, b, x_test, y_test, pr):\n",
        "    input_A = Input((9, 1))\n",
        "    Conv1_out =  Conv1D(filters=1, strides =1,kernel_size=5, activation=a1,padding='same')(input_A)\n",
        "    GRU_out = GRU(1, return_sequences=True, dropout=0.2, kernel_initializer=initializers.glorot_normal(seed=777),\n",
        "                  bias_initializer='zeros')(input_A)\n",
        "    Attention_out = Attention()([input_A, Conv1_out])\n",
        "    Attention_out1 = Attention()([input_A, GRU_out])\n",
        "    Concatenation = Concatenate()([Attention_out,Attention_out1])\n",
        "    Concatenation = BatchNormalization()(Concatenation)\n",
        "    Conv1_out1 =  Conv1D(filters=1, strides =1,kernel_size=5,activation=a1 ,padding='same')(Concatenation)\n",
        "    GRU_out1 = GRU(1, return_sequences=True, dropout=0.2, kernel_initializer=initializers.glorot_normal(seed=777),\n",
        "                   bias_initializer='zeros')(Concatenation)\n",
        "    Concatenation2 = Concatenate()([Conv1_out1,GRU_out1])\n",
        "    Concatenation2 = BatchNormalization()(Concatenation2)\n",
        "    output_tensor, weights = MH_layer(Concatenation2, Concatenation,\n",
        "                                   return_attention_scores=True)\n",
        "    input_B = Input((224,224, 3))\n",
        "    base_model = pr\n",
        "    x = base_model(input_B, training=False)\n",
        "    output_tensor_EEG = tf.keras.layers.GlobalAveragePooling2D()(x)\n",
        "    flatten_Moca = Flatten()(output_tensor)\n",
        "    flatten_EEG = Flatten()(output_tensor_EEG)\n",
        "    Concatenation_total = Concatenate()([flatten_Moca,flatten_EEG])\n",
        "    out1 = Dense(u1, activation=a3, kernel_initializer=initializers.glorot_normal(seed=777), bias_initializer='zeros')(Concatenation_total)\n",
        "    dropout1 = Dropout(d1)(out1)\n",
        "    out = Dense(3, activation='softmax', kernel_initializer=initializers.glorot_normal(seed=777), bias_initializer='zeros')(dropout1)\n",
        "    model_Transfomer_Attention_fused = Model(inputs=[input_A,input_B], outputs=[out])\n",
        "\n",
        "\n",
        "    #plot_model(model, to_file='model_plot.png', show_shapes=True, show_layer_names=True)\n",
        "    model_Transfomer_Attention_fused.compile(optimizer=op, loss=lf, metrics=[\"accuracy\"])\n",
        "    print(\"Training has started\")\n",
        "    history = model_Transfomer_Attention_fused.fit([trainb,traina], target_train, batch_size=b, epochs=ep, verbose = 2, validation_split=0.2,\n",
        "                                                   callbacks=[early_stopping_cb,lr_scheduler1,checkpoint_cb])\n",
        "    pd.DataFrame(history.history).plot(figsize=(8, 5))\n",
        "    plt.grid(True)\n",
        "    plt.gca().set_ylim(0, 1) # set the vertical range to [0-1]\n",
        "    plt.show()\n",
        "    print(\"Training has finished\")\n",
        "    #model_Transfomer_Attention_fused.save(\"CNN_GA_Readmission.h5\")\n",
        "    return model_Transfomer_Attention_fused\n",
        "#model with skip\n",
        "\n",
        "def selection(n):\n",
        "    n = sorted(n, key=lambda j: j.ac, reverse=True)\n",
        "    #n = sorted(n, key=lambda j: j.losss, reverse=True)\n",
        "    n = n[:2]\n",
        "    return n\n",
        "\n",
        "\n",
        "def crossover(n):\n",
        "    offspring = []\n",
        "    p1 = choice(n)\n",
        "    p2 = choice(n)\n",
        "    c1 = Net()\n",
        "    c2 = Net()\n",
        "    c1.ep = int(p2.ep) + 2\n",
        "    c2.ep = int(p1.ep) + 2\n",
        "    offspring.append(c1)\n",
        "    offspring.append(c2)\n",
        "    n.extend(offspring)\n",
        "    return n\n",
        "def crossover1(n):\n",
        "    offspring = []\n",
        "    p3 = choice(n)\n",
        "    p4 = choice(n)\n",
        "    c3 = Net()\n",
        "    c4 = Net()\n",
        "    c3.u1 = int(p4.u1) + 10\n",
        "    c4.u1 = int(p3.u1) + 10\n",
        "    offspring.append(c3)\n",
        "    offspring.append(c4)\n",
        "    n.extend(offspring)\n",
        "    return n\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def mutate(n):\n",
        "    for i in n:\n",
        "        if uniform(0, 1) <= 0.10991:\n",
        "            i.ep += randint(100, 200)\n",
        "            i.u1 += randint(10, 100)\n",
        "    return n\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "5C_4C_zTOtg-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "P = 2 # Population\n",
        "G = 50 # Generation\n",
        "B = 16 # Batch size\n",
        "C = 3  # Class number\n",
        "T = 0.964  # Threshold\n",
        "N = init_net(p=P)  # Create population number networks\n",
        "accuracy_list = []\n",
        "for g in range(G):\n",
        "    print('Generation {}'.format(g + 1))\n",
        "    N = fitness(n=N,\n",
        "                n_c=C,\n",
        "                x=[trainb,traina],\n",
        "                y=target_train,\n",
        "                b=B,\n",
        "                x_test=[testb,testa],\n",
        "                y_test=target_test)\n",
        "    N = selection(n=N)\n",
        "    N = crossover(n=N)\n",
        "    N = crossover1(n=N)\n",
        "    N = mutate(n=N)\n",
        "    for q in N:\n",
        "        accuracy_list.append(q.ac * 100)\n",
        "        if q.ac > T:\n",
        "            print('Threshold satisfied')\n",
        "            print(q.init_params())\n",
        "            print('Best accuracy: {}%'.format(q.ac * 100))\n",
        "            exit(code=0)\n",
        "    print(\"The best accuracy so far {}%\".format(max(accuracy_list)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h0-pLcnHRr6M",
        "outputId": "5d523e0a-5cdd-43c8-a989-95e3070491ca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generation 1\n",
            "optimizer adam\n",
            "activation1 leaky_relu\n",
            "activation2 selu\n",
            "dropout1 0.2\n",
            "number of neuron in unit1 1523\n",
            "Loss function is : categorical_focal_crossentropy\n",
            "Pretraining model is:  <Functional name=densenet201, built=True>\n",
            "The number of epochs is : 943\n",
            "Training has started\n",
            "Epoch 1/943\n",
            "28/28 - 195s - 7s/step - accuracy: 0.3705 - loss: 0.4777 - val_accuracy: 0.3364 - val_loss: 2.6741 - learning_rate: 0.0010\n",
            "Epoch 2/943\n",
            "28/28 - 47s - 2s/step - accuracy: 0.4034 - loss: 0.1597 - val_accuracy: 0.4455 - val_loss: 0.1837 - learning_rate: 0.0010\n",
            "Epoch 3/943\n",
            "28/28 - 32s - 1s/step - accuracy: 0.4193 - loss: 0.1315 - val_accuracy: 0.4455 - val_loss: 0.2215 - learning_rate: 0.0010\n",
            "Epoch 4/943\n",
            "28/28 - 45s - 2s/step - accuracy: 0.4455 - loss: 0.1197 - val_accuracy: 0.2227 - val_loss: 0.1512 - learning_rate: 0.0010\n",
            "Epoch 5/943\n",
            "28/28 - 36s - 1s/step - accuracy: 0.4795 - loss: 0.1151 - val_accuracy: 0.4455 - val_loss: 0.1521 - learning_rate: 0.0010\n",
            "Epoch 6/943\n",
            "28/28 - 44s - 2s/step - accuracy: 0.5216 - loss: 0.1041 - val_accuracy: 0.5909 - val_loss: 0.1075 - learning_rate: 0.0010\n",
            "Epoch 7/943\n",
            "28/28 - 43s - 2s/step - accuracy: 0.5784 - loss: 0.0996 - val_accuracy: 0.5045 - val_loss: 0.1013 - learning_rate: 0.0010\n",
            "Epoch 8/943\n",
            "28/28 - 44s - 2s/step - accuracy: 0.6250 - loss: 0.0838 - val_accuracy: 0.6273 - val_loss: 0.0936 - learning_rate: 0.0010\n",
            "Epoch 9/943\n",
            "28/28 - 36s - 1s/step - accuracy: 0.6864 - loss: 0.0657 - val_accuracy: 0.6273 - val_loss: 0.0820 - learning_rate: 0.0010\n",
            "Epoch 10/943\n",
            "28/28 - 37s - 1s/step - accuracy: 0.6864 - loss: 0.0593 - val_accuracy: 0.5591 - val_loss: 0.1395 - learning_rate: 0.0010\n",
            "Epoch 11/943\n",
            "28/28 - 42s - 2s/step - accuracy: 0.6795 - loss: 0.0676 - val_accuracy: 0.5182 - val_loss: 0.1666 - learning_rate: 0.0010\n",
            "Epoch 12/943\n",
            "28/28 - 41s - 1s/step - accuracy: 0.7420 - loss: 0.0459 - val_accuracy: 0.4182 - val_loss: 0.9692 - learning_rate: 0.0010\n",
            "Epoch 13/943\n",
            "28/28 - 40s - 1s/step - accuracy: 0.7830 - loss: 0.0370 - val_accuracy: 0.4455 - val_loss: 2.2346 - learning_rate: 0.0010\n",
            "Epoch 14/943\n",
            "28/28 - 42s - 2s/step - accuracy: 0.7614 - loss: 0.0463 - val_accuracy: 0.3364 - val_loss: 2.6741 - learning_rate: 0.0010\n",
            "Epoch 15/943\n",
            "28/28 - 40s - 1s/step - accuracy: 0.7830 - loss: 0.0484 - val_accuracy: 0.4455 - val_loss: 2.2346 - learning_rate: 0.0010\n",
            "Epoch 16/943\n",
            "28/28 - 42s - 2s/step - accuracy: 0.8045 - loss: 0.0380 - val_accuracy: 0.2182 - val_loss: 3.1504 - learning_rate: 0.0010\n",
            "Epoch 17/943\n",
            "28/28 - 32s - 1s/step - accuracy: 0.8489 - loss: 0.0258 - val_accuracy: 0.4455 - val_loss: 2.2346 - learning_rate: 0.0010\n",
            "Epoch 18/943\n",
            "28/28 - 40s - 1s/step - accuracy: 0.8773 - loss: 0.0231 - val_accuracy: 0.3455 - val_loss: 2.1386 - learning_rate: 0.0010\n",
            "Epoch 19/943\n",
            "28/28 - 41s - 1s/step - accuracy: 0.8545 - loss: 0.0269 - val_accuracy: 0.4591 - val_loss: 0.4036 - learning_rate: 0.0010\n",
            "Epoch 20/943\n",
            "28/28 - 39s - 1s/step - accuracy: 0.8477 - loss: 0.0307 - val_accuracy: 0.8364 - val_loss: 0.0373 - learning_rate: 0.0010\n",
            "Epoch 21/943\n",
            "28/28 - 34s - 1s/step - accuracy: 0.8568 - loss: 0.0236 - val_accuracy: 0.3409 - val_loss: 2.6232 - learning_rate: 0.0010\n",
            "Epoch 22/943\n",
            "28/28 - 41s - 1s/step - accuracy: 0.8875 - loss: 0.0199 - val_accuracy: 0.4455 - val_loss: 2.2346 - learning_rate: 0.0010\n",
            "Epoch 23/943\n",
            "28/28 - 48s - 2s/step - accuracy: 0.8818 - loss: 0.0210 - val_accuracy: 0.7773 - val_loss: 0.0366 - learning_rate: 0.0010\n",
            "Epoch 24/943\n",
            "28/28 - 38s - 1s/step - accuracy: 0.9091 - loss: 0.0156 - val_accuracy: 0.9136 - val_loss: 0.0166 - learning_rate: 0.0010\n",
            "Epoch 25/943\n",
            "28/28 - 35s - 1s/step - accuracy: 0.9068 - loss: 0.0169 - val_accuracy: 0.8136 - val_loss: 0.0463 - learning_rate: 0.0010\n",
            "Epoch 26/943\n",
            "28/28 - 41s - 1s/step - accuracy: 0.9080 - loss: 0.0174 - val_accuracy: 0.8455 - val_loss: 0.0274 - learning_rate: 0.0010\n",
            "Epoch 27/943\n",
            "28/28 - 64s - 2s/step - accuracy: 0.9045 - loss: 0.0163 - val_accuracy: 0.9318 - val_loss: 0.0143 - learning_rate: 0.0010\n",
            "Epoch 28/943\n",
            "28/28 - 31s - 1s/step - accuracy: 0.9216 - loss: 0.0147 - val_accuracy: 0.9318 - val_loss: 0.0151 - learning_rate: 0.0010\n",
            "Epoch 29/943\n",
            "28/28 - 41s - 1s/step - accuracy: 0.9057 - loss: 0.0180 - val_accuracy: 0.4318 - val_loss: 1.2691 - learning_rate: 0.0010\n",
            "Epoch 30/943\n",
            "28/28 - 41s - 1s/step - accuracy: 0.9318 - loss: 0.0129 - val_accuracy: 0.3364 - val_loss: 2.6741 - learning_rate: 0.0010\n",
            "Epoch 31/943\n",
            "28/28 - 41s - 1s/step - accuracy: 0.9216 - loss: 0.0143 - val_accuracy: 0.4500 - val_loss: 2.1731 - learning_rate: 0.0010\n",
            "Epoch 32/943\n",
            "28/28 - 42s - 1s/step - accuracy: 0.9102 - loss: 0.0181 - val_accuracy: 0.4227 - val_loss: 1.1461 - learning_rate: 0.0010\n",
            "Epoch 33/943\n",
            "28/28 - 40s - 1s/step - accuracy: 0.9295 - loss: 0.0150 - val_accuracy: 0.7909 - val_loss: 0.1067 - learning_rate: 0.0010\n",
            "Epoch 34/943\n",
            "28/28 - 41s - 1s/step - accuracy: 0.9432 - loss: 0.0125 - val_accuracy: 0.8091 - val_loss: 0.0913 - learning_rate: 0.0010\n",
            "Epoch 35/943\n",
            "28/28 - 31s - 1s/step - accuracy: 0.9443 - loss: 0.0096 - val_accuracy: 0.8818 - val_loss: 0.0283 - learning_rate: 0.0010\n",
            "Epoch 36/943\n",
            "28/28 - 42s - 1s/step - accuracy: 0.9443 - loss: 0.0123 - val_accuracy: 0.7682 - val_loss: 0.0814 - learning_rate: 0.0010\n",
            "Epoch 37/943\n",
            "28/28 - 32s - 1s/step - accuracy: 0.9545 - loss: 0.0096 - val_accuracy: 0.9091 - val_loss: 0.0228 - learning_rate: 0.0010\n",
            "Epoch 38/943\n",
            "28/28 - 41s - 1s/step - accuracy: 0.9511 - loss: 0.0099 - val_accuracy: 0.9227 - val_loss: 0.0146 - learning_rate: 0.0010\n",
            "Epoch 39/943\n",
            "28/28 - 40s - 1s/step - accuracy: 0.9477 - loss: 0.0099 - val_accuracy: 0.7955 - val_loss: 0.0494 - learning_rate: 0.0010\n",
            "Epoch 40/943\n",
            "28/28 - 41s - 1s/step - accuracy: 0.9670 - loss: 0.0079 - val_accuracy: 0.8773 - val_loss: 0.0199 - learning_rate: 0.0010\n",
            "Epoch 41/943\n",
            "28/28 - 47s - 2s/step - accuracy: 0.9455 - loss: 0.0098 - val_accuracy: 0.9409 - val_loss: 0.0123 - learning_rate: 0.0010\n",
            "Epoch 42/943\n",
            "28/28 - 36s - 1s/step - accuracy: 0.9602 - loss: 0.0086 - val_accuracy: 0.8409 - val_loss: 0.0448 - learning_rate: 0.0010\n",
            "Epoch 43/943\n",
            "28/28 - 40s - 1s/step - accuracy: 0.9659 - loss: 0.0078 - val_accuracy: 0.8227 - val_loss: 0.0466 - learning_rate: 0.0010\n",
            "Epoch 44/943\n",
            "28/28 - 32s - 1s/step - accuracy: 0.9477 - loss: 0.0102 - val_accuracy: 0.8773 - val_loss: 0.0227 - learning_rate: 0.0010\n",
            "Epoch 45/943\n",
            "28/28 - 31s - 1s/step - accuracy: 0.9580 - loss: 0.0088 - val_accuracy: 0.9227 - val_loss: 0.0144 - learning_rate: 0.0010\n",
            "Epoch 46/943\n",
            "28/28 - 41s - 1s/step - accuracy: 0.9670 - loss: 0.0057 - val_accuracy: 0.9227 - val_loss: 0.0147 - learning_rate: 0.0010\n",
            "Epoch 47/943\n",
            "28/28 - 42s - 1s/step - accuracy: 0.9750 - loss: 0.0047 - val_accuracy: 0.9455 - val_loss: 0.0153 - learning_rate: 0.0010\n",
            "Epoch 48/943\n",
            "28/28 - 41s - 1s/step - accuracy: 0.9659 - loss: 0.0083 - val_accuracy: 0.9182 - val_loss: 0.0165 - learning_rate: 0.0010\n",
            "Epoch 49/943\n",
            "28/28 - 41s - 1s/step - accuracy: 0.9545 - loss: 0.0067 - val_accuracy: 0.9045 - val_loss: 0.0425 - learning_rate: 0.0010\n",
            "Epoch 50/943\n",
            "28/28 - 40s - 1s/step - accuracy: 0.9432 - loss: 0.0123 - val_accuracy: 0.9455 - val_loss: 0.0162 - learning_rate: 0.0010\n",
            "Epoch 51/943\n",
            "28/28 - 49s - 2s/step - accuracy: 0.9580 - loss: 0.0086 - val_accuracy: 0.9500 - val_loss: 0.0090 - learning_rate: 0.0010\n",
            "Epoch 52/943\n",
            "28/28 - 40s - 1s/step - accuracy: 0.9705 - loss: 0.0065 - val_accuracy: 0.9545 - val_loss: 0.0087 - learning_rate: 0.0010\n",
            "Epoch 53/943\n",
            "28/28 - 33s - 1s/step - accuracy: 0.9659 - loss: 0.0058 - val_accuracy: 0.9182 - val_loss: 0.0193 - learning_rate: 0.0010\n",
            "Epoch 54/943\n",
            "28/28 - 42s - 1s/step - accuracy: 0.9580 - loss: 0.0084 - val_accuracy: 0.8182 - val_loss: 0.1047 - learning_rate: 0.0010\n",
            "Epoch 55/943\n",
            "28/28 - 40s - 1s/step - accuracy: 0.9705 - loss: 0.0051 - val_accuracy: 0.9409 - val_loss: 0.0139 - learning_rate: 0.0010\n",
            "Epoch 56/943\n",
            "28/28 - 31s - 1s/step - accuracy: 0.9727 - loss: 0.0068 - val_accuracy: 0.8409 - val_loss: 0.0509 - learning_rate: 0.0010\n",
            "Epoch 57/943\n",
            "28/28 - 42s - 2s/step - accuracy: 0.9591 - loss: 0.0068 - val_accuracy: 0.8318 - val_loss: 0.0523 - learning_rate: 0.0010\n",
            "Epoch 58/943\n",
            "28/28 - 40s - 1s/step - accuracy: 0.9682 - loss: 0.0055 - val_accuracy: 0.8227 - val_loss: 0.0553 - learning_rate: 0.0010\n",
            "Epoch 59/943\n",
            "28/28 - 41s - 1s/step - accuracy: 0.9670 - loss: 0.0062 - val_accuracy: 0.9364 - val_loss: 0.0159 - learning_rate: 0.0010\n",
            "Epoch 60/943\n",
            "28/28 - 41s - 1s/step - accuracy: 0.9761 - loss: 0.0051 - val_accuracy: 0.9045 - val_loss: 0.0266 - learning_rate: 0.0010\n",
            "Epoch 61/943\n",
            "28/28 - 42s - 1s/step - accuracy: 0.9648 - loss: 0.0103 - val_accuracy: 0.7818 - val_loss: 0.0776 - learning_rate: 0.0010\n",
            "Epoch 62/943\n",
            "28/28 - 31s - 1s/step - accuracy: 0.9750 - loss: 0.0056 - val_accuracy: 0.8818 - val_loss: 0.0241 - learning_rate: 0.0010\n",
            "Epoch 63/943\n",
            "28/28 - 32s - 1s/step - accuracy: 0.9602 - loss: 0.0078 - val_accuracy: 0.9273 - val_loss: 0.0142 - learning_rate: 0.0010\n",
            "Epoch 64/943\n",
            "28/28 - 42s - 1s/step - accuracy: 0.9761 - loss: 0.0050 - val_accuracy: 0.9364 - val_loss: 0.0155 - learning_rate: 0.0010\n",
            "Epoch 65/943\n",
            "28/28 - 40s - 1s/step - accuracy: 0.9625 - loss: 0.0059 - val_accuracy: 0.9591 - val_loss: 0.0142 - learning_rate: 0.0010\n",
            "Epoch 66/943\n",
            "28/28 - 41s - 1s/step - accuracy: 0.9739 - loss: 0.0072 - val_accuracy: 0.9500 - val_loss: 0.0150 - learning_rate: 0.0010\n",
            "Epoch 67/943\n",
            "28/28 - 41s - 1s/step - accuracy: 0.9670 - loss: 0.0049 - val_accuracy: 0.9318 - val_loss: 0.0230 - learning_rate: 0.0010\n",
            "Epoch 68/943\n",
            "28/28 - 45s - 2s/step - accuracy: 0.9773 - loss: 0.0057 - val_accuracy: 0.9591 - val_loss: 0.0055 - learning_rate: 0.0010\n",
            "Epoch 69/943\n",
            "28/28 - 36s - 1s/step - accuracy: 0.9841 - loss: 0.0038 - val_accuracy: 0.9591 - val_loss: 0.0068 - learning_rate: 0.0010\n",
            "Epoch 70/943\n",
            "28/28 - 41s - 1s/step - accuracy: 0.9818 - loss: 0.0033 - val_accuracy: 0.9636 - val_loss: 0.0115 - learning_rate: 0.0010\n",
            "Epoch 71/943\n",
            "28/28 - 42s - 2s/step - accuracy: 0.9670 - loss: 0.0060 - val_accuracy: 0.8636 - val_loss: 0.0342 - learning_rate: 0.0010\n",
            "Epoch 72/943\n",
            "28/28 - 31s - 1s/step - accuracy: 0.9739 - loss: 0.0065 - val_accuracy: 0.9182 - val_loss: 0.0162 - learning_rate: 0.0010\n",
            "Epoch 73/943\n",
            "28/28 - 41s - 1s/step - accuracy: 0.9807 - loss: 0.0045 - val_accuracy: 0.9136 - val_loss: 0.0296 - learning_rate: 0.0010\n",
            "Epoch 74/943\n",
            "28/28 - 32s - 1s/step - accuracy: 0.9841 - loss: 0.0027 - val_accuracy: 0.9545 - val_loss: 0.0099 - learning_rate: 0.0010\n",
            "Epoch 75/943\n",
            "28/28 - 40s - 1s/step - accuracy: 0.9852 - loss: 0.0033 - val_accuracy: 0.8864 - val_loss: 0.0194 - learning_rate: 0.0010\n",
            "Epoch 76/943\n",
            "28/28 - 32s - 1s/step - accuracy: 0.9830 - loss: 0.0030 - val_accuracy: 0.9636 - val_loss: 0.0160 - learning_rate: 0.0010\n",
            "Epoch 77/943\n",
            "28/28 - 41s - 1s/step - accuracy: 0.9761 - loss: 0.0044 - val_accuracy: 0.9591 - val_loss: 0.0066 - learning_rate: 0.0010\n",
            "Epoch 78/943\n",
            "28/28 - 40s - 1s/step - accuracy: 0.9750 - loss: 0.0043 - val_accuracy: 0.9318 - val_loss: 0.0159 - learning_rate: 0.0010\n",
            "Epoch 79/943\n",
            "28/28 - 42s - 1s/step - accuracy: 0.9761 - loss: 0.0042 - val_accuracy: 0.7000 - val_loss: 0.1762 - learning_rate: 0.0010\n",
            "Epoch 80/943\n",
            "28/28 - 40s - 1s/step - accuracy: 0.9795 - loss: 0.0039 - val_accuracy: 0.9000 - val_loss: 0.0326 - learning_rate: 0.0010\n",
            "Epoch 81/943\n",
            "28/28 - 41s - 1s/step - accuracy: 0.9432 - loss: 0.0173 - val_accuracy: 0.8182 - val_loss: 0.0960 - learning_rate: 0.0010\n",
            "Epoch 82/943\n",
            "28/28 - 42s - 2s/step - accuracy: 0.9614 - loss: 0.0105 - val_accuracy: 0.2182 - val_loss: 3.1504 - learning_rate: 0.0010\n",
            "Epoch 83/943\n",
            "28/28 - 40s - 1s/step - accuracy: 0.9682 - loss: 0.0077 - val_accuracy: 0.4909 - val_loss: 1.9460 - learning_rate: 0.0010\n",
            "Epoch 84/943\n",
            "28/28 - 42s - 2s/step - accuracy: 0.9841 - loss: 0.0044 - val_accuracy: 0.7136 - val_loss: 0.9350 - learning_rate: 0.0010\n",
            "Epoch 85/943\n",
            "28/28 - 41s - 1s/step - accuracy: 0.9773 - loss: 0.0050 - val_accuracy: 0.7455 - val_loss: 0.5007 - learning_rate: 0.0010\n",
            "Epoch 86/943\n",
            "28/28 - 41s - 1s/step - accuracy: 0.9795 - loss: 0.0040 - val_accuracy: 0.8364 - val_loss: 0.0927 - learning_rate: 0.0010\n",
            "Epoch 87/943\n",
            "28/28 - 40s - 1s/step - accuracy: 0.9830 - loss: 0.0032 - val_accuracy: 0.9000 - val_loss: 0.0381 - learning_rate: 0.0010\n",
            "Epoch 88/943\n",
            "28/28 - 42s - 1s/step - accuracy: 0.9807 - loss: 0.0034 - val_accuracy: 0.9318 - val_loss: 0.0155 - learning_rate: 0.0010\n",
            "Epoch 89/943\n",
            "28/28 - 41s - 1s/step - accuracy: 0.9795 - loss: 0.0047 - val_accuracy: 0.8636 - val_loss: 0.0990 - learning_rate: 0.0010\n",
            "Epoch 90/943\n",
            "28/28 - 41s - 1s/step - accuracy: 0.9807 - loss: 0.0030 - val_accuracy: 0.9727 - val_loss: 0.0064 - learning_rate: 0.0010\n",
            "Epoch 91/943\n",
            "28/28 - 41s - 1s/step - accuracy: 0.9852 - loss: 0.0032 - val_accuracy: 0.9682 - val_loss: 0.0093 - learning_rate: 0.0010\n",
            "Epoch 92/943\n",
            "28/28 - 40s - 1s/step - accuracy: 0.9864 - loss: 0.0021 - val_accuracy: 0.9091 - val_loss: 0.0479 - learning_rate: 0.0010\n",
            "Epoch 93/943\n",
            "28/28 - 41s - 1s/step - accuracy: 0.9602 - loss: 0.0075 - val_accuracy: 0.8955 - val_loss: 0.0624 - learning_rate: 0.0010\n",
            "Epoch 94/943\n",
            "28/28 - 41s - 1s/step - accuracy: 0.9852 - loss: 0.0025 - val_accuracy: 0.9591 - val_loss: 0.0119 - learning_rate: 0.0010\n",
            "Epoch 95/943\n",
            "28/28 - 42s - 2s/step - accuracy: 0.9886 - loss: 0.0024 - val_accuracy: 0.9682 - val_loss: 0.0121 - learning_rate: 0.0010\n",
            "Epoch 96/943\n",
            "28/28 - 41s - 1s/step - accuracy: 0.9795 - loss: 0.0035 - val_accuracy: 0.8818 - val_loss: 0.0598 - learning_rate: 0.0010\n",
            "Epoch 97/943\n",
            "28/28 - 41s - 1s/step - accuracy: 0.9886 - loss: 0.0028 - val_accuracy: 0.9000 - val_loss: 0.0382 - learning_rate: 0.0010\n",
            "Epoch 98/943\n",
            "28/28 - 41s - 1s/step - accuracy: 0.9864 - loss: 0.0031 - val_accuracy: 0.9455 - val_loss: 0.0163 - learning_rate: 0.0010\n",
            "Epoch 99/943\n",
            "28/28 - 41s - 1s/step - accuracy: 0.9909 - loss: 0.0031 - val_accuracy: 0.9227 - val_loss: 0.0416 - learning_rate: 0.0010\n",
            "Epoch 100/943\n",
            "28/28 - 40s - 1s/step - accuracy: 0.9875 - loss: 0.0019 - val_accuracy: 0.9136 - val_loss: 0.0395 - learning_rate: 0.0010\n",
            "Epoch 101/943\n",
            "28/28 - 41s - 1s/step - accuracy: 0.9864 - loss: 0.0023 - val_accuracy: 0.9500 - val_loss: 0.0170 - learning_rate: 0.0010\n",
            "Epoch 102/943\n",
            "28/28 - 41s - 1s/step - accuracy: 0.9875 - loss: 0.0027 - val_accuracy: 0.8909 - val_loss: 0.0444 - learning_rate: 0.0010\n",
            "Epoch 103/943\n",
            "28/28 - 41s - 1s/step - accuracy: 0.9875 - loss: 0.0024 - val_accuracy: 0.7500 - val_loss: 0.4095 - learning_rate: 0.0010\n",
            "Epoch 104/943\n",
            "28/28 - 41s - 1s/step - accuracy: 0.9614 - loss: 0.0089 - val_accuracy: 0.7182 - val_loss: 0.1801 - learning_rate: 0.0010\n",
            "Epoch 105/943\n",
            "28/28 - 31s - 1s/step - accuracy: 0.9795 - loss: 0.0040 - val_accuracy: 0.9455 - val_loss: 0.0230 - learning_rate: 0.0010\n",
            "Epoch 106/943\n",
            "28/28 - 42s - 1s/step - accuracy: 0.9886 - loss: 0.0027 - val_accuracy: 0.9818 - val_loss: 0.0070 - learning_rate: 0.0010\n",
            "Epoch 107/943\n",
            "28/28 - 41s - 1s/step - accuracy: 0.9886 - loss: 0.0024 - val_accuracy: 0.9773 - val_loss: 0.0059 - learning_rate: 0.0010\n",
            "Epoch 108/943\n",
            "28/28 - 46s - 2s/step - accuracy: 0.9886 - loss: 0.0023 - val_accuracy: 0.9773 - val_loss: 0.0046 - learning_rate: 0.0010\n",
            "Epoch 109/943\n",
            "28/28 - 34s - 1s/step - accuracy: 0.9898 - loss: 0.0016 - val_accuracy: 0.9500 - val_loss: 0.0099 - learning_rate: 0.0010\n",
            "Epoch 110/943\n",
            "28/28 - 42s - 1s/step - accuracy: 0.9864 - loss: 0.0028 - val_accuracy: 0.9455 - val_loss: 0.0105 - learning_rate: 0.0010\n",
            "Epoch 111/943\n",
            "28/28 - 41s - 1s/step - accuracy: 0.9830 - loss: 0.0027 - val_accuracy: 0.9636 - val_loss: 0.0083 - learning_rate: 0.0010\n",
            "Epoch 112/943\n",
            "28/28 - 41s - 1s/step - accuracy: 0.9761 - loss: 0.0039 - val_accuracy: 0.7864 - val_loss: 0.1066 - learning_rate: 0.0010\n",
            "Epoch 113/943\n",
            "28/28 - 40s - 1s/step - accuracy: 0.9875 - loss: 0.0034 - val_accuracy: 0.8818 - val_loss: 0.0777 - learning_rate: 0.0010\n",
            "Epoch 114/943\n",
            "28/28 - 41s - 1s/step - accuracy: 0.9852 - loss: 0.0024 - val_accuracy: 0.8727 - val_loss: 0.1298 - learning_rate: 0.0010\n",
            "Epoch 115/943\n",
            "28/28 - 41s - 1s/step - accuracy: 0.9932 - loss: 0.0018 - val_accuracy: 0.8682 - val_loss: 0.1466 - learning_rate: 0.0010\n",
            "Epoch 116/943\n",
            "28/28 - 42s - 1s/step - accuracy: 0.9864 - loss: 0.0018 - val_accuracy: 0.5091 - val_loss: 0.7318 - learning_rate: 0.0010\n",
            "Epoch 117/943\n",
            "28/28 - 41s - 1s/step - accuracy: 0.9909 - loss: 0.0017 - val_accuracy: 0.9500 - val_loss: 0.0124 - learning_rate: 0.0010\n",
            "Epoch 118/943\n",
            "28/28 - 41s - 1s/step - accuracy: 0.9898 - loss: 0.0017 - val_accuracy: 0.9818 - val_loss: 0.0074 - learning_rate: 0.0010\n",
            "Epoch 119/943\n",
            "28/28 - 41s - 1s/step - accuracy: 0.9932 - loss: 0.0021 - val_accuracy: 0.2909 - val_loss: 2.6644 - learning_rate: 0.0010\n",
            "Epoch 120/943\n",
            "28/28 - 41s - 1s/step - accuracy: 0.9773 - loss: 0.0055 - val_accuracy: 0.3182 - val_loss: 2.6765 - learning_rate: 0.0010\n",
            "Epoch 121/943\n",
            "28/28 - 40s - 1s/step - accuracy: 0.9693 - loss: 0.0085 - val_accuracy: 0.2318 - val_loss: 3.0336 - learning_rate: 0.0010\n",
            "Epoch 122/943\n",
            "28/28 - 41s - 1s/step - accuracy: 0.9886 - loss: 0.0026 - val_accuracy: 0.2318 - val_loss: 3.0568 - learning_rate: 0.0010\n",
            "Epoch 123/943\n",
            "28/28 - 42s - 1s/step - accuracy: 0.9886 - loss: 0.0022 - val_accuracy: 0.3455 - val_loss: 2.3550 - learning_rate: 0.0010\n",
            "Epoch 124/943\n",
            "28/28 - 40s - 1s/step - accuracy: 0.9795 - loss: 0.0067 - val_accuracy: 0.8727 - val_loss: 0.0934 - learning_rate: 0.0010\n",
            "Epoch 125/943\n",
            "28/28 - 41s - 1s/step - accuracy: 0.9500 - loss: 0.0180 - val_accuracy: 0.5455 - val_loss: 1.0379 - learning_rate: 0.0010\n",
            "Epoch 126/943\n",
            "28/28 - 41s - 1s/step - accuracy: 0.9489 - loss: 0.0143 - val_accuracy: 0.4455 - val_loss: 2.2346 - learning_rate: 0.0010\n",
            "Epoch 127/943\n",
            "28/28 - 42s - 1s/step - accuracy: 0.9773 - loss: 0.0043 - val_accuracy: 0.4864 - val_loss: 1.8344 - learning_rate: 0.0010\n",
            "Epoch 128/943\n",
            "28/28 - 41s - 1s/step - accuracy: 0.9841 - loss: 0.0027 - val_accuracy: 0.6045 - val_loss: 1.0882 - learning_rate: 0.0010\n",
            "Epoch 129/943\n",
            "28/28 - 31s - 1s/step - accuracy: 0.9761 - loss: 0.0048 - val_accuracy: 0.4955 - val_loss: 1.9378 - learning_rate: 0.0010\n",
            "Epoch 130/943\n",
            "28/28 - 42s - 2s/step - accuracy: 0.9795 - loss: 0.0046 - val_accuracy: 0.2182 - val_loss: 3.1504 - learning_rate: 0.0010\n",
            "Epoch 131/943\n",
            "28/28 - 40s - 1s/step - accuracy: 0.9818 - loss: 0.0032 - val_accuracy: 0.2227 - val_loss: 3.1320 - learning_rate: 0.0010\n",
            "Epoch 132/943\n",
            "28/28 - 41s - 1s/step - accuracy: 0.9818 - loss: 0.0030 - val_accuracy: 0.2591 - val_loss: 2.8990 - learning_rate: 0.0010\n",
            "Epoch 133/943\n",
            "28/28 - 41s - 1s/step - accuracy: 0.9886 - loss: 0.0020 - val_accuracy: 0.4136 - val_loss: 1.4921 - learning_rate: 0.0010\n",
            "Epoch 134/943\n",
            "28/28 - 31s - 1s/step - accuracy: 0.9864 - loss: 0.0031 - val_accuracy: 0.4727 - val_loss: 0.8861 - learning_rate: 0.0010\n",
            "Epoch 135/943\n",
            "28/28 - 42s - 1s/step - accuracy: 0.9852 - loss: 0.0038 - val_accuracy: 0.8636 - val_loss: 0.0906 - learning_rate: 0.0010\n",
            "Epoch 136/943\n",
            "28/28 - 40s - 1s/step - accuracy: 0.9795 - loss: 0.0036 - val_accuracy: 0.9682 - val_loss: 0.0217 - learning_rate: 0.0010\n",
            "Epoch 137/943\n",
            "28/28 - 42s - 1s/step - accuracy: 0.9909 - loss: 0.0027 - val_accuracy: 0.9455 - val_loss: 0.0286 - learning_rate: 0.0010\n",
            "Epoch 138/943\n",
            "28/28 - 41s - 1s/step - accuracy: 0.9818 - loss: 0.0029 - val_accuracy: 0.9727 - val_loss: 0.0140 - learning_rate: 0.0010\n",
            "Epoch 139/943\n",
            "28/28 - 41s - 1s/step - accuracy: 0.9898 - loss: 0.0023 - val_accuracy: 0.9455 - val_loss: 0.0149 - learning_rate: 0.0010\n",
            "Epoch 140/943\n",
            "28/28 - 40s - 1s/step - accuracy: 0.9932 - loss: 0.0016 - val_accuracy: 0.9682 - val_loss: 0.0095 - learning_rate: 0.0010\n",
            "Epoch 141/943\n",
            "28/28 - 42s - 1s/step - accuracy: 0.9841 - loss: 0.0033 - val_accuracy: 0.9818 - val_loss: 0.0060 - learning_rate: 0.0010\n",
            "Epoch 142/943\n",
            "28/28 - 40s - 1s/step - accuracy: 0.9739 - loss: 0.0079 - val_accuracy: 0.9091 - val_loss: 0.0538 - learning_rate: 0.0010\n",
            "Epoch 143/943\n",
            "28/28 - 42s - 1s/step - accuracy: 0.9830 - loss: 0.0036 - val_accuracy: 0.9682 - val_loss: 0.0116 - learning_rate: 0.0010\n",
            "Epoch 144/943\n",
            "28/28 - 41s - 1s/step - accuracy: 0.9909 - loss: 0.0024 - val_accuracy: 0.9409 - val_loss: 0.0214 - learning_rate: 0.0010\n",
            "Epoch 145/943\n",
            "28/28 - 41s - 1s/step - accuracy: 0.9898 - loss: 0.0021 - val_accuracy: 0.7273 - val_loss: 0.3443 - learning_rate: 0.0010\n",
            "Epoch 146/943\n",
            "28/28 - 40s - 1s/step - accuracy: 0.9898 - loss: 0.0023 - val_accuracy: 0.7682 - val_loss: 0.2471 - learning_rate: 0.0010\n",
            "Epoch 147/943\n",
            "28/28 - 42s - 1s/step - accuracy: 0.9864 - loss: 0.0044 - val_accuracy: 0.7591 - val_loss: 0.2880 - learning_rate: 0.0010\n",
            "Epoch 148/943\n",
            "28/28 - 40s - 1s/step - accuracy: 0.9693 - loss: 0.0084 - val_accuracy: 0.6227 - val_loss: 0.4001 - learning_rate: 0.0010\n",
            "Epoch 149/943\n",
            "28/28 - 42s - 1s/step - accuracy: 0.9614 - loss: 0.0186 - val_accuracy: 0.8136 - val_loss: 0.4375 - learning_rate: 0.0010\n",
            "Epoch 150/943\n",
            "28/28 - 31s - 1s/step - accuracy: 0.9670 - loss: 0.0079 - val_accuracy: 0.8273 - val_loss: 0.1604 - learning_rate: 0.0010\n",
            "Epoch 151/943\n",
            "28/28 - 31s - 1s/step - accuracy: 0.9773 - loss: 0.0045 - val_accuracy: 0.9227 - val_loss: 0.0493 - learning_rate: 0.0010\n",
            "Epoch 152/943\n",
            "28/28 - 42s - 2s/step - accuracy: 0.9795 - loss: 0.0044 - val_accuracy: 0.9318 - val_loss: 0.0347 - learning_rate: 0.0010\n",
            "Epoch 153/943\n",
            "28/28 - 40s - 1s/step - accuracy: 0.9807 - loss: 0.0033 - val_accuracy: 0.9364 - val_loss: 0.0132 - learning_rate: 0.0010\n",
            "Epoch 154/943\n",
            "28/28 - 47s - 2s/step - accuracy: 0.9784 - loss: 0.0029 - val_accuracy: 0.9864 - val_loss: 0.0027 - learning_rate: 0.0010\n",
            "Epoch 155/943\n",
            "28/28 - 31s - 1s/step - accuracy: 0.9955 - loss: 8.7880e-04 - val_accuracy: 0.9818 - val_loss: 0.0057 - learning_rate: 0.0010\n",
            "Epoch 156/943\n",
            "28/28 - 41s - 1s/step - accuracy: 0.9955 - loss: 0.0013 - val_accuracy: 0.9682 - val_loss: 0.0053 - learning_rate: 0.0010\n",
            "Epoch 157/943\n",
            "28/28 - 42s - 1s/step - accuracy: 0.9875 - loss: 0.0018 - val_accuracy: 0.9773 - val_loss: 0.0087 - learning_rate: 0.0010\n",
            "Epoch 158/943\n",
            "28/28 - 41s - 1s/step - accuracy: 0.9898 - loss: 0.0014 - val_accuracy: 0.9682 - val_loss: 0.0063 - learning_rate: 0.0010\n",
            "Epoch 159/943\n",
            "28/28 - 41s - 1s/step - accuracy: 0.9977 - loss: 8.5323e-04 - val_accuracy: 0.9545 - val_loss: 0.0105 - learning_rate: 0.0010\n",
            "Epoch 160/943\n",
            "28/28 - 31s - 1s/step - accuracy: 0.9943 - loss: 0.0012 - val_accuracy: 0.9682 - val_loss: 0.0064 - learning_rate: 0.0010\n",
            "Epoch 161/943\n",
            "28/28 - 41s - 1s/step - accuracy: 0.9920 - loss: 0.0012 - val_accuracy: 0.9864 - val_loss: 0.0074 - learning_rate: 0.0010\n",
            "Epoch 162/943\n",
            "28/28 - 31s - 1s/step - accuracy: 0.9943 - loss: 0.0019 - val_accuracy: 0.9591 - val_loss: 0.0110 - learning_rate: 0.0010\n",
            "Epoch 163/943\n",
            "28/28 - 31s - 1s/step - accuracy: 0.9955 - loss: 9.8111e-04 - val_accuracy: 0.9682 - val_loss: 0.0050 - learning_rate: 0.0010\n",
            "Epoch 164/943\n",
            "28/28 - 41s - 1s/step - accuracy: 0.9932 - loss: 0.0014 - val_accuracy: 0.9591 - val_loss: 0.0149 - learning_rate: 0.0010\n",
            "Epoch 165/943\n",
            "28/28 - 40s - 1s/step - accuracy: 0.9943 - loss: 6.5529e-04 - val_accuracy: 0.9364 - val_loss: 0.0264 - learning_rate: 0.0010\n",
            "Epoch 166/943\n",
            "28/28 - 42s - 2s/step - accuracy: 0.9920 - loss: 0.0013 - val_accuracy: 0.9045 - val_loss: 0.0319 - learning_rate: 0.0010\n",
            "Epoch 167/943\n",
            "28/28 - 41s - 1s/step - accuracy: 0.9966 - loss: 0.0011 - val_accuracy: 0.9636 - val_loss: 0.0115 - learning_rate: 0.0010\n",
            "Epoch 168/943\n",
            "28/28 - 41s - 1s/step - accuracy: 0.9898 - loss: 0.0031 - val_accuracy: 0.9500 - val_loss: 0.0182 - learning_rate: 0.0010\n",
            "Epoch 169/943\n",
            "28/28 - 40s - 1s/step - accuracy: 0.9864 - loss: 0.0022 - val_accuracy: 0.9864 - val_loss: 0.0051 - learning_rate: 0.0010\n",
            "Epoch 170/943\n",
            "28/28 - 41s - 1s/step - accuracy: 0.9920 - loss: 0.0015 - val_accuracy: 0.9591 - val_loss: 0.0075 - learning_rate: 0.0010\n",
            "Epoch 171/943\n",
            "28/28 - 42s - 1s/step - accuracy: 0.9898 - loss: 0.0014 - val_accuracy: 0.9818 - val_loss: 0.0065 - learning_rate: 0.0010\n",
            "Epoch 172/943\n",
            "28/28 - 58s - 2s/step - accuracy: 0.9909 - loss: 0.0015 - val_accuracy: 0.9818 - val_loss: 0.0024 - learning_rate: 0.0010\n",
            "Epoch 173/943\n",
            "28/28 - 65s - 2s/step - accuracy: 0.9943 - loss: 7.7656e-04 - val_accuracy: 0.9773 - val_loss: 0.0043 - learning_rate: 0.0010\n",
            "Epoch 174/943\n",
            "28/28 - 41s - 1s/step - accuracy: 0.9955 - loss: 0.0010 - val_accuracy: 0.9909 - val_loss: 0.0026 - learning_rate: 0.0010\n",
            "Epoch 175/943\n",
            "28/28 - 41s - 1s/step - accuracy: 0.9818 - loss: 0.0043 - val_accuracy: 0.9318 - val_loss: 0.0655 - learning_rate: 0.0010\n",
            "Epoch 176/943\n",
            "28/28 - 41s - 1s/step - accuracy: 0.9875 - loss: 0.0024 - val_accuracy: 0.9591 - val_loss: 0.0338 - learning_rate: 0.0010\n",
            "Epoch 177/943\n",
            "28/28 - 40s - 1s/step - accuracy: 0.9852 - loss: 0.0046 - val_accuracy: 0.9545 - val_loss: 0.0110 - learning_rate: 0.0010\n",
            "Epoch 178/943\n",
            "28/28 - 41s - 1s/step - accuracy: 0.9830 - loss: 0.0063 - val_accuracy: 0.9773 - val_loss: 0.0046 - learning_rate: 0.0010\n",
            "Epoch 179/943\n",
            "28/28 - 31s - 1s/step - accuracy: 0.9807 - loss: 0.0060 - val_accuracy: 0.5500 - val_loss: 1.6983 - learning_rate: 0.0010\n",
            "Epoch 180/943\n",
            "28/28 - 42s - 2s/step - accuracy: 0.9761 - loss: 0.0047 - val_accuracy: 0.5455 - val_loss: 1.7853 - learning_rate: 0.0010\n",
            "Epoch 181/943\n",
            "28/28 - 41s - 1s/step - accuracy: 0.9750 - loss: 0.0056 - val_accuracy: 0.9409 - val_loss: 0.0112 - learning_rate: 0.0010\n",
            "Epoch 182/943\n",
            "28/28 - 40s - 1s/step - accuracy: 0.9852 - loss: 0.0032 - val_accuracy: 0.9818 - val_loss: 0.0063 - learning_rate: 0.0010\n",
            "Epoch 183/943\n",
            "28/28 - 41s - 1s/step - accuracy: 0.9966 - loss: 5.7909e-04 - val_accuracy: 0.9727 - val_loss: 0.0116 - learning_rate: 0.0010\n",
            "Epoch 184/943\n",
            "28/28 - 32s - 1s/step - accuracy: 0.9909 - loss: 0.0026 - val_accuracy: 0.9773 - val_loss: 0.0048 - learning_rate: 0.0010\n",
            "Epoch 185/943\n",
            "28/28 - 41s - 1s/step - accuracy: 0.9932 - loss: 0.0011 - val_accuracy: 0.9682 - val_loss: 0.0124 - learning_rate: 0.0010\n",
            "Epoch 186/943\n",
            "28/28 - 40s - 1s/step - accuracy: 0.9909 - loss: 0.0018 - val_accuracy: 0.9545 - val_loss: 0.0198 - learning_rate: 0.0010\n",
            "Epoch 187/943\n",
            "28/28 - 41s - 1s/step - accuracy: 0.9932 - loss: 8.5933e-04 - val_accuracy: 0.9636 - val_loss: 0.0187 - learning_rate: 0.0010\n",
            "Epoch 188/943\n",
            "28/28 - 41s - 1s/step - accuracy: 0.9943 - loss: 7.1213e-04 - val_accuracy: 0.6318 - val_loss: 0.6749 - learning_rate: 0.0010\n",
            "Epoch 189/943\n",
            "28/28 - 41s - 1s/step - accuracy: 0.9955 - loss: 0.0019 - val_accuracy: 0.9636 - val_loss: 0.0108 - learning_rate: 0.0010\n",
            "Epoch 190/943\n",
            "28/28 - 42s - 1s/step - accuracy: 0.9886 - loss: 0.0032 - val_accuracy: 0.7909 - val_loss: 0.4973 - learning_rate: 0.0010\n",
            "Epoch 191/943\n",
            "28/28 - 40s - 1s/step - accuracy: 0.9920 - loss: 0.0020 - val_accuracy: 0.9727 - val_loss: 0.0112 - learning_rate: 0.0010\n",
            "Epoch 192/943\n",
            "28/28 - 32s - 1s/step - accuracy: 0.9830 - loss: 0.0057 - val_accuracy: 0.9182 - val_loss: 0.0451 - learning_rate: 0.0010\n",
            "Epoch 193/943\n",
            "28/28 - 40s - 1s/step - accuracy: 0.9773 - loss: 0.0054 - val_accuracy: 0.9136 - val_loss: 0.0483 - learning_rate: 0.0010\n",
            "Epoch 194/943\n",
            "28/28 - 42s - 2s/step - accuracy: 0.9841 - loss: 0.0020 - val_accuracy: 0.9773 - val_loss: 0.0084 - learning_rate: 0.0010\n",
            "Epoch 195/943\n",
            "28/28 - 53s - 2s/step - accuracy: 0.9943 - loss: 0.0015 - val_accuracy: 0.9864 - val_loss: 0.0021 - learning_rate: 0.0010\n",
            "Epoch 196/943\n",
            "28/28 - 69s - 2s/step - accuracy: 0.9909 - loss: 0.0023 - val_accuracy: 0.9773 - val_loss: 0.0028 - learning_rate: 0.0010\n",
            "Epoch 197/943\n",
            "28/28 - 41s - 1s/step - accuracy: 0.9864 - loss: 0.0024 - val_accuracy: 0.9818 - val_loss: 0.0033 - learning_rate: 0.0010\n",
            "Epoch 198/943\n",
            "28/28 - 32s - 1s/step - accuracy: 0.9898 - loss: 0.0020 - val_accuracy: 0.9727 - val_loss: 0.0033 - learning_rate: 0.0010\n",
            "Epoch 199/943\n",
            "28/28 - 49s - 2s/step - accuracy: 0.9932 - loss: 0.0015 - val_accuracy: 0.9955 - val_loss: 9.2773e-04 - learning_rate: 0.0010\n",
            "Epoch 200/943\n",
            "28/28 - 65s - 2s/step - accuracy: 0.9841 - loss: 0.0047 - val_accuracy: 0.9682 - val_loss: 0.0058 - learning_rate: 0.0010\n",
            "Epoch 201/943\n",
            "28/28 - 39s - 1s/step - accuracy: 0.9943 - loss: 0.0014 - val_accuracy: 0.9591 - val_loss: 0.0083 - learning_rate: 0.0010\n",
            "Epoch 202/943\n",
            "28/28 - 42s - 2s/step - accuracy: 0.9886 - loss: 0.0024 - val_accuracy: 0.9273 - val_loss: 0.0329 - learning_rate: 0.0010\n",
            "Epoch 203/943\n",
            "28/28 - 41s - 1s/step - accuracy: 0.9864 - loss: 0.0043 - val_accuracy: 0.9818 - val_loss: 0.0030 - learning_rate: 0.0010\n",
            "Epoch 204/943\n",
            "28/28 - 41s - 1s/step - accuracy: 0.9909 - loss: 0.0025 - val_accuracy: 0.9727 - val_loss: 0.0047 - learning_rate: 0.0010\n",
            "Epoch 205/943\n",
            "28/28 - 40s - 1s/step - accuracy: 0.9807 - loss: 0.0048 - val_accuracy: 0.8864 - val_loss: 0.0812 - learning_rate: 0.0010\n",
            "Epoch 206/943\n",
            "28/28 - 42s - 2s/step - accuracy: 0.9920 - loss: 0.0043 - val_accuracy: 0.7000 - val_loss: 1.0498 - learning_rate: 0.0010\n",
            "Epoch 207/943\n"
          ]
        }
      ]
    }
  ]
}