{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GH6uYngGtEo8",
        "outputId": "d3daf30a-b8e6-4d8c-f3d3-eebd1c984ad1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: natsort in /usr/local/lib/python3.10/dist-packages (8.4.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install natsort"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KX7l2rWG0S5R",
        "outputId": "8b1a37ce-4183-448b-e0bf-36da354ddfe1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-3CkQXV3Deks"
      },
      "outputs": [],
      "source": [
        "import joblib\n",
        "import sys\n",
        "from natsort import natsorted\n",
        "sys.modules['sklearn.externals.joblib'] = joblib\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import itertools\n",
        "import seaborn as sns\n",
        "import zipfile\n",
        "import os\n",
        "import cv2\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn import preprocessing\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.ensemble import VotingClassifier\n",
        "from sklearn.svm import SVC\n",
        "from mlxtend.feature_selection import SequentialFeatureSelector as SFS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GSmUI9kH7Spb"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.utils import to_categorical\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D,MaxPooling2D,Activation, Dropout, Flatten, Dense\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eYx-0qZ10q_s"
      },
      "outputs": [],
      "source": [
        "!mkdir defect_bearing_saved_pictures"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Mx2RfCdz0P4f"
      },
      "outputs": [],
      "source": [
        "!cp /content/drive/MyDrive/defect_bearing_saved_pictures_one_by_one/Pictures_generated_one_by_one_bearing_defaults_morefeatures_norma.zip /content/sample_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d-ffkdfe0wmH"
      },
      "outputs": [],
      "source": [
        "\n",
        "with zipfile.ZipFile(\"/content/sample_data/Pictures_generated_one_by_one_bearing_defaults_morefeatures_norma.zip\",\"r\") as zip_ref:\n",
        "    zip_ref.extractall(\"/content/defect_bearing_saved_pictures\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AOR7lTQUJPD9"
      },
      "outputs": [],
      "source": [
        "def union_lists(*lists):\n",
        "  # use the chain() function from itertools to concatenate all the lists\n",
        "  concatenated_list = list(itertools.chain(*lists))\n",
        "  # use the set() function to remove duplicates and convert the concatenated list to a set\n",
        "  unique_set = set(concatenated_list)\n",
        "  # convert the set back to a list and return it as the final union\n",
        "  final_union = list(unique_set)\n",
        "  final_union.sort()\n",
        "  return final_union"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B4ZbISsc2EkZ"
      },
      "outputs": [],
      "source": [
        "\n",
        "class reading_data_picture():\n",
        "    def __init__(self, path, img_size_x, img_size_y):\n",
        "        self.path = path\n",
        "        self.img_size_x = img_size_x\n",
        "        self.img_size_y = img_size_y\n",
        "    def get_data(self):\n",
        "        data = []\n",
        "        picture_list = os.listdir(self.path)\n",
        "        picture_list = natsorted(picture_list)\n",
        "        for x in picture_list:\n",
        "            picture_path = os.path.join(self.path,x)\n",
        "            out = cv2.imread(picture_path)\n",
        "            out_resize = cv2.resize(out,(self.img_size_x, self.img_size_y))\n",
        "            data.append(out_resize)\n",
        "        data_out = np.array(data) /255\n",
        "        return data_out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KCc-lB9z2bCb"
      },
      "outputs": [],
      "source": [
        "data_total  = reading_data_picture('/content/defect_bearing_saved_pictures', 224, 224)\n",
        "data_picture = data_total.get_data()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bTQyLpaZ2ygg"
      },
      "outputs": [],
      "source": [
        "class reading_data():\n",
        "  def __init__(self, path):\n",
        "    self.path = path\n",
        "  def reading_data(self):\n",
        "    df = pd.read_csv(self.path)\n",
        "    df['displacemednt'] = df['Acc, Rms (RMS)'] / df['Vel, Rms (RMS)']\n",
        "    df['momentum'] =  df['Acc, Rms (RMS)'] * df['Vel, Rms (RMS)']\n",
        "    print(df.isnull().sum())\n",
        "    if df.isnull().sum().all():\n",
        "      df = df.fillna(df.iloc[0])\n",
        "    else:\n",
        "      pass\n",
        "    outlier_indices_Vel = np.where((df['Vel, Rms (RMS)'] > 6.07) & (df['Vel, Peak (RMS)'] > 17.33) & (df['Vel, Peak to peak (RMS)'] > 32.70) )\n",
        "    outlier_indices_ace = np.where((df['Acc, Rms (RMS)'] > 2.32) )\n",
        "    outlier_indices_crest = np.where((df['Crest (RMS)'] > 4.74) )\n",
        "    outlier_indices_Kurt = np.where((df['Kurt (RMS)'] > 0.81) )\n",
        "    outliars =union_lists(list(outlier_indices_Vel[0]), list(outlier_indices_ace[0]), list(outlier_indices_crest[0]), list(outlier_indices_Kurt[0]))\n",
        "    no_outliers = df.drop(outliars)\n",
        "    return no_outliers\n",
        "  def visualization_pearson(self):\n",
        "    df = pd.read_csv(self.path)\n",
        "    corr =df.corr()\n",
        "    return sns.heatmap(\n",
        "        corr, annot=True,\n",
        "        vmin=-1, vmax=1, center=0,\n",
        "        cmap=sns.diverging_palette(5, 220, n=50),\n",
        "        square=True)\n",
        "  def visualization_kendas(self):\n",
        "    df = pd.read_csv(self.path)\n",
        "    corr =df.corr(method='kendall')\n",
        "    return sns.heatmap(\n",
        "        corr, annot=True,\n",
        "        center=0,\n",
        "        cmap=sns.diverging_palette(5, 220, n=50),\n",
        "        square=True)\n",
        "  def visualization_spearman(self):\n",
        "    df = pd.read_csv(self.path)\n",
        "    corr =df.corr(method='spearman')\n",
        "    return sns.heatmap(\n",
        "        corr, annot=True,\n",
        "        center=0,\n",
        "        cmap=sns.diverging_palette(5, 220, n=50),\n",
        "        square=True)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s7vMBLSxB-aj"
      },
      "outputs": [],
      "source": [
        "from imblearn.combine import SMOTETomek\n",
        "from imblearn.combine import SMOTEENN\n",
        "from imblearn.over_sampling import BorderlineSMOTE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ksQN2DzACKZP"
      },
      "outputs": [],
      "source": [
        "class augmnentation():\n",
        "  def __init__(self,x,y):\n",
        "    self.x = x\n",
        "    self.y = y\n",
        "  def SMOTETomek(self):\n",
        "    print(len(self.x))\n",
        "    if len(self.x.shape) == 4:\n",
        "      x_reshaped = self.x.reshape( self.x.shape[0], self.x.shape[1]* self.x.shape[2] *  self.x.shape[-1] )\n",
        "      print(x_reshaped.shape)\n",
        "      smt = SMOTETomek(sampling_strategy='auto')\n",
        "      X_resampled, y_resampled = smt.fit_resample(x_reshaped, self.y)\n",
        "      X_resampled_re = X_resampled.reshape(X_resampled.shape[0],self.x.shape[1], self.x.shape[2],self.x.shape[-1])\n",
        "      print(\"The distribution over the final distribution \", pd.DataFrame(y_resampled).value_counts())\n",
        "      return X_resampled_re, y_resampled\n",
        "    if len(self.x.shape) == 2:\n",
        "      smt = SMOTETomek(sampling_strategy='auto')\n",
        "      X_resampled, y_resampled = smt.fit_resample(self.x, self.y)\n",
        "      return  X_resampled, y_resampled\n",
        "  def SMOTEENN(self):\n",
        "    if len(self.x.shape) == 4:\n",
        "      x_reshaped = self.x.reshape( self.x.shape[0], self.x.shape[1]* self.x.shape[2] *  self.x.shape[-1]  )\n",
        "      smote_enn = SMOTEENN()\n",
        "      X_resampled, y_resampled = smote_enn.fit_resample(x_reshaped, self.y)\n",
        "      X_resampled_re = X_resampled.reshape(X_resampled.shape[0],self.x.shape[1], self.x.shape[2],self.x.shape[-1])\n",
        "      print(\"The distribution over the final distribution \", pd.DataFrame(y_resampled).value_counts())\n",
        "      return X_resampled_re, y_resampled\n",
        "    if len(self.x.shape) == 2:\n",
        "      smt = SMOTETomek(sampling_strategy='auto')\n",
        "      X_resampled, y_resampled = smote_enn.fit_resample(self.x, self.y)\n",
        "      return  X_resampled, y_resampled\n",
        "  def BorderlineSMOTE(self):\n",
        "    if len(self.x.shape) == 4:\n",
        "      x_reshaped = self.x.reshape( self.x.shape[0], self.x.shape[1]* self.x.shape[2] *  self.x.shape[-1]  )\n",
        "      blsmote = BorderlineSMOTE(sampling_strategy='minority', kind='borderline-1')\n",
        "      X_resampled, y_resampled = blsmote.fit_resample(x_reshaped, self.y)\n",
        "      X_resampled_re = X_resampled.reshape(X_resampled.shape[0],self.x.shape[1], self.x.shape[2],self.x.shape[-1])\n",
        "      print(\"The distribution over the final distribution \", pd.DataFrame(y_resampled).value_counts())\n",
        "      return X_resampled_re, y_resampled\n",
        "    if len(self.x.shape) == 2:\n",
        "      blsmote = BorderlineSMOTE(sampling_strategy='minority', kind='borderline-1')\n",
        "      X_resampled, y_resampled = blsmote.fit_resample(self.x, self.y)\n",
        "      return  X_resampled, y_resampled"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XkHoBkyO2kxa",
        "outputId": "ce0ae458-79e9-4d91-cfb1-b0fc7e01dd76"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "COMP_NAME                  0\n",
            "Vel, Rms (RMS)             0\n",
            "Acc, Rms (RMS)             0\n",
            "Crest (RMS)                0\n",
            "Kurt (RMS)                 0\n",
            "Vel, Peak (RMS)            0\n",
            "Vel, Peak to peak (RMS)    0\n",
            "MP_LOC                     0\n",
            "Label                      0\n",
            "displacemednt              0\n",
            "momentum                   0\n",
            "dtype: int64\n"
          ]
        }
      ],
      "source": [
        "\n",
        "data = reading_data(\"/content/bearing-failure.csv\")\n",
        "df = data.reading_data()\n",
        "target = df['Label']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Itp0RkAWJd6U",
        "outputId": "2705e4d1-100f-4430-ba28-5098e6a99524"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1242,)"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "target.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KQVsZR9KFn8a",
        "outputId": "fbed1c7f-26b5-497c-cdd2-a461581b4b96"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1242, 224, 224, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "data_picture.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PIHNJ1KkE_IW",
        "outputId": "d2d05980-2ef6-4d94-f8f0-e1dea91d4d74"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1242\n",
            "(1242, 150528)\n",
            "The distribution over the final distribution  0\n",
            "2    342\n",
            "0    294\n",
            "1    291\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "aug = augmnentation(data_picture,np.array(target))\n",
        "x_re , y_re = aug.SMOTETomek()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "raShXY3vOQpz",
        "outputId": "4e2c77df-f6d2-46ce-f854-aace4087f321"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The distribution over the final distribution  0\n",
            "2    83\n",
            "0    53\n",
            "1    40\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "x_re1 , y_re1 = aug.SMOTEENN()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Jge2Wa66OaT1"
      },
      "outputs": [],
      "source": [
        "#x_re2 , y_re2 = aug.BorderlineSMOTE()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KicbOdZ3LeI_"
      },
      "outputs": [],
      "source": [
        "data_augx , data_augy = pd.concat([pd.DataFrame(x_re.reshape(x_re.shape[0],x_re.shape[1]*x_re.shape[2]*x_re.shape[-1] )),pd.DataFrame(x_re1.reshape(x_re1.shape[0],x_re1.shape[1]*x_re1.shape[2]*x_re1.shape[-1]))], ignore_index=True),pd.concat([pd.DataFrame(y_re), pd.DataFrame(y_re1)], ignore_index=True)\n",
        "data_augx = np.array(data_augx).reshape(data_augx.shape[0],x_re.shape[1], x_re.shape[2],x_re.shape[-1])\n",
        "data_augy = np.array(data_augy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sb_dYjrX3QFs",
        "outputId": "2a6d6e94-e2ef-4297-9ad0-317cecb719e4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The training shaps is :  (882, 224, 224, 3)\n",
            "The testing shaps is :  (221, 224, 224, 3)\n",
            "The training target is :  (882, 3)\n",
            "The testing target is :  (221, 3)\n"
          ]
        }
      ],
      "source": [
        "from sklearn.preprocessing import OneHotEncoder\n",
        "encoder = OneHotEncoder(sparse_output=False)\n",
        "X_train, X_test, y_train, y_test = train_test_split(data_augx, encoder.fit_transform(data_augy.reshape( -1,1)), test_size=0.20, random_state=0)\n",
        "print(\"The training shaps is : \", X_train.shape)\n",
        "print(\"The testing shaps is : \", X_test.shape)\n",
        "print(\"The training target is : \", y_train.shape)\n",
        "print(\"The testing target is : \", y_test.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ThygiCrI4UQL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "22722d8f-1ed0-4129-82b1-0ad653c01c7b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/xception/xception_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "\u001b[1m83683744/83683744\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 0us/step\n"
          ]
        }
      ],
      "source": [
        "cnn_model = Sequential()\n",
        "\n",
        "\n",
        "pretrained_model= tf.keras.applications.Xception(\n",
        "    include_top=False,\n",
        "    weights= 'imagenet',\n",
        "    input_shape= (224,224,3),\n",
        "    pooling= 'avg',\n",
        "    classes= 3,\n",
        ")\n",
        "\n",
        "\n",
        "#Freezing the deeper layers\n",
        "for layer in pretrained_model.layers:\n",
        "        layer.trainable=False\n",
        "\n",
        "#adding our layers to the model\n",
        "cnn_model.add(pretrained_model)\n",
        "cnn_model.add(Flatten())\n",
        "cnn_model.add(Dropout(0.2))\n",
        "cnn_model.add(Dense(256, activation='swish'))\n",
        "cnn_model.add(Dropout(0.2))\n",
        "cnn_model.add(Dense(64, activation='swish'))\n",
        "cnn_model.add(Dropout(0.2))\n",
        "cnn_model.add(Dense(3, activation='softmax'))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zy3fvEem8Jif"
      },
      "outputs": [],
      "source": [
        "early_stopping_cb =  tf.keras.callbacks.EarlyStopping(patience=1000,restore_best_weights=True)\n",
        "lr_scheduler1 = tf.keras.callbacks.ReduceLROnPlateau(factor=0.333, patience=300)\n",
        "checkpoint_cb = tf.keras.callbacks.ModelCheckpoint(\"Bearing_defect_detetcion.keras\",save_best_only=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zUaE16D_CJA-"
      },
      "outputs": [],
      "source": [
        "METRICS = [\n",
        "      keras.metrics.TruePositives(name='tp'),\n",
        "      keras.metrics.TrueNegatives(name='tn'),\n",
        "      keras.metrics.FalsePositives(name='fp'),\n",
        "      keras.metrics.FalseNegatives(name='fn'),\n",
        "      keras.metrics.BinaryAccuracy(name='accuracy'),\n",
        "      keras.metrics.Precision(name='precision'),\n",
        "      keras.metrics.Recall(name='recall'),\n",
        "      keras.metrics.AUC(name='auc'),\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VndX9TUh8ZYB"
      },
      "outputs": [],
      "source": [
        "\n",
        "cnn_model.compile(optimizer='adamw', loss=tf.keras.losses.CategoricalFocalCrossentropy(),metrics=METRICS)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zf6aDu4Z8h17",
        "outputId": "44de4a2b-8fc6-4fd2-f2c9-42845600ae8e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 160ms/step - accuracy: 0.9079 - auc: 0.9672 - fn: 78.3793 - fp: 49.4828 - loss: 0.0287 - precision: 0.8866 - recall: 0.8295 - tn: 906.3793 - tp: 399.5517 - val_accuracy: 0.8205 - val_auc: 0.8492 - val_fn: 71.0000 - val_fp: 48.0000 - val_loss: 0.1628 - val_precision: 0.7576 - val_recall: 0.6787 - val_tn: 394.0000 - val_tp: 150.0000 - learning_rate: 1.1089e-04\n",
            "Epoch 690/2000\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 160ms/step - accuracy: 0.9196 - auc: 0.9739 - fn: 73.7931 - fp: 43.7931 - loss: 0.0243 - precision: 0.9051 - recall: 0.8476 - tn: 912.0690 - tp: 404.1379 - val_accuracy: 0.8084 - val_auc: 0.8519 - val_fn: 71.0000 - val_fp: 56.0000 - val_loss: 0.1610 - val_precision: 0.7282 - val_recall: 0.6787 - val_tn: 386.0000 - val_tp: 150.0000 - learning_rate: 1.1089e-04\n",
            "Epoch 691/2000\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 180ms/step - accuracy: 0.9314 - auc: 0.9782 - fn: 66.7586 - fp: 33.4828 - loss: 0.0223 - precision: 0.9284 - recall: 0.8606 - tn: 922.3793 - tp: 411.1724 - val_accuracy: 0.7964 - val_auc: 0.8476 - val_fn: 75.0000 - val_fp: 60.0000 - val_loss: 0.1641 - val_precision: 0.7087 - val_recall: 0.6606 - val_tn: 382.0000 - val_tp: 146.0000 - learning_rate: 1.1089e-04\n",
            "Epoch 692/2000\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 159ms/step - accuracy: 0.8945 - auc: 0.9615 - fn: 92.2414 - fp: 55.7241 - loss: 0.0301 - precision: 0.8695 - recall: 0.8040 - tn: 900.1379 - tp: 385.6897 - val_accuracy: 0.8175 - val_auc: 0.8482 - val_fn: 72.0000 - val_fp: 49.0000 - val_loss: 0.1627 - val_precision: 0.7525 - val_recall: 0.6742 - val_tn: 393.0000 - val_tp: 149.0000 - learning_rate: 1.1089e-04\n",
            "Epoch 693/2000\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 159ms/step - accuracy: 0.9132 - auc: 0.9737 - fn: 80.1724 - fp: 49.4828 - loss: 0.0239 - precision: 0.8961 - recall: 0.8368 - tn: 906.3793 - tp: 397.7586 - val_accuracy: 0.8205 - val_auc: 0.8486 - val_fn: 68.0000 - val_fp: 51.0000 - val_loss: 0.1644 - val_precision: 0.7500 - val_recall: 0.6923 - val_tn: 391.0000 - val_tp: 153.0000 - learning_rate: 1.1089e-04\n",
            "Epoch 694/2000\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 161ms/step - accuracy: 0.9141 - auc: 0.9747 - fn: 75.3103 - fp: 53.3448 - loss: 0.0227 - precision: 0.8885 - recall: 0.8487 - tn: 902.5172 - tp: 402.6207 - val_accuracy: 0.8130 - val_auc: 0.8495 - val_fn: 71.0000 - val_fp: 53.0000 - val_loss: 0.1643 - val_precision: 0.7389 - val_recall: 0.6787 - val_tn: 389.0000 - val_tp: 150.0000 - learning_rate: 1.1089e-04\n",
            "Epoch 695/2000\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 157ms/step - accuracy: 0.9088 - auc: 0.9715 - fn: 80.7931 - fp: 48.1724 - loss: 0.0247 - precision: 0.8888 - recall: 0.8302 - tn: 907.6896 - tp: 397.1379 - val_accuracy: 0.8235 - val_auc: 0.8531 - val_fn: 68.0000 - val_fp: 49.0000 - val_loss: 0.1625 - val_precision: 0.7574 - val_recall: 0.6923 - val_tn: 393.0000 - val_tp: 153.0000 - learning_rate: 1.1089e-04\n",
            "Epoch 696/2000\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 159ms/step - accuracy: 0.8960 - auc: 0.9698 - fn: 92.4483 - fp: 54.6897 - loss: 0.0256 - precision: 0.8751 - recall: 0.8026 - tn: 901.1724 - tp: 385.4828 - val_accuracy: 0.8069 - val_auc: 0.8456 - val_fn: 76.0000 - val_fp: 52.0000 - val_loss: 0.1633 - val_precision: 0.7360 - val_recall: 0.6561 - val_tn: 390.0000 - val_tp: 145.0000 - learning_rate: 1.1089e-04\n",
            "Epoch 697/2000\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 162ms/step - accuracy: 0.9105 - auc: 0.9689 - fn: 82.2414 - fp: 49.4828 - loss: 0.0258 - precision: 0.8945 - recall: 0.8296 - tn: 906.3793 - tp: 395.6897 - val_accuracy: 0.8160 - val_auc: 0.8509 - val_fn: 69.0000 - val_fp: 53.0000 - val_loss: 0.1663 - val_precision: 0.7415 - val_recall: 0.6878 - val_tn: 389.0000 - val_tp: 152.0000 - learning_rate: 1.1089e-04\n",
            "Epoch 698/2000\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 157ms/step - accuracy: 0.9179 - auc: 0.9733 - fn: 70.4828 - fp: 48.4828 - loss: 0.0238 - precision: 0.8934 - recall: 0.8557 - tn: 907.3793 - tp: 407.4483 - val_accuracy: 0.8069 - val_auc: 0.8485 - val_fn: 73.0000 - val_fp: 55.0000 - val_loss: 0.1649 - val_precision: 0.7291 - val_recall: 0.6697 - val_tn: 387.0000 - val_tp: 148.0000 - learning_rate: 1.1089e-04\n",
            "Epoch 699/2000\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 160ms/step - accuracy: 0.9000 - auc: 0.9647 - fn: 91.3448 - fp: 56.8966 - loss: 0.0276 - precision: 0.8792 - recall: 0.8116 - tn: 898.9655 - tp: 386.5862 - val_accuracy: 0.8175 - val_auc: 0.8497 - val_fn: 69.0000 - val_fp: 52.0000 - val_loss: 0.1683 - val_precision: 0.7451 - val_recall: 0.6878 - val_tn: 390.0000 - val_tp: 152.0000 - learning_rate: 1.1089e-04\n",
            "Epoch 700/2000\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 163ms/step - accuracy: 0.9174 - auc: 0.9747 - fn: 75.2759 - fp: 49.2759 - loss: 0.0231 - precision: 0.9005 - recall: 0.8457 - tn: 906.5862 - tp: 402.6552 - val_accuracy: 0.8250 - val_auc: 0.8493 - val_fn: 65.0000 - val_fp: 51.0000 - val_loss: 0.1695 - val_precision: 0.7536 - val_recall: 0.7059 - val_tn: 391.0000 - val_tp: 156.0000 - learning_rate: 1.1089e-04\n",
            "Epoch 701/2000\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 175ms/step - accuracy: 0.9084 - auc: 0.9713 - fn: 79.5862 - fp: 51.0000 - loss: 0.0256 - precision: 0.8869 - recall: 0.8312 - tn: 904.8621 - tp: 398.3448 - val_accuracy: 0.8145 - val_auc: 0.8511 - val_fn: 71.0000 - val_fp: 52.0000 - val_loss: 0.1661 - val_precision: 0.7426 - val_recall: 0.6787 - val_tn: 390.0000 - val_tp: 150.0000 - learning_rate: 1.1089e-04\n",
            "Epoch 702/2000\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 174ms/step - accuracy: 0.9146 - auc: 0.9743 - fn: 75.5172 - fp: 45.4483 - loss: 0.0225 - precision: 0.8974 - recall: 0.8397 - tn: 910.4138 - tp: 402.4138 - val_accuracy: 0.8160 - val_auc: 0.8494 - val_fn: 69.0000 - val_fp: 53.0000 - val_loss: 0.1715 - val_precision: 0.7415 - val_recall: 0.6878 - val_tn: 389.0000 - val_tp: 152.0000 - learning_rate: 1.1089e-04\n",
            "Epoch 703/2000\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 177ms/step - accuracy: 0.9137 - auc: 0.9720 - fn: 74.7241 - fp: 49.5517 - loss: 0.0246 - precision: 0.8915 - recall: 0.8437 - tn: 906.3104 - tp: 403.2069 - val_accuracy: 0.8160 - val_auc: 0.8506 - val_fn: 69.0000 - val_fp: 53.0000 - val_loss: 0.1674 - val_precision: 0.7415 - val_recall: 0.6878 - val_tn: 389.0000 - val_tp: 152.0000 - learning_rate: 1.1089e-04\n",
            "Epoch 704/2000\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 159ms/step - accuracy: 0.9157 - auc: 0.9750 - fn: 74.3793 - fp: 45.9310 - loss: 0.0230 - precision: 0.8955 - recall: 0.8461 - tn: 909.9310 - tp: 403.5517 - val_accuracy: 0.8190 - val_auc: 0.8507 - val_fn: 68.0000 - val_fp: 52.0000 - val_loss: 0.1701 - val_precision: 0.7463 - val_recall: 0.6923 - val_tn: 390.0000 - val_tp: 153.0000 - learning_rate: 1.1089e-04\n",
            "Epoch 705/2000\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 161ms/step - accuracy: 0.9242 - auc: 0.9799 - fn: 72.8966 - fp: 39.5172 - loss: 0.0217 - precision: 0.9206 - recall: 0.8458 - tn: 916.3448 - tp: 405.0345 - val_accuracy: 0.8130 - val_auc: 0.8493 - val_fn: 71.0000 - val_fp: 53.0000 - val_loss: 0.1706 - val_precision: 0.7389 - val_recall: 0.6787 - val_tn: 389.0000 - val_tp: 150.0000 - learning_rate: 1.1089e-04\n",
            "Epoch 706/2000\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 163ms/step - accuracy: 0.9104 - auc: 0.9711 - fn: 77.4483 - fp: 55.0345 - loss: 0.0250 - precision: 0.8832 - recall: 0.8426 - tn: 900.8276 - tp: 400.4828 - val_accuracy: 0.8130 - val_auc: 0.8498 - val_fn: 70.0000 - val_fp: 54.0000 - val_loss: 0.1708 - val_precision: 0.7366 - val_recall: 0.6833 - val_tn: 388.0000 - val_tp: 151.0000 - learning_rate: 1.1089e-04\n",
            "Epoch 707/2000\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 158ms/step - accuracy: 0.9040 - auc: 0.9723 - fn: 82.9310 - fp: 54.1379 - loss: 0.0239 - precision: 0.8772 - recall: 0.8277 - tn: 901.7241 - tp: 395.0000 - val_accuracy: 0.8115 - val_auc: 0.8488 - val_fn: 71.0000 - val_fp: 54.0000 - val_loss: 0.1693 - val_precision: 0.7353 - val_recall: 0.6787 - val_tn: 388.0000 - val_tp: 150.0000 - learning_rate: 1.1089e-04\n",
            "Epoch 708/2000\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 175ms/step - accuracy: 0.9003 - auc: 0.9689 - fn: 84.0690 - fp: 56.2759 - loss: 0.0246 - precision: 0.8716 - recall: 0.8220 - tn: 899.5862 - tp: 393.8621 - val_accuracy: 0.8115 - val_auc: 0.8521 - val_fn: 70.0000 - val_fp: 55.0000 - val_loss: 0.1682 - val_precision: 0.7330 - val_recall: 0.6833 - val_tn: 387.0000 - val_tp: 151.0000 - learning_rate: 1.1089e-04\n",
            "Epoch 709/2000\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 176ms/step - accuracy: 0.9171 - auc: 0.9729 - fn: 73.0690 - fp: 46.2069 - loss: 0.0269 - precision: 0.8990 - recall: 0.8463 - tn: 909.6552 - tp: 404.8621 - val_accuracy: 0.8100 - val_auc: 0.8466 - val_fn: 72.0000 - val_fp: 54.0000 - val_loss: 0.1693 - val_precision: 0.7340 - val_recall: 0.6742 - val_tn: 388.0000 - val_tp: 149.0000 - learning_rate: 1.1089e-04\n",
            "Epoch 710/2000\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 174ms/step - accuracy: 0.9190 - auc: 0.9728 - fn: 74.2414 - fp: 46.5172 - loss: 0.0246 - precision: 0.9001 - recall: 0.8513 - tn: 909.3448 - tp: 403.6897 - val_accuracy: 0.8130 - val_auc: 0.8483 - val_fn: 71.0000 - val_fp: 53.0000 - val_loss: 0.1652 - val_precision: 0.7389 - val_recall: 0.6787 - val_tn: 389.0000 - val_tp: 150.0000 - learning_rate: 1.1089e-04\n",
            "Epoch 711/2000\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 175ms/step - accuracy: 0.9188 - auc: 0.9750 - fn: 72.8276 - fp: 44.3103 - loss: 0.0223 - precision: 0.9035 - recall: 0.8466 - tn: 911.5517 - tp: 405.1035 - val_accuracy: 0.8175 - val_auc: 0.8482 - val_fn: 70.0000 - val_fp: 51.0000 - val_loss: 0.1672 - val_precision: 0.7475 - val_recall: 0.6833 - val_tn: 391.0000 - val_tp: 151.0000 - learning_rate: 1.1089e-04\n",
            "Epoch 712/2000\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 178ms/step - accuracy: 0.9089 - auc: 0.9702 - fn: 84.7241 - fp: 50.3103 - loss: 0.0244 - precision: 0.8882 - recall: 0.8312 - tn: 905.5517 - tp: 393.2069 - val_accuracy: 0.8115 - val_auc: 0.8505 - val_fn: 70.0000 - val_fp: 55.0000 - val_loss: 0.1640 - val_precision: 0.7330 - val_recall: 0.6833 - val_tn: 387.0000 - val_tp: 151.0000 - learning_rate: 1.1089e-04\n",
            "Epoch 713/2000\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 158ms/step - accuracy: 0.9073 - auc: 0.9723 - fn: 81.0690 - fp: 45.2414 - loss: 0.0249 - precision: 0.8905 - recall: 0.8232 - tn: 910.6207 - tp: 396.8621 - val_accuracy: 0.8009 - val_auc: 0.8478 - val_fn: 72.0000 - val_fp: 60.0000 - val_loss: 0.1674 - val_precision: 0.7129 - val_recall: 0.6742 - val_tn: 382.0000 - val_tp: 149.0000 - learning_rate: 1.1089e-04\n",
            "Epoch 714/2000\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 161ms/step - accuracy: 0.9188 - auc: 0.9773 - fn: 70.4483 - fp: 47.3103 - loss: 0.0214 - precision: 0.8986 - recall: 0.8525 - tn: 908.5517 - tp: 407.4828 - val_accuracy: 0.8024 - val_auc: 0.8487 - val_fn: 74.0000 - val_fp: 57.0000 - val_loss: 0.1700 - val_precision: 0.7206 - val_recall: 0.6652 - val_tn: 385.0000 - val_tp: 147.0000 - learning_rate: 1.1089e-04\n",
            "Epoch 715/2000\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 161ms/step - accuracy: 0.9125 - auc: 0.9708 - fn: 77.8276 - fp: 50.8621 - loss: 0.0259 - precision: 0.8910 - recall: 0.8404 - tn: 905.0000 - tp: 400.1035 - val_accuracy: 0.8115 - val_auc: 0.8505 - val_fn: 70.0000 - val_fp: 55.0000 - val_loss: 0.1690 - val_precision: 0.7330 - val_recall: 0.6833 - val_tn: 387.0000 - val_tp: 151.0000 - learning_rate: 1.1089e-04\n",
            "Epoch 716/2000\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 158ms/step - accuracy: 0.9095 - auc: 0.9754 - fn: 78.2759 - fp: 50.2414 - loss: 0.0220 - precision: 0.8879 - recall: 0.8336 - tn: 905.6207 - tp: 399.6552 - val_accuracy: 0.8039 - val_auc: 0.8463 - val_fn: 76.0000 - val_fp: 54.0000 - val_loss: 0.1697 - val_precision: 0.7286 - val_recall: 0.6561 - val_tn: 388.0000 - val_tp: 145.0000 - learning_rate: 1.1089e-04\n",
            "Epoch 717/2000\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 176ms/step - accuracy: 0.9113 - auc: 0.9717 - fn: 80.2759 - fp: 43.0345 - loss: 0.0246 - precision: 0.8978 - recall: 0.8283 - tn: 912.8276 - tp: 397.6552 - val_accuracy: 0.7979 - val_auc: 0.8450 - val_fn: 75.0000 - val_fp: 59.0000 - val_loss: 0.1718 - val_precision: 0.7122 - val_recall: 0.6606 - val_tn: 383.0000 - val_tp: 146.0000 - learning_rate: 1.1089e-04\n",
            "Epoch 718/2000\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 174ms/step - accuracy: 0.9216 - auc: 0.9734 - fn: 74.3103 - fp: 46.5172 - loss: 0.0237 - precision: 0.9046 - recall: 0.8547 - tn: 909.3448 - tp: 403.6207 - val_accuracy: 0.8069 - val_auc: 0.8428 - val_fn: 73.0000 - val_fp: 55.0000 - val_loss: 0.1745 - val_precision: 0.7291 - val_recall: 0.6697 - val_tn: 387.0000 - val_tp: 148.0000 - learning_rate: 1.1089e-04\n",
            "Epoch 719/2000\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 174ms/step - accuracy: 0.9212 - auc: 0.9771 - fn: 75.5862 - fp: 45.6207 - loss: 0.0220 - precision: 0.9059 - recall: 0.8519 - tn: 910.2414 - tp: 402.3448 - val_accuracy: 0.8084 - val_auc: 0.8431 - val_fn: 73.0000 - val_fp: 54.0000 - val_loss: 0.1716 - val_precision: 0.7327 - val_recall: 0.6697 - val_tn: 388.0000 - val_tp: 148.0000 - learning_rate: 1.1089e-04\n",
            "Epoch 720/2000\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 164ms/step - accuracy: 0.9130 - auc: 0.9709 - fn: 79.2069 - fp: 55.1724 - loss: 0.0253 - precision: 0.8870 - recall: 0.8466 - tn: 900.6896 - tp: 398.7242 - val_accuracy: 0.8145 - val_auc: 0.8504 - val_fn: 71.0000 - val_fp: 52.0000 - val_loss: 0.1688 - val_precision: 0.7426 - val_recall: 0.6787 - val_tn: 390.0000 - val_tp: 150.0000 - learning_rate: 1.1089e-04\n",
            "Epoch 721/2000\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 175ms/step - accuracy: 0.9150 - auc: 0.9778 - fn: 75.3793 - fp: 48.0345 - loss: 0.0228 - precision: 0.8938 - recall: 0.8457 - tn: 907.8276 - tp: 402.5517 - val_accuracy: 0.8145 - val_auc: 0.8510 - val_fn: 70.0000 - val_fp: 53.0000 - val_loss: 0.1692 - val_precision: 0.7402 - val_recall: 0.6833 - val_tn: 389.0000 - val_tp: 151.0000 - learning_rate: 1.1089e-04\n",
            "Epoch 722/2000\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 174ms/step - accuracy: 0.9117 - auc: 0.9737 - fn: 83.6207 - fp: 49.0000 - loss: 0.0246 - precision: 0.8944 - recall: 0.8334 - tn: 906.8621 - tp: 394.3103 - val_accuracy: 0.8190 - val_auc: 0.8529 - val_fn: 70.0000 - val_fp: 50.0000 - val_loss: 0.1678 - val_precision: 0.7512 - val_recall: 0.6833 - val_tn: 392.0000 - val_tp: 151.0000 - learning_rate: 1.1089e-04\n",
            "Epoch 723/2000\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 163ms/step - accuracy: 0.8982 - auc: 0.9700 - fn: 84.9310 - fp: 51.2414 - loss: 0.0249 - precision: 0.8751 - recall: 0.8100 - tn: 904.6207 - tp: 393.0000 - val_accuracy: 0.8145 - val_auc: 0.8550 - val_fn: 71.0000 - val_fp: 52.0000 - val_loss: 0.1670 - val_precision: 0.7426 - val_recall: 0.6787 - val_tn: 390.0000 - val_tp: 150.0000 - learning_rate: 1.1089e-04\n",
            "Epoch 724/2000\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 175ms/step - accuracy: 0.8990 - auc: 0.9626 - fn: 88.1379 - fp: 52.4138 - loss: 0.0302 - precision: 0.8795 - recall: 0.8076 - tn: 903.4483 - tp: 389.7931 - val_accuracy: 0.8069 - val_auc: 0.8497 - val_fn: 73.0000 - val_fp: 55.0000 - val_loss: 0.1671 - val_precision: 0.7291 - val_recall: 0.6697 - val_tn: 387.0000 - val_tp: 148.0000 - learning_rate: 1.1089e-04\n",
            "Epoch 725/2000\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 174ms/step - accuracy: 0.9205 - auc: 0.9721 - fn: 74.3448 - fp: 47.9655 - loss: 0.0254 - precision: 0.9034 - recall: 0.8527 - tn: 907.8965 - tp: 403.5862 - val_accuracy: 0.8220 - val_auc: 0.8478 - val_fn: 69.0000 - val_fp: 49.0000 - val_loss: 0.1694 - val_precision: 0.7562 - val_recall: 0.6878 - val_tn: 393.0000 - val_tp: 152.0000 - learning_rate: 1.1089e-04\n",
            "Epoch 726/2000\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 179ms/step - accuracy: 0.8933 - auc: 0.9595 - fn: 89.1034 - fp: 52.7241 - loss: 0.0312 - precision: 0.8718 - recall: 0.7969 - tn: 903.1379 - tp: 388.8276 - val_accuracy: 0.8145 - val_auc: 0.8479 - val_fn: 71.0000 - val_fp: 52.0000 - val_loss: 0.1659 - val_precision: 0.7426 - val_recall: 0.6787 - val_tn: 390.0000 - val_tp: 150.0000 - learning_rate: 1.1089e-04\n",
            "Epoch 727/2000\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 175ms/step - accuracy: 0.9185 - auc: 0.9743 - fn: 74.7586 - fp: 45.6897 - loss: 0.0236 - precision: 0.9011 - recall: 0.8487 - tn: 910.1724 - tp: 403.1724 - val_accuracy: 0.8160 - val_auc: 0.8515 - val_fn: 69.0000 - val_fp: 53.0000 - val_loss: 0.1655 - val_precision: 0.7415 - val_recall: 0.6878 - val_tn: 389.0000 - val_tp: 152.0000 - learning_rate: 1.1089e-04\n",
            "Epoch 728/2000\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 177ms/step - accuracy: 0.9074 - auc: 0.9698 - fn: 81.9655 - fp: 48.8621 - loss: 0.0263 - precision: 0.8897 - recall: 0.8245 - tn: 907.0000 - tp: 395.9655 - val_accuracy: 0.8130 - val_auc: 0.8479 - val_fn: 71.0000 - val_fp: 53.0000 - val_loss: 0.1677 - val_precision: 0.7389 - val_recall: 0.6787 - val_tn: 389.0000 - val_tp: 150.0000 - learning_rate: 1.1089e-04\n",
            "Epoch 729/2000\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 180ms/step - accuracy: 0.9157 - auc: 0.9747 - fn: 72.8276 - fp: 45.7241 - loss: 0.0237 - precision: 0.8965 - recall: 0.8448 - tn: 910.1379 - tp: 405.1035 - val_accuracy: 0.8024 - val_auc: 0.8459 - val_fn: 74.0000 - val_fp: 57.0000 - val_loss: 0.1681 - val_precision: 0.7206 - val_recall: 0.6652 - val_tn: 385.0000 - val_tp: 147.0000 - learning_rate: 1.1089e-04\n",
            "Epoch 730/2000\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 158ms/step - accuracy: 0.9060 - auc: 0.9683 - fn: 84.5517 - fp: 56.3793 - loss: 0.0277 - precision: 0.8807 - recall: 0.8305 - tn: 899.4828 - tp: 393.3793 - val_accuracy: 0.8069 - val_auc: 0.8476 - val_fn: 73.0000 - val_fp: 55.0000 - val_loss: 0.1629 - val_precision: 0.7291 - val_recall: 0.6697 - val_tn: 387.0000 - val_tp: 148.0000 - learning_rate: 1.1089e-04\n",
            "Epoch 731/2000\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 159ms/step - accuracy: 0.9085 - auc: 0.9740 - fn: 79.0345 - fp: 50.0345 - loss: 0.0234 - precision: 0.8846 - recall: 0.8342 - tn: 905.8276 - tp: 398.8965 - val_accuracy: 0.8084 - val_auc: 0.8509 - val_fn: 74.0000 - val_fp: 53.0000 - val_loss: 0.1623 - val_precision: 0.7350 - val_recall: 0.6652 - val_tn: 389.0000 - val_tp: 147.0000 - learning_rate: 1.1089e-04\n",
            "Epoch 732/2000\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 163ms/step - accuracy: 0.9160 - auc: 0.9752 - fn: 77.6897 - fp: 48.2759 - loss: 0.0237 - precision: 0.8995 - recall: 0.8421 - tn: 907.5862 - tp: 400.2414 - val_accuracy: 0.8115 - val_auc: 0.8515 - val_fn: 72.0000 - val_fp: 53.0000 - val_loss: 0.1665 - val_precision: 0.7376 - val_recall: 0.6742 - val_tn: 389.0000 - val_tp: 149.0000 - learning_rate: 1.1089e-04\n",
            "Epoch 733/2000\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 160ms/step - accuracy: 0.9138 - auc: 0.9763 - fn: 74.0345 - fp: 45.7931 - loss: 0.0221 - precision: 0.8959 - recall: 0.8389 - tn: 910.0690 - tp: 403.8965 - val_accuracy: 0.8024 - val_auc: 0.8497 - val_fn: 75.0000 - val_fp: 56.0000 - val_loss: 0.1670 - val_precision: 0.7228 - val_recall: 0.6606 - val_tn: 386.0000 - val_tp: 146.0000 - learning_rate: 1.1089e-04\n",
            "Epoch 734/2000\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 158ms/step - accuracy: 0.9250 - auc: 0.9763 - fn: 72.1034 - fp: 39.9655 - loss: 0.0228 - precision: 0.9171 - recall: 0.8520 - tn: 915.8965 - tp: 405.8276 - val_accuracy: 0.8100 - val_auc: 0.8521 - val_fn: 72.0000 - val_fp: 54.0000 - val_loss: 0.1672 - val_precision: 0.7340 - val_recall: 0.6742 - val_tn: 388.0000 - val_tp: 149.0000 - learning_rate: 1.1089e-04\n",
            "Epoch 735/2000\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 162ms/step - accuracy: 0.9063 - auc: 0.9694 - fn: 78.1724 - fp: 55.4483 - loss: 0.0257 - precision: 0.8779 - recall: 0.8352 - tn: 900.4138 - tp: 399.7586 - val_accuracy: 0.8084 - val_auc: 0.8447 - val_fn: 72.0000 - val_fp: 55.0000 - val_loss: 0.1676 - val_precision: 0.7304 - val_recall: 0.6742 - val_tn: 387.0000 - val_tp: 149.0000 - learning_rate: 1.1089e-04\n",
            "Epoch 736/2000\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 177ms/step - accuracy: 0.9197 - auc: 0.9747 - fn: 74.9310 - fp: 44.2414 - loss: 0.0234 - precision: 0.9076 - recall: 0.8454 - tn: 911.6207 - tp: 403.0000 - val_accuracy: 0.8054 - val_auc: 0.8470 - val_fn: 74.0000 - val_fp: 55.0000 - val_loss: 0.1743 - val_precision: 0.7277 - val_recall: 0.6652 - val_tn: 387.0000 - val_tp: 147.0000 - learning_rate: 1.1089e-04\n",
            "Epoch 737/2000\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 174ms/step - accuracy: 0.9205 - auc: 0.9777 - fn: 74.8276 - fp: 47.5862 - loss: 0.0225 - precision: 0.9025 - recall: 0.8535 - tn: 908.2759 - tp: 403.1035 - val_accuracy: 0.8084 - val_auc: 0.8466 - val_fn: 72.0000 - val_fp: 55.0000 - val_loss: 0.1759 - val_precision: 0.7304 - val_recall: 0.6742 - val_tn: 387.0000 - val_tp: 149.0000 - learning_rate: 1.1089e-04\n",
            "Epoch 738/2000\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 175ms/step - accuracy: 0.9135 - auc: 0.9741 - fn: 79.2759 - fp: 51.3103 - loss: 0.0242 - precision: 0.8930 - recall: 0.8412 - tn: 904.5517 - tp: 398.6552 - val_accuracy: 0.8084 - val_auc: 0.8475 - val_fn: 72.0000 - val_fp: 55.0000 - val_loss: 0.1701 - val_precision: 0.7304 - val_recall: 0.6742 - val_tn: 387.0000 - val_tp: 149.0000 - learning_rate: 1.1089e-04\n",
            "Epoch 739/2000\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 160ms/step - accuracy: 0.9077 - auc: 0.9732 - fn: 81.0690 - fp: 50.0690 - loss: 0.0257 - precision: 0.8842 - recall: 0.8322 - tn: 905.7931 - tp: 396.8621 - val_accuracy: 0.8175 - val_auc: 0.8504 - val_fn: 68.0000 - val_fp: 53.0000 - val_loss: 0.1669 - val_precision: 0.7427 - val_recall: 0.6923 - val_tn: 389.0000 - val_tp: 153.0000 - learning_rate: 1.1089e-04\n",
            "Epoch 740/2000\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 158ms/step - accuracy: 0.9119 - auc: 0.9756 - fn: 77.3103 - fp: 48.1379 - loss: 0.0232 - precision: 0.8920 - recall: 0.8371 - tn: 907.7241 - tp: 400.6207 - val_accuracy: 0.8190 - val_auc: 0.8523 - val_fn: 67.0000 - val_fp: 53.0000 - val_loss: 0.1679 - val_precision: 0.7440 - val_recall: 0.6968 - val_tn: 389.0000 - val_tp: 154.0000 - learning_rate: 1.1089e-04\n",
            "Epoch 741/2000\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 163ms/step - accuracy: 0.9084 - auc: 0.9739 - fn: 83.2414 - fp: 47.6897 - loss: 0.0238 - precision: 0.8934 - recall: 0.8237 - tn: 908.1724 - tp: 394.6897 - val_accuracy: 0.8220 - val_auc: 0.8508 - val_fn: 68.0000 - val_fp: 50.0000 - val_loss: 0.1660 - val_precision: 0.7537 - val_recall: 0.6923 - val_tn: 392.0000 - val_tp: 153.0000 - learning_rate: 1.1089e-04\n",
            "Epoch 742/2000\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 176ms/step - accuracy: 0.9027 - auc: 0.9711 - fn: 80.4483 - fp: 50.2069 - loss: 0.0256 - precision: 0.8786 - recall: 0.8219 - tn: 905.6552 - tp: 397.4828 - val_accuracy: 0.8175 - val_auc: 0.8498 - val_fn: 69.0000 - val_fp: 52.0000 - val_loss: 0.1673 - val_precision: 0.7451 - val_recall: 0.6878 - val_tn: 390.0000 - val_tp: 152.0000 - learning_rate: 1.1089e-04\n",
            "Epoch 743/2000\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 174ms/step - accuracy: 0.9109 - auc: 0.9705 - fn: 77.3448 - fp: 48.6207 - loss: 0.0269 - precision: 0.8887 - recall: 0.8377 - tn: 907.2414 - tp: 400.5862 - val_accuracy: 0.8190 - val_auc: 0.8532 - val_fn: 68.0000 - val_fp: 52.0000 - val_loss: 0.1618 - val_precision: 0.7463 - val_recall: 0.6923 - val_tn: 390.0000 - val_tp: 153.0000 - learning_rate: 1.1089e-04\n",
            "Epoch 744/2000\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 163ms/step - accuracy: 0.9201 - auc: 0.9741 - fn: 70.4828 - fp: 47.8966 - loss: 0.0239 - precision: 0.8954 - recall: 0.8609 - tn: 907.9655 - tp: 407.4483 - val_accuracy: 0.8250 - val_auc: 0.8535 - val_fn: 65.0000 - val_fp: 51.0000 - val_loss: 0.1646 - val_precision: 0.7536 - val_recall: 0.7059 - val_tn: 391.0000 - val_tp: 156.0000 - learning_rate: 1.1089e-04\n",
            "Epoch 745/2000\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 176ms/step - accuracy: 0.9327 - auc: 0.9796 - fn: 65.2759 - fp: 33.5862 - loss: 0.0210 - precision: 0.9286 - recall: 0.8646 - tn: 922.2759 - tp: 412.6552 - val_accuracy: 0.8145 - val_auc: 0.8526 - val_fn: 69.0000 - val_fp: 54.0000 - val_loss: 0.1657 - val_precision: 0.7379 - val_recall: 0.6878 - val_tn: 388.0000 - val_tp: 152.0000 - learning_rate: 1.1089e-04\n",
            "Epoch 746/2000\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 158ms/step - accuracy: 0.9200 - auc: 0.9779 - fn: 69.1034 - fp: 46.4138 - loss: 0.0222 - precision: 0.8986 - recall: 0.8567 - tn: 909.4483 - tp: 408.8276 - val_accuracy: 0.8235 - val_auc: 0.8508 - val_fn: 67.0000 - val_fp: 50.0000 - val_loss: 0.1696 - val_precision: 0.7549 - val_recall: 0.6968 - val_tn: 392.0000 - val_tp: 154.0000 - learning_rate: 1.1089e-04\n",
            "Epoch 747/2000\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 162ms/step - accuracy: 0.9126 - auc: 0.9725 - fn: 76.6207 - fp: 46.6207 - loss: 0.0252 - precision: 0.8961 - recall: 0.8346 - tn: 909.2414 - tp: 401.3103 - val_accuracy: 0.8130 - val_auc: 0.8509 - val_fn: 70.0000 - val_fp: 54.0000 - val_loss: 0.1689 - val_precision: 0.7366 - val_recall: 0.6833 - val_tn: 388.0000 - val_tp: 151.0000 - learning_rate: 1.1089e-04\n",
            "Epoch 748/2000\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 161ms/step - accuracy: 0.9100 - auc: 0.9740 - fn: 77.2069 - fp: 45.9310 - loss: 0.0232 - precision: 0.8916 - recall: 0.8309 - tn: 909.9310 - tp: 400.7242 - val_accuracy: 0.8084 - val_auc: 0.8517 - val_fn: 70.0000 - val_fp: 57.0000 - val_loss: 0.1676 - val_precision: 0.7260 - val_recall: 0.6833 - val_tn: 385.0000 - val_tp: 151.0000 - learning_rate: 1.1089e-04\n",
            "Epoch 749/2000\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 158ms/step - accuracy: 0.9192 - auc: 0.9758 - fn: 77.9655 - fp: 45.5517 - loss: 0.0223 - precision: 0.9043 - recall: 0.8472 - tn: 910.3104 - tp: 399.9655 - val_accuracy: 0.8190 - val_auc: 0.8490 - val_fn: 68.0000 - val_fp: 52.0000 - val_loss: 0.1678 - val_precision: 0.7463 - val_recall: 0.6923 - val_tn: 390.0000 - val_tp: 153.0000 - learning_rate: 1.1089e-04\n",
            "Epoch 750/2000\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 177ms/step - accuracy: 0.9014 - auc: 0.9686 - fn: 82.7931 - fp: 53.7586 - loss: 0.0262 - precision: 0.8767 - recall: 0.8195 - tn: 902.1035 - tp: 395.1379 - val_accuracy: 0.8145 - val_auc: 0.8487 - val_fn: 71.0000 - val_fp: 52.0000 - val_loss: 0.1739 - val_precision: 0.7426 - val_recall: 0.6787 - val_tn: 390.0000 - val_tp: 150.0000 - learning_rate: 1.1089e-04\n",
            "Epoch 751/2000\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 159ms/step - accuracy: 0.9123 - auc: 0.9707 - fn: 76.1034 - fp: 48.8966 - loss: 0.0255 - precision: 0.8906 - recall: 0.8402 - tn: 906.9655 - tp: 401.8276 - val_accuracy: 0.8235 - val_auc: 0.8530 - val_fn: 65.0000 - val_fp: 52.0000 - val_loss: 0.1702 - val_precision: 0.7500 - val_recall: 0.7059 - val_tn: 390.0000 - val_tp: 156.0000 - learning_rate: 1.1089e-04\n",
            "Epoch 752/2000\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 157ms/step - accuracy: 0.9193 - auc: 0.9755 - fn: 73.3103 - fp: 45.7586 - loss: 0.0230 - precision: 0.9004 - recall: 0.8522 - tn: 910.1035 - tp: 404.6207 - val_accuracy: 0.8220 - val_auc: 0.8513 - val_fn: 66.0000 - val_fp: 52.0000 - val_loss: 0.1694 - val_precision: 0.7488 - val_recall: 0.7014 - val_tn: 390.0000 - val_tp: 155.0000 - learning_rate: 1.1089e-04\n",
            "Epoch 753/2000\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 176ms/step - accuracy: 0.9225 - auc: 0.9795 - fn: 67.8621 - fp: 42.3103 - loss: 0.0209 - precision: 0.9045 - recall: 0.8581 - tn: 913.5517 - tp: 410.0690 - val_accuracy: 0.8145 - val_auc: 0.8499 - val_fn: 70.0000 - val_fp: 53.0000 - val_loss: 0.1699 - val_precision: 0.7402 - val_recall: 0.6833 - val_tn: 389.0000 - val_tp: 151.0000 - learning_rate: 1.1089e-04\n",
            "Epoch 754/2000\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 161ms/step - accuracy: 0.9173 - auc: 0.9769 - fn: 73.6552 - fp: 40.6207 - loss: 0.0232 - precision: 0.9049 - recall: 0.8402 - tn: 915.2414 - tp: 404.2758 - val_accuracy: 0.8190 - val_auc: 0.8515 - val_fn: 68.0000 - val_fp: 52.0000 - val_loss: 0.1672 - val_precision: 0.7463 - val_recall: 0.6923 - val_tn: 390.0000 - val_tp: 153.0000 - learning_rate: 1.1089e-04\n",
            "Epoch 755/2000\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 157ms/step - accuracy: 0.9101 - auc: 0.9693 - fn: 78.6207 - fp: 44.2759 - loss: 0.0255 - precision: 0.8964 - recall: 0.8256 - tn: 911.5862 - tp: 399.3103 - val_accuracy: 0.8235 - val_auc: 0.8520 - val_fn: 65.0000 - val_fp: 52.0000 - val_loss: 0.1665 - val_precision: 0.7500 - val_recall: 0.7059 - val_tn: 390.0000 - val_tp: 156.0000 - learning_rate: 1.1089e-04\n",
            "Epoch 756/2000\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 175ms/step - accuracy: 0.9226 - auc: 0.9760 - fn: 70.5172 - fp: 45.4483 - loss: 0.0232 - precision: 0.9045 - recall: 0.8584 - tn: 910.4138 - tp: 407.4138 - val_accuracy: 0.8175 - val_auc: 0.8515 - val_fn: 67.0000 - val_fp: 54.0000 - val_loss: 0.1666 - val_precision: 0.7404 - val_recall: 0.6968 - val_tn: 388.0000 - val_tp: 154.0000 - learning_rate: 1.1089e-04\n",
            "Epoch 757/2000\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 162ms/step - accuracy: 0.9114 - auc: 0.9751 - fn: 79.6552 - fp: 50.6207 - loss: 0.0232 - precision: 0.8908 - recall: 0.8369 - tn: 905.2414 - tp: 398.2758 - val_accuracy: 0.8100 - val_auc: 0.8532 - val_fn: 70.0000 - val_fp: 56.0000 - val_loss: 0.1654 - val_precision: 0.7295 - val_recall: 0.6833 - val_tn: 386.0000 - val_tp: 151.0000 - learning_rate: 1.1089e-04\n",
            "Epoch 758/2000\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 158ms/step - accuracy: 0.9124 - auc: 0.9736 - fn: 75.5172 - fp: 50.7931 - loss: 0.0237 - precision: 0.8891 - recall: 0.8424 - tn: 905.0690 - tp: 402.4138 - val_accuracy: 0.8190 - val_auc: 0.8516 - val_fn: 68.0000 - val_fp: 52.0000 - val_loss: 0.1655 - val_precision: 0.7463 - val_recall: 0.6923 - val_tn: 390.0000 - val_tp: 153.0000 - learning_rate: 1.1089e-04\n",
            "Epoch 759/2000\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 174ms/step - accuracy: 0.9130 - auc: 0.9731 - fn: 75.2759 - fp: 46.9310 - loss: 0.0235 - precision: 0.8936 - recall: 0.8387 - tn: 908.9310 - tp: 402.6552 - val_accuracy: 0.8250 - val_auc: 0.8529 - val_fn: 63.0000 - val_fp: 53.0000 - val_loss: 0.1679 - val_precision: 0.7488 - val_recall: 0.7149 - val_tn: 389.0000 - val_tp: 158.0000 - learning_rate: 1.1089e-04\n",
            "Epoch 760/2000\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 177ms/step - accuracy: 0.9049 - auc: 0.9678 - fn: 81.3103 - fp: 49.9655 - loss: 0.0272 - precision: 0.8815 - recall: 0.8258 - tn: 905.8965 - tp: 396.6207 - val_accuracy: 0.8054 - val_auc: 0.8492 - val_fn: 71.0000 - val_fp: 58.0000 - val_loss: 0.1672 - val_precision: 0.7212 - val_recall: 0.6787 - val_tn: 384.0000 - val_tp: 150.0000 - learning_rate: 1.1089e-04\n",
            "Epoch 761/2000\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 175ms/step - accuracy: 0.9238 - auc: 0.9784 - fn: 73.3448 - fp: 38.8966 - loss: 0.0216 - precision: 0.9132 - recall: 0.8525 - tn: 916.9655 - tp: 404.5862 - val_accuracy: 0.8115 - val_auc: 0.8470 - val_fn: 71.0000 - val_fp: 54.0000 - val_loss: 0.1699 - val_precision: 0.7353 - val_recall: 0.6787 - val_tn: 388.0000 - val_tp: 150.0000 - learning_rate: 1.1089e-04\n",
            "Epoch 762/2000\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 175ms/step - accuracy: 0.9154 - auc: 0.9719 - fn: 79.0000 - fp: 49.4138 - loss: 0.0252 - precision: 0.8985 - recall: 0.8414 - tn: 906.4483 - tp: 398.9310 - val_accuracy: 0.8115 - val_auc: 0.8531 - val_fn: 66.0000 - val_fp: 59.0000 - val_loss: 0.1669 - val_precision: 0.7243 - val_recall: 0.7014 - val_tn: 383.0000 - val_tp: 155.0000 - learning_rate: 1.1089e-04\n",
            "Epoch 763/2000\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 177ms/step - accuracy: 0.9115 - auc: 0.9737 - fn: 75.2414 - fp: 49.6897 - loss: 0.0237 - precision: 0.8865 - recall: 0.8426 - tn: 906.1724 - tp: 402.6897 - val_accuracy: 0.8145 - val_auc: 0.8510 - val_fn: 68.0000 - val_fp: 55.0000 - val_loss: 0.1665 - val_precision: 0.7356 - val_recall: 0.6923 - val_tn: 387.0000 - val_tp: 153.0000 - learning_rate: 1.1089e-04\n",
            "Epoch 764/2000\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 174ms/step - accuracy: 0.9087 - auc: 0.9717 - fn: 83.5172 - fp: 43.8621 - loss: 0.0262 - precision: 0.8974 - recall: 0.8198 - tn: 912.0000 - tp: 394.4138 - val_accuracy: 0.8175 - val_auc: 0.8533 - val_fn: 68.0000 - val_fp: 53.0000 - val_loss: 0.1680 - val_precision: 0.7427 - val_recall: 0.6923 - val_tn: 389.0000 - val_tp: 153.0000 - learning_rate: 1.1089e-04\n",
            "Epoch 765/2000\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 162ms/step - accuracy: 0.9102 - auc: 0.9713 - fn: 81.0345 - fp: 50.1724 - loss: 0.0274 - precision: 0.8876 - recall: 0.8364 - tn: 905.6896 - tp: 396.8965 - val_accuracy: 0.8069 - val_auc: 0.8456 - val_fn: 71.0000 - val_fp: 57.0000 - val_loss: 0.1754 - val_precision: 0.7246 - val_recall: 0.6787 - val_tn: 385.0000 - val_tp: 150.0000 - learning_rate: 1.1089e-04\n",
            "Epoch 766/2000\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 159ms/step - accuracy: 0.9133 - auc: 0.9707 - fn: 72.2069 - fp: 44.1034 - loss: 0.0256 - precision: 0.8972 - recall: 0.8354 - tn: 911.7586 - tp: 405.7242 - val_accuracy: 0.8130 - val_auc: 0.8514 - val_fn: 68.0000 - val_fp: 56.0000 - val_loss: 0.1760 - val_precision: 0.7321 - val_recall: 0.6923 - val_tn: 386.0000 - val_tp: 153.0000 - learning_rate: 1.1089e-04\n",
            "Epoch 767/2000\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 174ms/step - accuracy: 0.9057 - auc: 0.9673 - fn: 83.4828 - fp: 53.7931 - loss: 0.0276 - precision: 0.8824 - recall: 0.8273 - tn: 902.0690 - tp: 394.4483 - val_accuracy: 0.8084 - val_auc: 0.8474 - val_fn: 71.0000 - val_fp: 56.0000 - val_loss: 0.1766 - val_precision: 0.7282 - val_recall: 0.6787 - val_tn: 386.0000 - val_tp: 150.0000 - learning_rate: 1.1089e-04\n",
            "Epoch 768/2000\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 164ms/step - accuracy: 0.9033 - auc: 0.9680 - fn: 85.3793 - fp: 49.5517 - loss: 0.0260 - precision: 0.8822 - recall: 0.8194 - tn: 906.3104 - tp: 392.5517 - val_accuracy: 0.8069 - val_auc: 0.8479 - val_fn: 72.0000 - val_fp: 56.0000 - val_loss: 0.1775 - val_precision: 0.7268 - val_recall: 0.6742 - val_tn: 386.0000 - val_tp: 149.0000 - learning_rate: 1.1089e-04\n",
            "Epoch 769/2000\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 177ms/step - accuracy: 0.9186 - auc: 0.9774 - fn: 76.3793 - fp: 45.0345 - loss: 0.0222 - precision: 0.9022 - recall: 0.8476 - tn: 910.8276 - tp: 401.5517 - val_accuracy: 0.8145 - val_auc: 0.8490 - val_fn: 70.0000 - val_fp: 53.0000 - val_loss: 0.1738 - val_precision: 0.7402 - val_recall: 0.6833 - val_tn: 389.0000 - val_tp: 151.0000 - learning_rate: 1.1089e-04\n",
            "Epoch 770/2000\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 173ms/step - accuracy: 0.9168 - auc: 0.9697 - fn: 72.2759 - fp: 44.3793 - loss: 0.0273 - precision: 0.8980 - recall: 0.8465 - tn: 911.4828 - tp: 405.6552 - val_accuracy: 0.8130 - val_auc: 0.8458 - val_fn: 70.0000 - val_fp: 54.0000 - val_loss: 0.1722 - val_precision: 0.7366 - val_recall: 0.6833 - val_tn: 388.0000 - val_tp: 151.0000 - learning_rate: 1.1089e-04\n",
            "Epoch 771/2000\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 177ms/step - accuracy: 0.9203 - auc: 0.9748 - fn: 73.5172 - fp: 44.2759 - loss: 0.0234 - precision: 0.9048 - recall: 0.8505 - tn: 911.5862 - tp: 404.4138 - val_accuracy: 0.8084 - val_auc: 0.8446 - val_fn: 71.0000 - val_fp: 56.0000 - val_loss: 0.1791 - val_precision: 0.7282 - val_recall: 0.6787 - val_tn: 386.0000 - val_tp: 150.0000 - learning_rate: 1.1089e-04\n",
            "Epoch 772/2000\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 158ms/step - accuracy: 0.9070 - auc: 0.9663 - fn: 84.0000 - fp: 52.5172 - loss: 0.0282 - precision: 0.8835 - recall: 0.8305 - tn: 903.3448 - tp: 393.9310 - val_accuracy: 0.8054 - val_auc: 0.8448 - val_fn: 73.0000 - val_fp: 56.0000 - val_loss: 0.1731 - val_precision: 0.7255 - val_recall: 0.6697 - val_tn: 386.0000 - val_tp: 148.0000 - learning_rate: 1.1089e-04\n",
            "Epoch 773/2000\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 159ms/step - accuracy: 0.9209 - auc: 0.9742 - fn: 71.4828 - fp: 40.6897 - loss: 0.0246 - precision: 0.9124 - recall: 0.8439 - tn: 915.1724 - tp: 406.4483 - val_accuracy: 0.8115 - val_auc: 0.8469 - val_fn: 71.0000 - val_fp: 54.0000 - val_loss: 0.1779 - val_precision: 0.7353 - val_recall: 0.6787 - val_tn: 388.0000 - val_tp: 150.0000 - learning_rate: 1.1089e-04\n",
            "Epoch 774/2000\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 178ms/step - accuracy: 0.9213 - auc: 0.9746 - fn: 70.7241 - fp: 47.1034 - loss: 0.0247 - precision: 0.8990 - recall: 0.8603 - tn: 908.7586 - tp: 407.2069 - val_accuracy: 0.8130 - val_auc: 0.8451 - val_fn: 70.0000 - val_fp: 54.0000 - val_loss: 0.1844 - val_precision: 0.7366 - val_recall: 0.6833 - val_tn: 388.0000 - val_tp: 151.0000 - learning_rate: 1.1089e-04\n",
            "Epoch 775/2000\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 157ms/step - accuracy: 0.9142 - auc: 0.9744 - fn: 71.3448 - fp: 47.8276 - loss: 0.0227 - precision: 0.8905 - recall: 0.8468 - tn: 908.0345 - tp: 406.5862 - val_accuracy: 0.8100 - val_auc: 0.8476 - val_fn: 70.0000 - val_fp: 56.0000 - val_loss: 0.1837 - val_precision: 0.7295 - val_recall: 0.6833 - val_tn: 386.0000 - val_tp: 151.0000 - learning_rate: 1.1089e-04\n",
            "Epoch 776/2000\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 157ms/step - accuracy: 0.9074 - auc: 0.9769 - fn: 76.4483 - fp: 50.3793 - loss: 0.0212 - precision: 0.8814 - recall: 0.8344 - tn: 905.4828 - tp: 401.4828 - val_accuracy: 0.8069 - val_auc: 0.8472 - val_fn: 70.0000 - val_fp: 58.0000 - val_loss: 0.1767 - val_precision: 0.7225 - val_recall: 0.6833 - val_tn: 384.0000 - val_tp: 151.0000 - learning_rate: 1.1089e-04\n",
            "Epoch 777/2000\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 178ms/step - accuracy: 0.9129 - auc: 0.9723 - fn: 72.1034 - fp: 50.4828 - loss: 0.0238 - precision: 0.8862 - recall: 0.8473 - tn: 905.3793 - tp: 405.8276 - val_accuracy: 0.8190 - val_auc: 0.8482 - val_fn: 68.0000 - val_fp: 52.0000 - val_loss: 0.1798 - val_precision: 0.7463 - val_recall: 0.6923 - val_tn: 390.0000 - val_tp: 153.0000 - learning_rate: 1.1089e-04\n",
            "Epoch 778/2000\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 173ms/step - accuracy: 0.9027 - auc: 0.9690 - fn: 77.1379 - fp: 55.4483 - loss: 0.0268 - precision: 0.8718 - recall: 0.8299 - tn: 900.4138 - tp: 400.7931 - val_accuracy: 0.8205 - val_auc: 0.8473 - val_fn: 69.0000 - val_fp: 50.0000 - val_loss: 0.1748 - val_precision: 0.7525 - val_recall: 0.6878 - val_tn: 392.0000 - val_tp: 152.0000 - learning_rate: 1.1089e-04\n",
            "Epoch 779/2000\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 158ms/step - accuracy: 0.9268 - auc: 0.9773 - fn: 71.4138 - fp: 40.3448 - loss: 0.0224 - precision: 0.9159 - recall: 0.8590 - tn: 915.5172 - tp: 406.5172 - val_accuracy: 0.8175 - val_auc: 0.8464 - val_fn: 70.0000 - val_fp: 51.0000 - val_loss: 0.1761 - val_precision: 0.7475 - val_recall: 0.6833 - val_tn: 391.0000 - val_tp: 151.0000 - learning_rate: 1.1089e-04\n",
            "Epoch 780/2000\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 163ms/step - accuracy: 0.9161 - auc: 0.9730 - fn: 73.3793 - fp: 46.8966 - loss: 0.0241 - precision: 0.8960 - recall: 0.8465 - tn: 908.9655 - tp: 404.5517 - val_accuracy: 0.8190 - val_auc: 0.8496 - val_fn: 67.0000 - val_fp: 53.0000 - val_loss: 0.1708 - val_precision: 0.7440 - val_recall: 0.6968 - val_tn: 389.0000 - val_tp: 154.0000 - learning_rate: 1.1089e-04\n",
            "Epoch 781/2000\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 158ms/step - accuracy: 0.9231 - auc: 0.9790 - fn: 69.0345 - fp: 47.0690 - loss: 0.0210 - precision: 0.9035 - recall: 0.8613 - tn: 908.7931 - tp: 408.8965 - val_accuracy: 0.8205 - val_auc: 0.8468 - val_fn: 70.0000 - val_fp: 49.0000 - val_loss: 0.1759 - val_precision: 0.7550 - val_recall: 0.6833 - val_tn: 393.0000 - val_tp: 151.0000 - learning_rate: 1.1089e-04\n",
            "Epoch 782/2000\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 175ms/step - accuracy: 0.9223 - auc: 0.9764 - fn: 67.0690 - fp: 46.6207 - loss: 0.0217 - precision: 0.8989 - recall: 0.8641 - tn: 909.2414 - tp: 410.8621 - val_accuracy: 0.8190 - val_auc: 0.8527 - val_fn: 67.0000 - val_fp: 53.0000 - val_loss: 0.1750 - val_precision: 0.7440 - val_recall: 0.6968 - val_tn: 389.0000 - val_tp: 154.0000 - learning_rate: 1.1089e-04\n",
            "Epoch 783/2000\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 162ms/step - accuracy: 0.9131 - auc: 0.9713 - fn: 73.2759 - fp: 45.1379 - loss: 0.0263 - precision: 0.8952 - recall: 0.8371 - tn: 910.7241 - tp: 404.6552 - val_accuracy: 0.8145 - val_auc: 0.8495 - val_fn: 68.0000 - val_fp: 55.0000 - val_loss: 0.1791 - val_precision: 0.7356 - val_recall: 0.6923 - val_tn: 387.0000 - val_tp: 153.0000 - learning_rate: 1.1089e-04\n",
            "Epoch 784/2000\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 158ms/step - accuracy: 0.9071 - auc: 0.9694 - fn: 76.7241 - fp: 54.0690 - loss: 0.0272 - precision: 0.8784 - recall: 0.8371 - tn: 901.7931 - tp: 401.2069 - val_accuracy: 0.8054 - val_auc: 0.8461 - val_fn: 72.0000 - val_fp: 57.0000 - val_loss: 0.1732 - val_precision: 0.7233 - val_recall: 0.6742 - val_tn: 385.0000 - val_tp: 149.0000 - learning_rate: 1.1089e-04\n",
            "Epoch 785/2000\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 175ms/step - accuracy: 0.9133 - auc: 0.9738 - fn: 77.9655 - fp: 40.8621 - loss: 0.0238 - precision: 0.9038 - recall: 0.8278 - tn: 915.0000 - tp: 399.9655 - val_accuracy: 0.8160 - val_auc: 0.8542 - val_fn: 69.0000 - val_fp: 53.0000 - val_loss: 0.1735 - val_precision: 0.7415 - val_recall: 0.6878 - val_tn: 389.0000 - val_tp: 152.0000 - learning_rate: 1.1089e-04\n",
            "Epoch 786/2000\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 162ms/step - accuracy: 0.9166 - auc: 0.9683 - fn: 72.8966 - fp: 46.8276 - loss: 0.0289 - precision: 0.8967 - recall: 0.8474 - tn: 909.0345 - tp: 405.0345 - val_accuracy: 0.8265 - val_auc: 0.8547 - val_fn: 64.0000 - val_fp: 51.0000 - val_loss: 0.1738 - val_precision: 0.7548 - val_recall: 0.7104 - val_tn: 391.0000 - val_tp: 157.0000 - learning_rate: 1.1089e-04\n",
            "Epoch 787/2000\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 157ms/step - accuracy: 0.9001 - auc: 0.9706 - fn: 86.8276 - fp: 55.0345 - loss: 0.0257 - precision: 0.8759 - recall: 0.8157 - tn: 900.8276 - tp: 391.1035 - val_accuracy: 0.8115 - val_auc: 0.8499 - val_fn: 71.0000 - val_fp: 54.0000 - val_loss: 0.1783 - val_precision: 0.7353 - val_recall: 0.6787 - val_tn: 388.0000 - val_tp: 150.0000 - learning_rate: 1.1089e-04\n",
            "Epoch 788/2000\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 176ms/step - accuracy: 0.9222 - auc: 0.9790 - fn: 68.0690 - fp: 40.7241 - loss: 0.0211 - precision: 0.9087 - recall: 0.8522 - tn: 915.1379 - tp: 409.8621 - val_accuracy: 0.8054 - val_auc: 0.8467 - val_fn: 72.0000 - val_fp: 57.0000 - val_loss: 0.1794 - val_precision: 0.7233 - val_recall: 0.6742 - val_tn: 385.0000 - val_tp: 149.0000 - learning_rate: 1.1089e-04\n",
            "Epoch 789/2000\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 162ms/step - accuracy: 0.9251 - auc: 0.9782 - fn: 69.8966 - fp: 40.8276 - loss: 0.0216 - precision: 0.9112 - recall: 0.8591 - tn: 915.0345 - tp: 408.0345 - val_accuracy: 0.8115 - val_auc: 0.8500 - val_fn: 70.0000 - val_fp: 55.0000 - val_loss: 0.1726 - val_precision: 0.7330 - val_recall: 0.6833 - val_tn: 387.0000 - val_tp: 151.0000 - learning_rate: 1.1089e-04\n",
            "Epoch 790/2000\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 161ms/step - accuracy: 0.9008 - auc: 0.9668 - fn: 85.8966 - fp: 50.4483 - loss: 0.0281 - precision: 0.8865 - recall: 0.8057 - tn: 905.4138 - tp: 392.0345 - val_accuracy: 0.8054 - val_auc: 0.8500 - val_fn: 73.0000 - val_fp: 56.0000 - val_loss: 0.1753 - val_precision: 0.7255 - val_recall: 0.6697 - val_tn: 386.0000 - val_tp: 148.0000 - learning_rate: 1.1089e-04\n",
            "Epoch 791/2000\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 177ms/step - accuracy: 0.9072 - auc: 0.9708 - fn: 79.8276 - fp: 50.1379 - loss: 0.0265 - precision: 0.8840 - recall: 0.8308 - tn: 905.7241 - tp: 398.1035 - val_accuracy: 0.8220 - val_auc: 0.8481 - val_fn: 67.0000 - val_fp: 51.0000 - val_loss: 0.1700 - val_precision: 0.7512 - val_recall: 0.6968 - val_tn: 391.0000 - val_tp: 154.0000 - learning_rate: 1.1089e-04\n",
            "Epoch 792/2000\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 177ms/step - accuracy: 0.9231 - auc: 0.9768 - fn: 77.6897 - fp: 38.9655 - loss: 0.0233 - precision: 0.9197 - recall: 0.8431 - tn: 916.8965 - tp: 400.2414 - val_accuracy: 0.8145 - val_auc: 0.8464 - val_fn: 70.0000 - val_fp: 53.0000 - val_loss: 0.1760 - val_precision: 0.7402 - val_recall: 0.6833 - val_tn: 389.0000 - val_tp: 151.0000 - learning_rate: 1.1089e-04\n",
            "Epoch 793/2000\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 175ms/step - accuracy: 0.9148 - auc: 0.9748 - fn: 77.7241 - fp: 45.1724 - loss: 0.0241 - precision: 0.9016 - recall: 0.8355 - tn: 910.6896 - tp: 400.2069 - val_accuracy: 0.8039 - val_auc: 0.8451 - val_fn: 70.0000 - val_fp: 60.0000 - val_loss: 0.1791 - val_precision: 0.7156 - val_recall: 0.6833 - val_tn: 382.0000 - val_tp: 151.0000 - learning_rate: 1.1089e-04\n",
            "Epoch 794/2000\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 164ms/step - accuracy: 0.8975 - auc: 0.9660 - fn: 85.2759 - fp: 53.5172 - loss: 0.0272 - precision: 0.8708 - recall: 0.8131 - tn: 902.3448 - tp: 392.6552 - val_accuracy: 0.8069 - val_auc: 0.8457 - val_fn: 70.0000 - val_fp: 58.0000 - val_loss: 0.1787 - val_precision: 0.7225 - val_recall: 0.6833 - val_tn: 384.0000 - val_tp: 151.0000 - learning_rate: 1.1089e-04\n",
            "Epoch 795/2000\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 161ms/step - accuracy: 0.9171 - auc: 0.9763 - fn: 72.3448 - fp: 42.6552 - loss: 0.0230 - precision: 0.9022 - recall: 0.8426 - tn: 913.2069 - tp: 405.5862 - val_accuracy: 0.8054 - val_auc: 0.8470 - val_fn: 70.0000 - val_fp: 59.0000 - val_loss: 0.1789 - val_precision: 0.7190 - val_recall: 0.6833 - val_tn: 383.0000 - val_tp: 151.0000 - learning_rate: 1.1089e-04\n",
            "Epoch 796/2000\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 159ms/step - accuracy: 0.9188 - auc: 0.9756 - fn: 71.6897 - fp: 48.8621 - loss: 0.0224 - precision: 0.8960 - recall: 0.8558 - tn: 907.0000 - tp: 406.2414 - val_accuracy: 0.8115 - val_auc: 0.8501 - val_fn: 68.0000 - val_fp: 57.0000 - val_loss: 0.1744 - val_precision: 0.7286 - val_recall: 0.6923 - val_tn: 385.0000 - val_tp: 153.0000 - learning_rate: 1.1089e-04\n",
            "Epoch 797/2000\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 161ms/step - accuracy: 0.9058 - auc: 0.9694 - fn: 83.5172 - fp: 48.2759 - loss: 0.0282 - precision: 0.8855 - recall: 0.8242 - tn: 907.5862 - tp: 394.4138 - val_accuracy: 0.8190 - val_auc: 0.8496 - val_fn: 65.0000 - val_fp: 55.0000 - val_loss: 0.1684 - val_precision: 0.7393 - val_recall: 0.7059 - val_tn: 387.0000 - val_tp: 156.0000 - learning_rate: 1.1089e-04\n",
            "Epoch 798/2000\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 161ms/step - accuracy: 0.9151 - auc: 0.9716 - fn: 76.3448 - fp: 45.8966 - loss: 0.0255 - precision: 0.9000 - recall: 0.8387 - tn: 909.9655 - tp: 401.5862 - val_accuracy: 0.8054 - val_auc: 0.8483 - val_fn: 72.0000 - val_fp: 57.0000 - val_loss: 0.1739 - val_precision: 0.7233 - val_recall: 0.6742 - val_tn: 385.0000 - val_tp: 149.0000 - learning_rate: 1.1089e-04\n",
            "Epoch 799/2000\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 174ms/step - accuracy: 0.9044 - auc: 0.9682 - fn: 79.6552 - fp: 52.5862 - loss: 0.0265 - precision: 0.8787 - recall: 0.8275 - tn: 903.2759 - tp: 398.2758 - val_accuracy: 0.8160 - val_auc: 0.8534 - val_fn: 66.0000 - val_fp: 56.0000 - val_loss: 0.1752 - val_precision: 0.7346 - val_recall: 0.7014 - val_tn: 386.0000 - val_tp: 155.0000 - learning_rate: 1.1089e-04\n",
            "Epoch 800/2000\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 178ms/step - accuracy: 0.9185 - auc: 0.9735 - fn: 71.6207 - fp: 43.3448 - loss: 0.0261 - precision: 0.8998 - recall: 0.8503 - tn: 912.5172 - tp: 406.3103 - val_accuracy: 0.8100 - val_auc: 0.8489 - val_fn: 68.0000 - val_fp: 58.0000 - val_loss: 0.1759 - val_precision: 0.7251 - val_recall: 0.6923 - val_tn: 384.0000 - val_tp: 153.0000 - learning_rate: 1.1089e-04\n",
            "Epoch 801/2000\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 160ms/step - accuracy: 0.9204 - auc: 0.9766 - fn: 71.7931 - fp: 41.8966 - loss: 0.0219 - precision: 0.9068 - recall: 0.8485 - tn: 913.9655 - tp: 406.1379 - val_accuracy: 0.8054 - val_auc: 0.8486 - val_fn: 70.0000 - val_fp: 59.0000 - val_loss: 0.1784 - val_precision: 0.7190 - val_recall: 0.6833 - val_tn: 383.0000 - val_tp: 151.0000 - learning_rate: 1.1089e-04\n",
            "Epoch 802/2000\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 158ms/step - accuracy: 0.9245 - auc: 0.9776 - fn: 70.9310 - fp: 40.8276 - loss: 0.0221 - precision: 0.9154 - recall: 0.8525 - tn: 915.0345 - tp: 407.0000 - val_accuracy: 0.8145 - val_auc: 0.8528 - val_fn: 68.0000 - val_fp: 55.0000 - val_loss: 0.1740 - val_precision: 0.7356 - val_recall: 0.6923 - val_tn: 387.0000 - val_tp: 153.0000 - learning_rate: 1.1089e-04\n",
            "Epoch 803/2000\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 161ms/step - accuracy: 0.9146 - auc: 0.9700 - fn: 72.0345 - fp: 46.3448 - loss: 0.0264 - precision: 0.8921 - recall: 0.8460 - tn: 909.5172 - tp: 405.8965 - val_accuracy: 0.8115 - val_auc: 0.8510 - val_fn: 68.0000 - val_fp: 57.0000 - val_loss: 0.1708 - val_precision: 0.7286 - val_recall: 0.6923 - val_tn: 385.0000 - val_tp: 153.0000 - learning_rate: 1.1089e-04\n",
            "Epoch 804/2000\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 163ms/step - accuracy: 0.9303 - auc: 0.9810 - fn: 67.2414 - fp: 39.0000 - loss: 0.0200 - precision: 0.9209 - recall: 0.8654 - tn: 916.8621 - tp: 410.6897 - val_accuracy: 0.8145 - val_auc: 0.8509 - val_fn: 67.0000 - val_fp: 56.0000 - val_loss: 0.1745 - val_precision: 0.7333 - val_recall: 0.6968 - val_tn: 386.0000 - val_tp: 154.0000 - learning_rate: 1.1089e-04\n",
            "Epoch 805/2000\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 158ms/step - accuracy: 0.9182 - auc: 0.9769 - fn: 70.3103 - fp: 44.8276 - loss: 0.0217 - precision: 0.8999 - recall: 0.8490 - tn: 911.0345 - tp: 407.6207 - val_accuracy: 0.8145 - val_auc: 0.8485 - val_fn: 68.0000 - val_fp: 55.0000 - val_loss: 0.1781 - val_precision: 0.7356 - val_recall: 0.6923 - val_tn: 387.0000 - val_tp: 153.0000 - learning_rate: 1.1089e-04\n",
            "Epoch 806/2000\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 161ms/step - accuracy: 0.8995 - auc: 0.9673 - fn: 89.2414 - fp: 53.7586 - loss: 0.0272 - precision: 0.8773 - recall: 0.8122 - tn: 902.1035 - tp: 388.6897 - val_accuracy: 0.8145 - val_auc: 0.8509 - val_fn: 69.0000 - val_fp: 54.0000 - val_loss: 0.1720 - val_precision: 0.7379 - val_recall: 0.6878 - val_tn: 388.0000 - val_tp: 152.0000 - learning_rate: 1.1089e-04\n",
            "Epoch 807/2000\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 163ms/step - accuracy: 0.9095 - auc: 0.9744 - fn: 77.2759 - fp: 48.6552 - loss: 0.0235 - precision: 0.8878 - recall: 0.8340 - tn: 907.2069 - tp: 400.6552 - val_accuracy: 0.8054 - val_auc: 0.8513 - val_fn: 73.0000 - val_fp: 56.0000 - val_loss: 0.1690 - val_precision: 0.7255 - val_recall: 0.6697 - val_tn: 386.0000 - val_tp: 148.0000 - learning_rate: 1.1089e-04\n",
            "Epoch 808/2000\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 175ms/step - accuracy: 0.9085 - auc: 0.9734 - fn: 81.2759 - fp: 47.9655 - loss: 0.0228 - precision: 0.8896 - recall: 0.8281 - tn: 907.8965 - tp: 396.6552 - val_accuracy: 0.8205 - val_auc: 0.8538 - val_fn: 65.0000 - val_fp: 54.0000 - val_loss: 0.1741 - val_precision: 0.7429 - val_recall: 0.7059 - val_tn: 388.0000 - val_tp: 156.0000 - learning_rate: 1.1089e-04\n",
            "Epoch 809/2000\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 159ms/step - accuracy: 0.9149 - auc: 0.9787 - fn: 75.4828 - fp: 58.0345 - loss: 0.0204 - precision: 0.8835 - recall: 0.8575 - tn: 897.8276 - tp: 402.4483 - val_accuracy: 0.8175 - val_auc: 0.8530 - val_fn: 68.0000 - val_fp: 53.0000 - val_loss: 0.1739 - val_precision: 0.7427 - val_recall: 0.6923 - val_tn: 389.0000 - val_tp: 153.0000 - learning_rate: 1.1089e-04\n",
            "Epoch 810/2000\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 181ms/step - accuracy: 0.9304 - auc: 0.9805 - fn: 67.6552 - fp: 40.2069 - loss: 0.0204 - precision: 0.9180 - recall: 0.8686 - tn: 915.6552 - tp: 410.2758 - val_accuracy: 0.8235 - val_auc: 0.8509 - val_fn: 65.0000 - val_fp: 52.0000 - val_loss: 0.1742 - val_precision: 0.7500 - val_recall: 0.7059 - val_tn: 390.0000 - val_tp: 156.0000 - learning_rate: 1.1089e-04\n",
            "Epoch 811/2000\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 174ms/step - accuracy: 0.9302 - auc: 0.9769 - fn: 68.7241 - fp: 40.7931 - loss: 0.0229 - precision: 0.9173 - recall: 0.8687 - tn: 915.0690 - tp: 409.2069 - val_accuracy: 0.8160 - val_auc: 0.8491 - val_fn: 70.0000 - val_fp: 52.0000 - val_loss: 0.1728 - val_precision: 0.7438 - val_recall: 0.6833 - val_tn: 390.0000 - val_tp: 151.0000 - learning_rate: 1.1089e-04\n",
            "Epoch 812/2000\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 174ms/step - accuracy: 0.9198 - auc: 0.9730 - fn: 76.3448 - fp: 44.2414 - loss: 0.0265 - precision: 0.9071 - recall: 0.8459 - tn: 911.6207 - tp: 401.5862 - val_accuracy: 0.8205 - val_auc: 0.8521 - val_fn: 68.0000 - val_fp: 51.0000 - val_loss: 0.1735 - val_precision: 0.7500 - val_recall: 0.6923 - val_tn: 391.0000 - val_tp: 153.0000 - learning_rate: 1.1089e-04\n",
            "Epoch 813/2000\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 164ms/step - accuracy: 0.9061 - auc: 0.9741 - fn: 87.1034 - fp: 49.4828 - loss: 0.0238 - precision: 0.8881 - recall: 0.8217 - tn: 906.3793 - tp: 390.8276 - val_accuracy: 0.8220 - val_auc: 0.8509 - val_fn: 66.0000 - val_fp: 52.0000 - val_loss: 0.1799 - val_precision: 0.7488 - val_recall: 0.7014 - val_tn: 390.0000 - val_tp: 155.0000 - learning_rate: 1.1089e-04\n",
            "Epoch 814/2000\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 174ms/step - accuracy: 0.9087 - auc: 0.9669 - fn: 80.2414 - fp: 53.3448 - loss: 0.0289 - precision: 0.8859 - recall: 0.8334 - tn: 902.5172 - tp: 397.6897 - val_accuracy: 0.8145 - val_auc: 0.8491 - val_fn: 70.0000 - val_fp: 53.0000 - val_loss: 0.1773 - val_precision: 0.7402 - val_recall: 0.6833 - val_tn: 389.0000 - val_tp: 151.0000 - learning_rate: 1.1089e-04\n",
            "Epoch 815/2000\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 159ms/step - accuracy: 0.9115 - auc: 0.9704 - fn: 79.0345 - fp: 49.8966 - loss: 0.0261 - precision: 0.8899 - recall: 0.8384 - tn: 905.9655 - tp: 398.8965 - val_accuracy: 0.8205 - val_auc: 0.8500 - val_fn: 66.0000 - val_fp: 53.0000 - val_loss: 0.1770 - val_precision: 0.7452 - val_recall: 0.7014 - val_tn: 389.0000 - val_tp: 155.0000 - learning_rate: 1.1089e-04\n",
            "Epoch 816/2000\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 165ms/step - accuracy: 0.9114 - auc: 0.9689 - fn: 80.0690 - fp: 54.8621 - loss: 0.0257 - precision: 0.8865 - recall: 0.8419 - tn: 901.0000 - tp: 397.8621 - val_accuracy: 0.8265 - val_auc: 0.8524 - val_fn: 65.0000 - val_fp: 50.0000 - val_loss: 0.1717 - val_precision: 0.7573 - val_recall: 0.7059 - val_tn: 392.0000 - val_tp: 156.0000 - learning_rate: 1.1089e-04\n",
            "Epoch 817/2000\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 173ms/step - accuracy: 0.9117 - auc: 0.9716 - fn: 70.5172 - fp: 53.7241 - loss: 0.0246 - precision: 0.8805 - recall: 0.8507 - tn: 902.1379 - tp: 407.4138 - val_accuracy: 0.8250 - val_auc: 0.8497 - val_fn: 69.0000 - val_fp: 47.0000 - val_loss: 0.1727 - val_precision: 0.7638 - val_recall: 0.6878 - val_tn: 395.0000 - val_tp: 152.0000 - learning_rate: 1.1089e-04\n",
            "Epoch 818/2000\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 175ms/step - accuracy: 0.8961 - auc: 0.9685 - fn: 84.4828 - fp: 57.6552 - loss: 0.0259 - precision: 0.8645 - recall: 0.8161 - tn: 898.2069 - tp: 393.4483 - val_accuracy: 0.8190 - val_auc: 0.8541 - val_fn: 67.0000 - val_fp: 53.0000 - val_loss: 0.1703 - val_precision: 0.7440 - val_recall: 0.6968 - val_tn: 389.0000 - val_tp: 154.0000 - learning_rate: 1.1089e-04\n",
            "Epoch 819/2000\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 161ms/step - accuracy: 0.9122 - auc: 0.9721 - fn: 75.4483 - fp: 50.9655 - loss: 0.0233 - precision: 0.8881 - recall: 0.8429 - tn: 904.8965 - tp: 402.4828 - val_accuracy: 0.8281 - val_auc: 0.8518 - val_fn: 61.0000 - val_fp: 53.0000 - val_loss: 0.1780 - val_precision: 0.7512 - val_recall: 0.7240 - val_tn: 389.0000 - val_tp: 160.0000 - learning_rate: 1.1089e-04\n",
            "Epoch 820/2000\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 174ms/step - accuracy: 0.9221 - auc: 0.9765 - fn: 69.8276 - fp: 44.7241 - loss: 0.0219 - precision: 0.9041 - recall: 0.8574 - tn: 911.1379 - tp: 408.1035 - val_accuracy: 0.8190 - val_auc: 0.8503 - val_fn: 66.0000 - val_fp: 54.0000 - val_loss: 0.1766 - val_precision: 0.7416 - val_recall: 0.7014 - val_tn: 388.0000 - val_tp: 155.0000 - learning_rate: 1.1089e-04\n",
            "Epoch 821/2000\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 175ms/step - accuracy: 0.9100 - auc: 0.9740 - fn: 79.7586 - fp: 54.6897 - loss: 0.0242 - precision: 0.8841 - recall: 0.8401 - tn: 901.1724 - tp: 398.1724 - val_accuracy: 0.8145 - val_auc: 0.8499 - val_fn: 69.0000 - val_fp: 54.0000 - val_loss: 0.1764 - val_precision: 0.7379 - val_recall: 0.6878 - val_tn: 388.0000 - val_tp: 152.0000 - learning_rate: 1.1089e-04\n",
            "Epoch 822/2000\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 161ms/step - accuracy: 0.9235 - auc: 0.9766 - fn: 70.7931 - fp: 43.4828 - loss: 0.0220 - precision: 0.9085 - recall: 0.8568 - tn: 912.3793 - tp: 407.1379 - val_accuracy: 0.8190 - val_auc: 0.8496 - val_fn: 67.0000 - val_fp: 53.0000 - val_loss: 0.1790 - val_precision: 0.7440 - val_recall: 0.6968 - val_tn: 389.0000 - val_tp: 154.0000 - learning_rate: 1.1089e-04\n",
            "Epoch 823/2000\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 157ms/step - accuracy: 0.9211 - auc: 0.9721 - fn: 73.2069 - fp: 42.0000 - loss: 0.0282 - precision: 0.9054 - recall: 0.8523 - tn: 913.8621 - tp: 404.7242 - val_accuracy: 0.8145 - val_auc: 0.8480 - val_fn: 69.0000 - val_fp: 54.0000 - val_loss: 0.1761 - val_precision: 0.7379 - val_recall: 0.6878 - val_tn: 388.0000 - val_tp: 152.0000 - learning_rate: 1.1089e-04\n",
            "Epoch 824/2000\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 175ms/step - accuracy: 0.9067 - auc: 0.9682 - fn: 74.5172 - fp: 49.6207 - loss: 0.0249 - precision: 0.8787 - recall: 0.8356 - tn: 906.2414 - tp: 403.4138 - val_accuracy: 0.8220 - val_auc: 0.8510 - val_fn: 67.0000 - val_fp: 51.0000 - val_loss: 0.1812 - val_precision: 0.7512 - val_recall: 0.6968 - val_tn: 391.0000 - val_tp: 154.0000 - learning_rate: 1.1089e-04\n",
            "Epoch 825/2000\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 177ms/step - accuracy: 0.8970 - auc: 0.9576 - fn: 87.5517 - fp: 56.3793 - loss: 0.0329 - precision: 0.8691 - recall: 0.8135 - tn: 899.4828 - tp: 390.3793 - val_accuracy: 0.8175 - val_auc: 0.8517 - val_fn: 67.0000 - val_fp: 54.0000 - val_loss: 0.1763 - val_precision: 0.7404 - val_recall: 0.6968 - val_tn: 388.0000 - val_tp: 154.0000 - learning_rate: 1.1089e-04\n",
            "Epoch 826/2000\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 158ms/step - accuracy: 0.9042 - auc: 0.9692 - fn: 79.3103 - fp: 54.9310 - loss: 0.0253 - precision: 0.8782 - recall: 0.8274 - tn: 900.9310 - tp: 398.6207 - val_accuracy: 0.8145 - val_auc: 0.8516 - val_fn: 67.0000 - val_fp: 56.0000 - val_loss: 0.1777 - val_precision: 0.7333 - val_recall: 0.6968 - val_tn: 386.0000 - val_tp: 154.0000 - learning_rate: 1.1089e-04\n",
            "Epoch 827/2000\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 161ms/step - accuracy: 0.9071 - auc: 0.9755 - fn: 80.7586 - fp: 54.8966 - loss: 0.0224 - precision: 0.8804 - recall: 0.8348 - tn: 900.9655 - tp: 397.1724 - val_accuracy: 0.8220 - val_auc: 0.8495 - val_fn: 68.0000 - val_fp: 50.0000 - val_loss: 0.1789 - val_precision: 0.7537 - val_recall: 0.6923 - val_tn: 392.0000 - val_tp: 153.0000 - learning_rate: 1.1089e-04\n",
            "Epoch 828/2000\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 160ms/step - accuracy: 0.9150 - auc: 0.9743 - fn: 78.2069 - fp: 43.5862 - loss: 0.0238 - precision: 0.9013 - recall: 0.8368 - tn: 912.2759 - tp: 399.7242 - val_accuracy: 0.8100 - val_auc: 0.8499 - val_fn: 72.0000 - val_fp: 54.0000 - val_loss: 0.1788 - val_precision: 0.7340 - val_recall: 0.6742 - val_tn: 388.0000 - val_tp: 149.0000 - learning_rate: 1.1089e-04\n",
            "Epoch 829/2000\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 174ms/step - accuracy: 0.9156 - auc: 0.9703 - fn: 72.3793 - fp: 49.4138 - loss: 0.0272 - precision: 0.8913 - recall: 0.8506 - tn: 906.4483 - tp: 405.5517 - val_accuracy: 0.8235 - val_auc: 0.8507 - val_fn: 66.0000 - val_fp: 51.0000 - val_loss: 0.1755 - val_precision: 0.7524 - val_recall: 0.7014 - val_tn: 391.0000 - val_tp: 155.0000 - learning_rate: 1.1089e-04\n",
            "Epoch 830/2000\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 163ms/step - accuracy: 0.9164 - auc: 0.9741 - fn: 73.4138 - fp: 45.7931 - loss: 0.0248 - precision: 0.8988 - recall: 0.8442 - tn: 910.0690 - tp: 404.5172 - val_accuracy: 0.8115 - val_auc: 0.8516 - val_fn: 72.0000 - val_fp: 53.0000 - val_loss: 0.1751 - val_precision: 0.7376 - val_recall: 0.6742 - val_tn: 389.0000 - val_tp: 149.0000 - learning_rate: 1.1089e-04\n",
            "Epoch 831/2000\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 162ms/step - accuracy: 0.9132 - auc: 0.9735 - fn: 76.5862 - fp: 50.8276 - loss: 0.0237 - precision: 0.8924 - recall: 0.8410 - tn: 905.0345 - tp: 401.3448 - val_accuracy: 0.8130 - val_auc: 0.8478 - val_fn: 71.0000 - val_fp: 53.0000 - val_loss: 0.1754 - val_precision: 0.7389 - val_recall: 0.6787 - val_tn: 389.0000 - val_tp: 150.0000 - learning_rate: 1.1089e-04\n",
            "Epoch 832/2000\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 158ms/step - accuracy: 0.9100 - auc: 0.9708 - fn: 74.0690 - fp: 48.7931 - loss: 0.0256 - precision: 0.8885 - recall: 0.8345 - tn: 907.0690 - tp: 403.8621 - val_accuracy: 0.8039 - val_auc: 0.8466 - val_fn: 73.0000 - val_fp: 57.0000 - val_loss: 0.1756 - val_precision: 0.7220 - val_recall: 0.6697 - val_tn: 385.0000 - val_tp: 148.0000 - learning_rate: 1.1089e-04\n",
            "Epoch 833/2000\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 176ms/step - accuracy: 0.9110 - auc: 0.9737 - fn: 78.4483 - fp: 49.8276 - loss: 0.0230 - precision: 0.8909 - recall: 0.8354 - tn: 906.0345 - tp: 399.4828 - val_accuracy: 0.8100 - val_auc: 0.8458 - val_fn: 71.0000 - val_fp: 55.0000 - val_loss: 0.1746 - val_precision: 0.7317 - val_recall: 0.6787 - val_tn: 387.0000 - val_tp: 150.0000 - learning_rate: 1.1089e-04\n",
            "Epoch 834/2000\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 163ms/step - accuracy: 0.9211 - auc: 0.9793 - fn: 71.0345 - fp: 41.2069 - loss: 0.0214 - precision: 0.9067 - recall: 0.8508 - tn: 914.6552 - tp: 406.8965 - val_accuracy: 0.8100 - val_auc: 0.8505 - val_fn: 70.0000 - val_fp: 56.0000 - val_loss: 0.1750 - val_precision: 0.7295 - val_recall: 0.6833 - val_tn: 386.0000 - val_tp: 151.0000 - learning_rate: 1.1089e-04\n",
            "Epoch 835/2000\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 174ms/step - accuracy: 0.9289 - auc: 0.9786 - fn: 62.3103 - fp: 44.9310 - loss: 0.0210 - precision: 0.9066 - recall: 0.8768 - tn: 910.9310 - tp: 415.6207 - val_accuracy: 0.8145 - val_auc: 0.8472 - val_fn: 71.0000 - val_fp: 52.0000 - val_loss: 0.1774 - val_precision: 0.7426 - val_recall: 0.6787 - val_tn: 390.0000 - val_tp: 150.0000 - learning_rate: 1.1089e-04\n",
            "Epoch 836/2000\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 175ms/step - accuracy: 0.9150 - auc: 0.9752 - fn: 71.0345 - fp: 47.4483 - loss: 0.0227 - precision: 0.8909 - recall: 0.8489 - tn: 908.4138 - tp: 406.8965 - val_accuracy: 0.8039 - val_auc: 0.8463 - val_fn: 74.0000 - val_fp: 56.0000 - val_loss: 0.1782 - val_precision: 0.7241 - val_recall: 0.6652 - val_tn: 386.0000 - val_tp: 147.0000 - learning_rate: 1.1089e-04\n",
            "Epoch 837/2000\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 162ms/step - accuracy: 0.9217 - auc: 0.9784 - fn: 73.3793 - fp: 47.2069 - loss: 0.0215 - precision: 0.9043 - recall: 0.8557 - tn: 908.6552 - tp: 404.5517 - val_accuracy: 0.8130 - val_auc: 0.8498 - val_fn: 70.0000 - val_fp: 54.0000 - val_loss: 0.1775 - val_precision: 0.7366 - val_recall: 0.6833 - val_tn: 388.0000 - val_tp: 151.0000 - learning_rate: 1.1089e-04\n",
            "Epoch 838/2000\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 158ms/step - accuracy: 0.9082 - auc: 0.9721 - fn: 78.0690 - fp: 52.6552 - loss: 0.0241 - precision: 0.8824 - recall: 0.8362 - tn: 903.2069 - tp: 399.8621 - val_accuracy: 0.8145 - val_auc: 0.8509 - val_fn: 69.0000 - val_fp: 54.0000 - val_loss: 0.1756 - val_precision: 0.7379 - val_recall: 0.6878 - val_tn: 388.0000 - val_tp: 152.0000 - learning_rate: 1.1089e-04\n",
            "Epoch 839/2000\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 175ms/step - accuracy: 0.9052 - auc: 0.9669 - fn: 80.0690 - fp: 53.0000 - loss: 0.0283 - precision: 0.8784 - recall: 0.8307 - tn: 902.8621 - tp: 397.8621 - val_accuracy: 0.8160 - val_auc: 0.8503 - val_fn: 68.0000 - val_fp: 54.0000 - val_loss: 0.1730 - val_precision: 0.7391 - val_recall: 0.6923 - val_tn: 388.0000 - val_tp: 153.0000 - learning_rate: 1.1089e-04\n",
            "Epoch 840/2000\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 160ms/step - accuracy: 0.9223 - auc: 0.9769 - fn: 74.0000 - fp: 42.0000 - loss: 0.0231 - precision: 0.9088 - recall: 0.8525 - tn: 913.8621 - tp: 403.9310 - val_accuracy: 0.8100 - val_auc: 0.8475 - val_fn: 71.0000 - val_fp: 55.0000 - val_loss: 0.1775 - val_precision: 0.7317 - val_recall: 0.6787 - val_tn: 387.0000 - val_tp: 150.0000 - learning_rate: 1.1089e-04\n",
            "Epoch 841/2000\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 174ms/step - accuracy: 0.9311 - auc: 0.9793 - fn: 64.3448 - fp: 39.4483 - loss: 0.0212 - precision: 0.9176 - recall: 0.8715 - tn: 916.4138 - tp: 413.5862 - val_accuracy: 0.8084 - val_auc: 0.8456 - val_fn: 72.0000 - val_fp: 55.0000 - val_loss: 0.1819 - val_precision: 0.7304 - val_recall: 0.6742 - val_tn: 387.0000 - val_tp: 149.0000 - learning_rate: 1.1089e-04\n",
            "Epoch 842/2000\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 160ms/step - accuracy: 0.9115 - auc: 0.9726 - fn: 77.2414 - fp: 49.6897 - loss: 0.0241 - precision: 0.8894 - recall: 0.8389 - tn: 906.1724 - tp: 400.6897 - val_accuracy: 0.8084 - val_auc: 0.8476 - val_fn: 71.0000 - val_fp: 56.0000 - val_loss: 0.1796 - val_precision: 0.7282 - val_recall: 0.6787 - val_tn: 386.0000 - val_tp: 150.0000 - learning_rate: 1.1089e-04\n",
            "Epoch 843/2000\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 176ms/step - accuracy: 0.8997 - auc: 0.9678 - fn: 86.4138 - fp: 51.9655 - loss: 0.0261 - precision: 0.8770 - recall: 0.8133 - tn: 903.8965 - tp: 391.5172 - val_accuracy: 0.8100 - val_auc: 0.8461 - val_fn: 72.0000 - val_fp: 54.0000 - val_loss: 0.1841 - val_precision: 0.7340 - val_recall: 0.6742 - val_tn: 388.0000 - val_tp: 149.0000 - learning_rate: 1.1089e-04\n",
            "Epoch 844/2000\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 157ms/step - accuracy: 0.9219 - auc: 0.9766 - fn: 64.6897 - fp: 45.8621 - loss: 0.0226 - precision: 0.8972 - recall: 0.8650 - tn: 910.0000 - tp: 413.2414 - val_accuracy: 0.8115 - val_auc: 0.8464 - val_fn: 70.0000 - val_fp: 55.0000 - val_loss: 0.1862 - val_precision: 0.7330 - val_recall: 0.6833 - val_tn: 387.0000 - val_tp: 151.0000 - learning_rate: 1.1089e-04\n",
            "Epoch 845/2000\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 176ms/step - accuracy: 0.9145 - auc: 0.9756 - fn: 74.9310 - fp: 48.7586 - loss: 0.0225 - precision: 0.8928 - recall: 0.8449 - tn: 907.1035 - tp: 403.0000 - val_accuracy: 0.8175 - val_auc: 0.8478 - val_fn: 66.0000 - val_fp: 55.0000 - val_loss: 0.1822 - val_precision: 0.7381 - val_recall: 0.7014 - val_tn: 387.0000 - val_tp: 155.0000 - learning_rate: 1.1089e-04\n",
            "Epoch 846/2000\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 175ms/step - accuracy: 0.9101 - auc: 0.9719 - fn: 76.1724 - fp: 49.0000 - loss: 0.0260 - precision: 0.8903 - recall: 0.8327 - tn: 906.8621 - tp: 401.7586 - val_accuracy: 0.8054 - val_auc: 0.8471 - val_fn: 73.0000 - val_fp: 56.0000 - val_loss: 0.1769 - val_precision: 0.7255 - val_recall: 0.6697 - val_tn: 386.0000 - val_tp: 148.0000 - learning_rate: 1.1089e-04\n",
            "Epoch 847/2000\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 174ms/step - accuracy: 0.9273 - auc: 0.9750 - fn: 67.4828 - fp: 37.6552 - loss: 0.0247 - precision: 0.9168 - recall: 0.8601 - tn: 918.2069 - tp: 410.4483 - val_accuracy: 0.8009 - val_auc: 0.8440 - val_fn: 75.0000 - val_fp: 57.0000 - val_loss: 0.1775 - val_precision: 0.7192 - val_recall: 0.6606 - val_tn: 385.0000 - val_tp: 146.0000 - learning_rate: 1.1089e-04\n",
            "Epoch 848/2000\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 164ms/step - accuracy: 0.9140 - auc: 0.9776 - fn: 78.3793 - fp: 44.2759 - loss: 0.0221 - precision: 0.9026 - recall: 0.8319 - tn: 911.5862 - tp: 399.5517 - val_accuracy: 0.8220 - val_auc: 0.8487 - val_fn: 67.0000 - val_fp: 51.0000 - val_loss: 0.1757 - val_precision: 0.7512 - val_recall: 0.6968 - val_tn: 391.0000 - val_tp: 154.0000 - learning_rate: 1.1089e-04\n",
            "Epoch 849/2000\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 159ms/step - accuracy: 0.9185 - auc: 0.9722 - fn: 69.8966 - fp: 44.1379 - loss: 0.0253 - precision: 0.8989 - recall: 0.8513 - tn: 911.7241 - tp: 408.0345 - val_accuracy: 0.8145 - val_auc: 0.8494 - val_fn: 71.0000 - val_fp: 52.0000 - val_loss: 0.1723 - val_precision: 0.7426 - val_recall: 0.6787 - val_tn: 390.0000 - val_tp: 150.0000 - learning_rate: 1.1089e-04\n",
            "Epoch 850/2000\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 174ms/step - accuracy: 0.9117 - auc: 0.9735 - fn: 80.9655 - fp: 44.3793 - loss: 0.0247 - precision: 0.8997 - recall: 0.8273 - tn: 911.4828 - tp: 396.9655 - val_accuracy: 0.8145 - val_auc: 0.8548 - val_fn: 69.0000 - val_fp: 54.0000 - val_loss: 0.1656 - val_precision: 0.7379 - val_recall: 0.6878 - val_tn: 388.0000 - val_tp: 152.0000 - learning_rate: 1.1089e-04\n",
            "Epoch 851/2000\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 179ms/step - accuracy: 0.9155 - auc: 0.9714 - fn: 76.0345 - fp: 46.7241 - loss: 0.0258 - precision: 0.8980 - recall: 0.8423 - tn: 909.1379 - tp: 401.8965 - val_accuracy: 0.8250 - val_auc: 0.8539 - val_fn: 66.0000 - val_fp: 50.0000 - val_loss: 0.1665 - val_precision: 0.7561 - val_recall: 0.7014 - val_tn: 392.0000 - val_tp: 155.0000 - learning_rate: 1.1089e-04\n",
            "Epoch 852/2000\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 163ms/step - accuracy: 0.9129 - auc: 0.9754 - fn: 72.5517 - fp: 46.8621 - loss: 0.0229 - precision: 0.8910 - recall: 0.8414 - tn: 909.0000 - tp: 405.3793 - val_accuracy: 0.8190 - val_auc: 0.8538 - val_fn: 67.0000 - val_fp: 53.0000 - val_loss: 0.1683 - val_precision: 0.7440 - val_recall: 0.6968 - val_tn: 389.0000 - val_tp: 154.0000 - learning_rate: 1.1089e-04\n",
            "Epoch 853/2000\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 158ms/step - accuracy: 0.9337 - auc: 0.9826 - fn: 65.7931 - fp: 41.6897 - loss: 0.0187 - precision: 0.9186 - recall: 0.8786 - tn: 914.1724 - tp: 412.1379 - val_accuracy: 0.8115 - val_auc: 0.8538 - val_fn: 67.0000 - val_fp: 58.0000 - val_loss: 0.1631 - val_precision: 0.7264 - val_recall: 0.6968 - val_tn: 384.0000 - val_tp: 154.0000 - learning_rate: 1.1089e-04\n",
            "Epoch 854/2000\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 177ms/step - accuracy: 0.9142 - auc: 0.9756 - fn: 73.6207 - fp: 47.0345 - loss: 0.0230 - precision: 0.8955 - recall: 0.8408 - tn: 908.8276 - tp: 404.3103 - val_accuracy: 0.8115 - val_auc: 0.8525 - val_fn: 69.0000 - val_fp: 56.0000 - val_loss: 0.1649 - val_precision: 0.7308 - val_recall: 0.6878 - val_tn: 386.0000 - val_tp: 152.0000 - learning_rate: 1.1089e-04\n",
            "Epoch 855/2000\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 157ms/step - accuracy: 0.9191 - auc: 0.9760 - fn: 72.5172 - fp: 42.7586 - loss: 0.0226 - precision: 0.9047 - recall: 0.8466 - tn: 913.1035 - tp: 405.4138 - val_accuracy: 0.8069 - val_auc: 0.8460 - val_fn: 72.0000 - val_fp: 56.0000 - val_loss: 0.1699 - val_precision: 0.7268 - val_recall: 0.6742 - val_tn: 386.0000 - val_tp: 149.0000 - learning_rate: 1.1089e-04\n",
            "Epoch 856/2000\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 157ms/step - accuracy: 0.9142 - auc: 0.9765 - fn: 75.9310 - fp: 47.6552 - loss: 0.0216 - precision: 0.8938 - recall: 0.8428 - tn: 908.2069 - tp: 402.0000 - val_accuracy: 0.8205 - val_auc: 0.8512 - val_fn: 64.0000 - val_fp: 55.0000 - val_loss: 0.1707 - val_precision: 0.7406 - val_recall: 0.7104 - val_tn: 387.0000 - val_tp: 157.0000 - learning_rate: 1.1089e-04\n",
            "Epoch 857/2000\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 177ms/step - accuracy: 0.9312 - auc: 0.9796 - fn: 64.4138 - fp: 39.5517 - loss: 0.0217 - precision: 0.9180 - recall: 0.8716 - tn: 916.3104 - tp: 413.5172 - val_accuracy: 0.8145 - val_auc: 0.8478 - val_fn: 67.0000 - val_fp: 56.0000 - val_loss: 0.1700 - val_precision: 0.7333 - val_recall: 0.6968 - val_tn: 386.0000 - val_tp: 154.0000 - learning_rate: 1.1089e-04\n",
            "Epoch 858/2000\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 173ms/step - accuracy: 0.9181 - auc: 0.9789 - fn: 71.2069 - fp: 43.2759 - loss: 0.0204 - precision: 0.9013 - recall: 0.8470 - tn: 912.5862 - tp: 406.7242 - val_accuracy: 0.8175 - val_auc: 0.8495 - val_fn: 67.0000 - val_fp: 54.0000 - val_loss: 0.1731 - val_precision: 0.7404 - val_recall: 0.6968 - val_tn: 388.0000 - val_tp: 154.0000 - learning_rate: 1.1089e-04\n",
            "Epoch 859/2000\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 158ms/step - accuracy: 0.9238 - auc: 0.9770 - fn: 69.1379 - fp: 43.3793 - loss: 0.0219 - precision: 0.9092 - recall: 0.8572 - tn: 912.4828 - tp: 408.7931 - val_accuracy: 0.8100 - val_auc: 0.8517 - val_fn: 71.0000 - val_fp: 55.0000 - val_loss: 0.1747 - val_precision: 0.7317 - val_recall: 0.6787 - val_tn: 387.0000 - val_tp: 150.0000 - learning_rate: 1.1089e-04\n",
            "Epoch 860/2000\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 178ms/step - accuracy: 0.9113 - auc: 0.9751 - fn: 77.8966 - fp: 51.6552 - loss: 0.0229 - precision: 0.8886 - recall: 0.8391 - tn: 904.2069 - tp: 400.0345 - val_accuracy: 0.8145 - val_auc: 0.8522 - val_fn: 69.0000 - val_fp: 54.0000 - val_loss: 0.1745 - val_precision: 0.7379 - val_recall: 0.6878 - val_tn: 388.0000 - val_tp: 152.0000 - learning_rate: 1.1089e-04\n",
            "Epoch 861/2000\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 158ms/step - accuracy: 0.9133 - auc: 0.9710 - fn: 77.0345 - fp: 50.6207 - loss: 0.0249 - precision: 0.8896 - recall: 0.8449 - tn: 905.2414 - tp: 400.8965 - val_accuracy: 0.8175 - val_auc: 0.8554 - val_fn: 69.0000 - val_fp: 52.0000 - val_loss: 0.1713 - val_precision: 0.7451 - val_recall: 0.6878 - val_tn: 390.0000 - val_tp: 152.0000 - learning_rate: 1.1089e-04\n",
            "Epoch 862/2000\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 158ms/step - accuracy: 0.9118 - auc: 0.9695 - fn: 77.0000 - fp: 45.7241 - loss: 0.0242 - precision: 0.8932 - recall: 0.8351 - tn: 910.1379 - tp: 400.9310 - val_accuracy: 0.8220 - val_auc: 0.8511 - val_fn: 66.0000 - val_fp: 52.0000 - val_loss: 0.1754 - val_precision: 0.7488 - val_recall: 0.7014 - val_tn: 390.0000 - val_tp: 155.0000 - learning_rate: 1.1089e-04\n",
            "Epoch 863/2000\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 179ms/step - accuracy: 0.9187 - auc: 0.9748 - fn: 75.6897 - fp: 44.1724 - loss: 0.0232 - precision: 0.9055 - recall: 0.8441 - tn: 911.6896 - tp: 402.2414 - val_accuracy: 0.8115 - val_auc: 0.8551 - val_fn: 68.0000 - val_fp: 57.0000 - val_loss: 0.1735 - val_precision: 0.7286 - val_recall: 0.6923 - val_tn: 385.0000 - val_tp: 153.0000 - learning_rate: 1.1089e-04\n",
            "Epoch 864/2000\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 175ms/step - accuracy: 0.8890 - auc: 0.9630 - fn: 92.1034 - fp: 63.6897 - loss: 0.0283 - precision: 0.8532 - recall: 0.8059 - tn: 892.1724 - tp: 385.8276 - val_accuracy: 0.8220 - val_auc: 0.8571 - val_fn: 67.0000 - val_fp: 51.0000 - val_loss: 0.1670 - val_precision: 0.7512 - val_recall: 0.6968 - val_tn: 391.0000 - val_tp: 154.0000 - learning_rate: 1.1089e-04\n",
            "Epoch 865/2000\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 174ms/step - accuracy: 0.9284 - auc: 0.9779 - fn: 70.4138 - fp: 38.2759 - loss: 0.0229 - precision: 0.9186 - recall: 0.8615 - tn: 917.5862 - tp: 407.5172 - val_accuracy: 0.8220 - val_auc: 0.8535 - val_fn: 67.0000 - val_fp: 51.0000 - val_loss: 0.1653 - val_precision: 0.7512 - val_recall: 0.6968 - val_tn: 391.0000 - val_tp: 154.0000 - learning_rate: 1.1089e-04\n",
            "Epoch 866/2000\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 164ms/step - accuracy: 0.9172 - auc: 0.9777 - fn: 69.5862 - fp: 48.1724 - loss: 0.0225 - precision: 0.8933 - recall: 0.8536 - tn: 907.6896 - tp: 408.3448 - val_accuracy: 0.8205 - val_auc: 0.8546 - val_fn: 64.0000 - val_fp: 55.0000 - val_loss: 0.1720 - val_precision: 0.7406 - val_recall: 0.7104 - val_tn: 387.0000 - val_tp: 157.0000 - learning_rate: 1.1089e-04\n",
            "Epoch 867/2000\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 160ms/step - accuracy: 0.9296 - auc: 0.9808 - fn: 67.4828 - fp: 40.3103 - loss: 0.0199 - precision: 0.9158 - recall: 0.8687 - tn: 915.5517 - tp: 410.4483 - val_accuracy: 0.8175 - val_auc: 0.8490 - val_fn: 68.0000 - val_fp: 53.0000 - val_loss: 0.1749 - val_precision: 0.7427 - val_recall: 0.6923 - val_tn: 389.0000 - val_tp: 153.0000 - learning_rate: 1.1089e-04\n",
            "Epoch 868/2000\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 174ms/step - accuracy: 0.9246 - auc: 0.9779 - fn: 69.0690 - fp: 44.4828 - loss: 0.0208 - precision: 0.9067 - recall: 0.8625 - tn: 911.3793 - tp: 408.8621 - val_accuracy: 0.8115 - val_auc: 0.8467 - val_fn: 71.0000 - val_fp: 54.0000 - val_loss: 0.1757 - val_precision: 0.7353 - val_recall: 0.6787 - val_tn: 388.0000 - val_tp: 150.0000 - learning_rate: 1.1089e-04\n",
            "Epoch 869/2000\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 163ms/step - accuracy: 0.9110 - auc: 0.9734 - fn: 80.3103 - fp: 48.8621 - loss: 0.0245 - precision: 0.8911 - recall: 0.8353 - tn: 907.0000 - tp: 397.6207 - val_accuracy: 0.8115 - val_auc: 0.8495 - val_fn: 69.0000 - val_fp: 56.0000 - val_loss: 0.1733 - val_precision: 0.7308 - val_recall: 0.6878 - val_tn: 386.0000 - val_tp: 152.0000 - learning_rate: 1.1089e-04\n",
            "Epoch 870/2000\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 162ms/step - accuracy: 0.9344 - auc: 0.9792 - fn: 56.8621 - fp: 39.0690 - loss: 0.0203 - precision: 0.9142 - recall: 0.8862 - tn: 916.7931 - tp: 421.0690 - val_accuracy: 0.8160 - val_auc: 0.8472 - val_fn: 69.0000 - val_fp: 53.0000 - val_loss: 0.1774 - val_precision: 0.7415 - val_recall: 0.6878 - val_tn: 389.0000 - val_tp: 152.0000 - learning_rate: 1.1089e-04\n",
            "Epoch 871/2000\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 173ms/step - accuracy: 0.9112 - auc: 0.9721 - fn: 79.6207 - fp: 45.0000 - loss: 0.0243 - precision: 0.8964 - recall: 0.8296 - tn: 910.8621 - tp: 398.3103 - val_accuracy: 0.8145 - val_auc: 0.8472 - val_fn: 69.0000 - val_fp: 54.0000 - val_loss: 0.1713 - val_precision: 0.7379 - val_recall: 0.6878 - val_tn: 388.0000 - val_tp: 152.0000 - learning_rate: 1.1089e-04\n",
            "Epoch 872/2000\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 162ms/step - accuracy: 0.9182 - auc: 0.9771 - fn: 75.3793 - fp: 43.2414 - loss: 0.0220 - precision: 0.9074 - recall: 0.8405 - tn: 912.6207 - tp: 402.5517 - val_accuracy: 0.8175 - val_auc: 0.8489 - val_fn: 66.0000 - val_fp: 55.0000 - val_loss: 0.1769 - val_precision: 0.7381 - val_recall: 0.7014 - val_tn: 387.0000 - val_tp: 155.0000 - learning_rate: 1.1089e-04\n",
            "Epoch 873/2000\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 177ms/step - accuracy: 0.9101 - auc: 0.9748 - fn: 74.7586 - fp: 50.8966 - loss: 0.0229 - precision: 0.8841 - recall: 0.8405 - tn: 904.9655 - tp: 403.1724 - val_accuracy: 0.8130 - val_auc: 0.8514 - val_fn: 66.0000 - val_fp: 58.0000 - val_loss: 0.1767 - val_precision: 0.7277 - val_recall: 0.7014 - val_tn: 384.0000 - val_tp: 155.0000 - learning_rate: 1.1089e-04\n",
            "Epoch 874/2000\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 159ms/step - accuracy: 0.9214 - auc: 0.9743 - fn: 70.0690 - fp: 40.9310 - loss: 0.0235 - precision: 0.9069 - recall: 0.8516 - tn: 914.9310 - tp: 407.8621 - val_accuracy: 0.8100 - val_auc: 0.8466 - val_fn: 70.0000 - val_fp: 56.0000 - val_loss: 0.1746 - val_precision: 0.7295 - val_recall: 0.6833 - val_tn: 386.0000 - val_tp: 151.0000 - learning_rate: 1.1089e-04\n",
            "Epoch 875/2000\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 161ms/step - accuracy: 0.9109 - auc: 0.9720 - fn: 73.0345 - fp: 50.0345 - loss: 0.0250 - precision: 0.8841 - recall: 0.8431 - tn: 905.8276 - tp: 404.8965 - val_accuracy: 0.8130 - val_auc: 0.8475 - val_fn: 70.0000 - val_fp: 54.0000 - val_loss: 0.1691 - val_precision: 0.7366 - val_recall: 0.6833 - val_tn: 388.0000 - val_tp: 151.0000 - learning_rate: 1.1089e-04\n",
            "Epoch 876/2000\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 177ms/step - accuracy: 0.9109 - auc: 0.9741 - fn: 75.8966 - fp: 47.8276 - loss: 0.0229 - precision: 0.8901 - recall: 0.8358 - tn: 908.0345 - tp: 402.0345 - val_accuracy: 0.8175 - val_auc: 0.8498 - val_fn: 67.0000 - val_fp: 54.0000 - val_loss: 0.1748 - val_precision: 0.7404 - val_recall: 0.6968 - val_tn: 388.0000 - val_tp: 154.0000 - learning_rate: 1.1089e-04\n",
            "Epoch 877/2000\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 174ms/step - accuracy: 0.9216 - auc: 0.9755 - fn: 69.7931 - fp: 44.6897 - loss: 0.0226 - precision: 0.9021 - recall: 0.8579 - tn: 911.1724 - tp: 408.1379 - val_accuracy: 0.8084 - val_auc: 0.8478 - val_fn: 70.0000 - val_fp: 57.0000 - val_loss: 0.1797 - val_precision: 0.7260 - val_recall: 0.6833 - val_tn: 385.0000 - val_tp: 151.0000 - learning_rate: 1.1089e-04\n",
            "Epoch 878/2000\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 177ms/step - accuracy: 0.9218 - auc: 0.9805 - fn: 69.7586 - fp: 49.1379 - loss: 0.0196 - precision: 0.8987 - recall: 0.8624 - tn: 906.7241 - tp: 408.1724 - val_accuracy: 0.8175 - val_auc: 0.8490 - val_fn: 69.0000 - val_fp: 52.0000 - val_loss: 0.1782 - val_precision: 0.7451 - val_recall: 0.6878 - val_tn: 390.0000 - val_tp: 152.0000 - learning_rate: 1.1089e-04\n",
            "Epoch 879/2000\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 161ms/step - accuracy: 0.9031 - auc: 0.9694 - fn: 82.1034 - fp: 55.7586 - loss: 0.0277 - precision: 0.8788 - recall: 0.8232 - tn: 900.1035 - tp: 395.8276 - val_accuracy: 0.8160 - val_auc: 0.8478 - val_fn: 70.0000 - val_fp: 52.0000 - val_loss: 0.1795 - val_precision: 0.7438 - val_recall: 0.6833 - val_tn: 390.0000 - val_tp: 151.0000 - learning_rate: 1.1089e-04\n",
            "Epoch 880/2000\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 174ms/step - accuracy: 0.9202 - auc: 0.9763 - fn: 71.3103 - fp: 45.6207 - loss: 0.0234 - precision: 0.9040 - recall: 0.8512 - tn: 910.2414 - tp: 406.6207 - val_accuracy: 0.8145 - val_auc: 0.8491 - val_fn: 69.0000 - val_fp: 54.0000 - val_loss: 0.1786 - val_precision: 0.7379 - val_recall: 0.6878 - val_tn: 388.0000 - val_tp: 152.0000 - learning_rate: 1.1089e-04\n",
            "Epoch 881/2000\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 161ms/step - accuracy: 0.9119 - auc: 0.9743 - fn: 76.5862 - fp: 48.3103 - loss: 0.0247 - precision: 0.8894 - recall: 0.8403 - tn: 907.5517 - tp: 401.3448 - val_accuracy: 0.8069 - val_auc: 0.8476 - val_fn: 72.0000 - val_fp: 56.0000 - val_loss: 0.1742 - val_precision: 0.7268 - val_recall: 0.6742 - val_tn: 386.0000 - val_tp: 149.0000 - learning_rate: 1.1089e-04\n",
            "Epoch 882/2000\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 163ms/step - accuracy: 0.9291 - auc: 0.9789 - fn: 64.3448 - fp: 42.4138 - loss: 0.0212 - precision: 0.9091 - recall: 0.8747 - tn: 913.4483 - tp: 413.5862 - val_accuracy: 0.8190 - val_auc: 0.8513 - val_fn: 67.0000 - val_fp: 53.0000 - val_loss: 0.1781 - val_precision: 0.7440 - val_recall: 0.6968 - val_tn: 389.0000 - val_tp: 154.0000 - learning_rate: 1.1089e-04\n",
            "Epoch 883/2000\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 173ms/step - accuracy: 0.8971 - auc: 0.9687 - fn: 81.7931 - fp: 57.1034 - loss: 0.0290 - precision: 0.8646 - recall: 0.8198 - tn: 898.7586 - tp: 396.1379 - val_accuracy: 0.8160 - val_auc: 0.8513 - val_fn: 68.0000 - val_fp: 54.0000 - val_loss: 0.1758 - val_precision: 0.7391 - val_recall: 0.6923 - val_tn: 388.0000 - val_tp: 153.0000 - learning_rate: 1.1089e-04\n",
            "Epoch 884/2000\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 174ms/step - accuracy: 0.9219 - auc: 0.9769 - fn: 66.6207 - fp: 42.0000 - loss: 0.0222 - precision: 0.9047 - recall: 0.8557 - tn: 913.8621 - tp: 411.3103 - val_accuracy: 0.8115 - val_auc: 0.8488 - val_fn: 72.0000 - val_fp: 53.0000 - val_loss: 0.1734 - val_precision: 0.7376 - val_recall: 0.6742 - val_tn: 389.0000 - val_tp: 149.0000 - learning_rate: 1.1089e-04\n",
            "Epoch 885/2000\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 179ms/step - accuracy: 0.9345 - auc: 0.9817 - fn: 61.9310 - fp: 38.9655 - loss: 0.0205 - precision: 0.9214 - recall: 0.8784 - tn: 916.8965 - tp: 416.0000 - val_accuracy: 0.8235 - val_auc: 0.8505 - val_fn: 66.0000 - val_fp: 51.0000 - val_loss: 0.1735 - val_precision: 0.7524 - val_recall: 0.7014 - val_tn: 391.0000 - val_tp: 155.0000 - learning_rate: 1.1089e-04\n",
            "Epoch 886/2000\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 159ms/step - accuracy: 0.9231 - auc: 0.9769 - fn: 67.6552 - fp: 42.0690 - loss: 0.0211 - precision: 0.9058 - recall: 0.8584 - tn: 913.7931 - tp: 410.2758 - val_accuracy: 0.8205 - val_auc: 0.8506 - val_fn: 68.0000 - val_fp: 51.0000 - val_loss: 0.1797 - val_precision: 0.7500 - val_recall: 0.6923 - val_tn: 391.0000 - val_tp: 153.0000 - learning_rate: 1.1089e-04\n",
            "Epoch 887/2000\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 174ms/step - accuracy: 0.9183 - auc: 0.9785 - fn: 70.8276 - fp: 45.4828 - loss: 0.0210 - precision: 0.8981 - recall: 0.8516 - tn: 910.3793 - tp: 407.1035 - val_accuracy: 0.8220 - val_auc: 0.8487 - val_fn: 66.0000 - val_fp: 52.0000 - val_loss: 0.1760 - val_precision: 0.7488 - val_recall: 0.7014 - val_tn: 390.0000 - val_tp: 155.0000 - learning_rate: 1.1089e-04\n",
            "Epoch 888/2000\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 164ms/step - accuracy: 0.9294 - auc: 0.9776 - fn: 63.5517 - fp: 40.8621 - loss: 0.0216 - precision: 0.9132 - recall: 0.8707 - tn: 915.0000 - tp: 414.3793 - val_accuracy: 0.8205 - val_auc: 0.8492 - val_fn: 63.0000 - val_fp: 56.0000 - val_loss: 0.1787 - val_precision: 0.7383 - val_recall: 0.7149 - val_tn: 386.0000 - val_tp: 158.0000 - learning_rate: 1.1089e-04\n",
            "Epoch 889/2000\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 157ms/step - accuracy: 0.9286 - auc: 0.9819 - fn: 62.8966 - fp: 45.1724 - loss: 0.0193 - precision: 0.9067 - recall: 0.8758 - tn: 910.6896 - tp: 415.0345 - val_accuracy: 0.8130 - val_auc: 0.8508 - val_fn: 67.0000 - val_fp: 57.0000 - val_loss: 0.1784 - val_precision: 0.7299 - val_recall: 0.6968 - val_tn: 385.0000 - val_tp: 154.0000 - learning_rate: 1.1089e-04\n",
            "Epoch 890/2000\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 175ms/step - accuracy: 0.9188 - auc: 0.9741 - fn: 67.9310 - fp: 49.1034 - loss: 0.0239 - precision: 0.8923 - recall: 0.8604 - tn: 906.7586 - tp: 410.0000 - val_accuracy: 0.8190 - val_auc: 0.8509 - val_fn: 68.0000 - val_fp: 52.0000 - val_loss: 0.1761 - val_precision: 0.7463 - val_recall: 0.6923 - val_tn: 390.0000 - val_tp: 153.0000 - learning_rate: 1.1089e-04\n",
            "Epoch 891/2000\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 181ms/step - accuracy: 0.9159 - auc: 0.9739 - fn: 72.7241 - fp: 46.2759 - loss: 0.0244 - precision: 0.8942 - recall: 0.8482 - tn: 909.5862 - tp: 405.2069 - val_accuracy: 0.8160 - val_auc: 0.8526 - val_fn: 68.0000 - val_fp: 54.0000 - val_loss: 0.1733 - val_precision: 0.7391 - val_recall: 0.6923 - val_tn: 388.0000 - val_tp: 153.0000 - learning_rate: 1.1089e-04\n",
            "Epoch 892/2000\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 159ms/step - accuracy: 0.9305 - auc: 0.9817 - fn: 65.5172 - fp: 38.8276 - loss: 0.0192 - precision: 0.9179 - recall: 0.8692 - tn: 917.0345 - tp: 412.4138 - val_accuracy: 0.8130 - val_auc: 0.8490 - val_fn: 69.0000 - val_fp: 55.0000 - val_loss: 0.1775 - val_precision: 0.7343 - val_recall: 0.6878 - val_tn: 387.0000 - val_tp: 152.0000 - learning_rate: 1.1089e-04\n",
            "Epoch 893/2000\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 159ms/step - accuracy: 0.9334 - auc: 0.9848 - fn: 61.0345 - fp: 40.4828 - loss: 0.0176 - precision: 0.9153 - recall: 0.8818 - tn: 915.3793 - tp: 416.8965 - val_accuracy: 0.8190 - val_auc: 0.8515 - val_fn: 68.0000 - val_fp: 52.0000 - val_loss: 0.1759 - val_precision: 0.7463 - val_recall: 0.6923 - val_tn: 390.0000 - val_tp: 153.0000 - learning_rate: 1.1089e-04\n",
            "Epoch 894/2000\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 165ms/step - accuracy: 0.9266 - auc: 0.9765 - fn: 70.8276 - fp: 44.8276 - loss: 0.0236 - precision: 0.9101 - recall: 0.8650 - tn: 911.0345 - tp: 407.1035 - val_accuracy: 0.8160 - val_auc: 0.8512 - val_fn: 68.0000 - val_fp: 54.0000 - val_loss: 0.1758 - val_precision: 0.7391 - val_recall: 0.6923 - val_tn: 388.0000 - val_tp: 153.0000 - learning_rate: 1.1089e-04\n",
            "Epoch 895/2000\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 161ms/step - accuracy: 0.9122 - auc: 0.9727 - fn: 77.9310 - fp: 50.8276 - loss: 0.0242 - precision: 0.8911 - recall: 0.8390 - tn: 905.0345 - tp: 400.0000 - val_accuracy: 0.8069 - val_auc: 0.8493 - val_fn: 73.0000 - val_fp: 55.0000 - val_loss: 0.1706 - val_precision: 0.7291 - val_recall: 0.6697 - val_tn: 387.0000 - val_tp: 148.0000 - learning_rate: 1.1089e-04\n",
            "Epoch 896/2000\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 174ms/step - accuracy: 0.9155 - auc: 0.9736 - fn: 77.0345 - fp: 45.4138 - loss: 0.0247 - precision: 0.9010 - recall: 0.8387 - tn: 910.4483 - tp: 400.8965 - val_accuracy: 0.8205 - val_auc: 0.8515 - val_fn: 65.0000 - val_fp: 54.0000 - val_loss: 0.1702 - val_precision: 0.7429 - val_recall: 0.7059 - val_tn: 388.0000 - val_tp: 156.0000 - learning_rate: 1.1089e-04\n",
            "Epoch 897/2000\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 177ms/step - accuracy: 0.9141 - auc: 0.9762 - fn: 73.3103 - fp: 44.4828 - loss: 0.0213 - precision: 0.8946 - recall: 0.8412 - tn: 911.3793 - tp: 404.6207 - val_accuracy: 0.8175 - val_auc: 0.8495 - val_fn: 67.0000 - val_fp: 54.0000 - val_loss: 0.1747 - val_precision: 0.7404 - val_recall: 0.6968 - val_tn: 388.0000 - val_tp: 154.0000 - learning_rate: 1.1089e-04\n",
            "Epoch 898/2000\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 175ms/step - accuracy: 0.9197 - auc: 0.9779 - fn: 70.1379 - fp: 44.7931 - loss: 0.0217 - precision: 0.9021 - recall: 0.8517 - tn: 911.0690 - tp: 407.7931 - val_accuracy: 0.8145 - val_auc: 0.8495 - val_fn: 66.0000 - val_fp: 57.0000 - val_loss: 0.1767 - val_precision: 0.7311 - val_recall: 0.7014 - val_tn: 385.0000 - val_tp: 155.0000 - learning_rate: 1.1089e-04\n",
            "Epoch 899/2000\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 156ms/step - accuracy: 0.9271 - auc: 0.9790 - fn: 70.0000 - fp: 44.8966 - loss: 0.0204 - precision: 0.9119 - recall: 0.8647 - tn: 910.9655 - tp: 407.9310 - val_accuracy: 0.8190 - val_auc: 0.8511 - val_fn: 65.0000 - val_fp: 55.0000 - val_loss: 0.1770 - val_precision: 0.7393 - val_recall: 0.7059 - val_tn: 387.0000 - val_tp: 156.0000 - learning_rate: 1.1089e-04\n",
            "Epoch 900/2000\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 161ms/step - accuracy: 0.9056 - auc: 0.9702 - fn: 74.5172 - fp: 49.3103 - loss: 0.0242 - precision: 0.8804 - recall: 0.8291 - tn: 906.5517 - tp: 403.4138 - val_accuracy: 0.8130 - val_auc: 0.8488 - val_fn: 69.0000 - val_fp: 55.0000 - val_loss: 0.1762 - val_precision: 0.7343 - val_recall: 0.6878 - val_tn: 387.0000 - val_tp: 152.0000 - learning_rate: 1.1089e-04\n",
            "Epoch 901/2000\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 158ms/step - accuracy: 0.9210 - auc: 0.9752 - fn: 66.6207 - fp: 42.6207 - loss: 0.0238 - precision: 0.9009 - recall: 0.8571 - tn: 913.2414 - tp: 411.3103 - val_accuracy: 0.8084 - val_auc: 0.8466 - val_fn: 70.0000 - val_fp: 57.0000 - val_loss: 0.1814 - val_precision: 0.7260 - val_recall: 0.6833 - val_tn: 385.0000 - val_tp: 151.0000 - learning_rate: 1.1089e-04\n",
            "Epoch 902/2000\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 158ms/step - accuracy: 0.9171 - auc: 0.9757 - fn: 69.0000 - fp: 41.7931 - loss: 0.0227 - precision: 0.9016 - recall: 0.8428 - tn: 914.0690 - tp: 408.9310 - val_accuracy: 0.8039 - val_auc: 0.8461 - val_fn: 73.0000 - val_fp: 57.0000 - val_loss: 0.1842 - val_precision: 0.7220 - val_recall: 0.6697 - val_tn: 385.0000 - val_tp: 148.0000 - learning_rate: 1.1089e-04\n",
            "Epoch 903/2000\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 179ms/step - accuracy: 0.9092 - auc: 0.9747 - fn: 77.8621 - fp: 50.7931 - loss: 0.0222 - precision: 0.8852 - recall: 0.8361 - tn: 905.0690 - tp: 400.0690 - val_accuracy: 0.8039 - val_auc: 0.8449 - val_fn: 72.0000 - val_fp: 58.0000 - val_loss: 0.1835 - val_precision: 0.7198 - val_recall: 0.6742 - val_tn: 384.0000 - val_tp: 149.0000 - learning_rate: 1.1089e-04\n",
            "Epoch 904/2000\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 175ms/step - accuracy: 0.9235 - auc: 0.9752 - fn: 70.3103 - fp: 41.0345 - loss: 0.0227 - precision: 0.9130 - recall: 0.8517 - tn: 914.8276 - tp: 407.6207 - val_accuracy: 0.8115 - val_auc: 0.8487 - val_fn: 69.0000 - val_fp: 56.0000 - val_loss: 0.1840 - val_precision: 0.7308 - val_recall: 0.6878 - val_tn: 386.0000 - val_tp: 152.0000 - learning_rate: 1.1089e-04\n",
            "Epoch 905/2000\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 174ms/step - accuracy: 0.9092 - auc: 0.9729 - fn: 77.8276 - fp: 50.9655 - loss: 0.0235 - precision: 0.8828 - recall: 0.8391 - tn: 904.8965 - tp: 400.1035 - val_accuracy: 0.8084 - val_auc: 0.8473 - val_fn: 71.0000 - val_fp: 56.0000 - val_loss: 0.1842 - val_precision: 0.7282 - val_recall: 0.6787 - val_tn: 386.0000 - val_tp: 150.0000 - learning_rate: 1.1089e-04\n",
            "Epoch 906/2000\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 163ms/step - accuracy: 0.9131 - auc: 0.9712 - fn: 69.4483 - fp: 50.0000 - loss: 0.0238 - precision: 0.8852 - recall: 0.8496 - tn: 905.8621 - tp: 408.4828 - val_accuracy: 0.8115 - val_auc: 0.8464 - val_fn: 71.0000 - val_fp: 54.0000 - val_loss: 0.1808 - val_precision: 0.7353 - val_recall: 0.6787 - val_tn: 388.0000 - val_tp: 150.0000 - learning_rate: 1.1089e-04\n",
            "Epoch 907/2000\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 162ms/step - accuracy: 0.9089 - auc: 0.9728 - fn: 79.8966 - fp: 48.5517 - loss: 0.0240 - precision: 0.8893 - recall: 0.8300 - tn: 907.3104 - tp: 398.0345 - val_accuracy: 0.8130 - val_auc: 0.8489 - val_fn: 68.0000 - val_fp: 56.0000 - val_loss: 0.1781 - val_precision: 0.7321 - val_recall: 0.6923 - val_tn: 386.0000 - val_tp: 153.0000 - learning_rate: 1.1089e-04\n",
            "Epoch 908/2000\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 158ms/step - accuracy: 0.9150 - auc: 0.9738 - fn: 76.0000 - fp: 47.3793 - loss: 0.0238 - precision: 0.8971 - recall: 0.8414 - tn: 908.4828 - tp: 401.9310 - val_accuracy: 0.8205 - val_auc: 0.8482 - val_fn: 65.0000 - val_fp: 54.0000 - val_loss: 0.1833 - val_precision: 0.7429 - val_recall: 0.7059 - val_tn: 388.0000 - val_tp: 156.0000 - learning_rate: 1.1089e-04\n",
            "Epoch 909/2000\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 177ms/step - accuracy: 0.9167 - auc: 0.9713 - fn: 66.7241 - fp: 52.2069 - loss: 0.0241 - precision: 0.8868 - recall: 0.8597 - tn: 903.6552 - tp: 411.2069 - val_accuracy: 0.8084 - val_auc: 0.8488 - val_fn: 69.0000 - val_fp: 58.0000 - val_loss: 0.1781 - val_precision: 0.7238 - val_recall: 0.6878 - val_tn: 384.0000 - val_tp: 152.0000 - learning_rate: 1.1089e-04\n",
            "Epoch 910/2000\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 162ms/step - accuracy: 0.9165 - auc: 0.9747 - fn: 72.2069 - fp: 46.9655 - loss: 0.0224 - precision: 0.8964 - recall: 0.8475 - tn: 908.8965 - tp: 405.7242 - val_accuracy: 0.8024 - val_auc: 0.8437 - val_fn: 74.0000 - val_fp: 57.0000 - val_loss: 0.1820 - val_precision: 0.7206 - val_recall: 0.6652 - val_tn: 385.0000 - val_tp: 147.0000 - learning_rate: 1.1089e-04\n",
            "Epoch 911/2000\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 157ms/step - accuracy: 0.9117 - auc: 0.9757 - fn: 73.7241 - fp: 48.5517 - loss: 0.0227 - precision: 0.8855 - recall: 0.8444 - tn: 907.3104 - tp: 404.2069 - val_accuracy: 0.8115 - val_auc: 0.8478 - val_fn: 70.0000 - val_fp: 55.0000 - val_loss: 0.1817 - val_precision: 0.7330 - val_recall: 0.6833 - val_tn: 387.0000 - val_tp: 151.0000 - learning_rate: 1.1089e-04\n",
            "Epoch 912/2000\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 174ms/step - accuracy: 0.9142 - auc: 0.9729 - fn: 72.8621 - fp: 47.8276 - loss: 0.0251 - precision: 0.8939 - recall: 0.8425 - tn: 908.0345 - tp: 405.0690 - val_accuracy: 0.8084 - val_auc: 0.8488 - val_fn: 71.0000 - val_fp: 56.0000 - val_loss: 0.1790 - val_precision: 0.7282 - val_recall: 0.6787 - val_tn: 386.0000 - val_tp: 150.0000 - learning_rate: 1.1089e-04\n",
            "Epoch 913/2000\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 162ms/step - accuracy: 0.9109 - auc: 0.9759 - fn: 73.8621 - fp: 50.9655 - loss: 0.0221 - precision: 0.8851 - recall: 0.8420 - tn: 904.8965 - tp: 404.0690 - val_accuracy: 0.8220 - val_auc: 0.8501 - val_fn: 63.0000 - val_fp: 55.0000 - val_loss: 0.1749 - val_precision: 0.7418 - val_recall: 0.7149 - val_tn: 387.0000 - val_tp: 158.0000 - learning_rate: 1.1089e-04\n",
            "Epoch 914/2000\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 160ms/step - accuracy: 0.9146 - auc: 0.9768 - fn: 74.3448 - fp: 48.6207 - loss: 0.0221 - precision: 0.8922 - recall: 0.8461 - tn: 907.2414 - tp: 403.5862 - val_accuracy: 0.8100 - val_auc: 0.8484 - val_fn: 69.0000 - val_fp: 57.0000 - val_loss: 0.1755 - val_precision: 0.7273 - val_recall: 0.6878 - val_tn: 385.0000 - val_tp: 152.0000 - learning_rate: 1.1089e-04\n",
            "Epoch 915/2000\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 165ms/step - accuracy: 0.9317 - auc: 0.9776 - fn: 63.7931 - fp: 39.5862 - loss: 0.0227 - precision: 0.9187 - recall: 0.8723 - tn: 916.2759 - tp: 414.1379 - val_accuracy: 0.8054 - val_auc: 0.8443 - val_fn: 72.0000 - val_fp: 57.0000 - val_loss: 0.1742 - val_precision: 0.7233 - val_recall: 0.6742 - val_tn: 385.0000 - val_tp: 149.0000 - learning_rate: 1.1089e-04\n",
            "Epoch 916/2000\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 181ms/step - accuracy: 0.9095 - auc: 0.9723 - fn: 79.1379 - fp: 54.6207 - loss: 0.0244 - precision: 0.8822 - recall: 0.8406 - tn: 901.2414 - tp: 398.7931 - val_accuracy: 0.8220 - val_auc: 0.8481 - val_fn: 66.0000 - val_fp: 52.0000 - val_loss: 0.1728 - val_precision: 0.7488 - val_recall: 0.7014 - val_tn: 390.0000 - val_tp: 155.0000 - learning_rate: 1.1089e-04\n",
            "Epoch 917/2000\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 174ms/step - accuracy: 0.9163 - auc: 0.9712 - fn: 76.9310 - fp: 47.5862 - loss: 0.0264 - precision: 0.8975 - recall: 0.8453 - tn: 908.2759 - tp: 401.0000 - val_accuracy: 0.8235 - val_auc: 0.8496 - val_fn: 66.0000 - val_fp: 51.0000 - val_loss: 0.1728 - val_precision: 0.7524 - val_recall: 0.7014 - val_tn: 391.0000 - val_tp: 155.0000 - learning_rate: 1.1089e-04\n",
            "Epoch 918/2000\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 174ms/step - accuracy: 0.9256 - auc: 0.9764 - fn: 65.7586 - fp: 42.6897 - loss: 0.0223 - precision: 0.9082 - recall: 0.8642 - tn: 913.1724 - tp: 412.1724 - val_accuracy: 0.8145 - val_auc: 0.8480 - val_fn: 69.0000 - val_fp: 54.0000 - val_loss: 0.1733 - val_precision: 0.7379 - val_recall: 0.6878 - val_tn: 388.0000 - val_tp: 152.0000 - learning_rate: 1.1089e-04\n",
            "Epoch 919/2000\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 180ms/step - accuracy: 0.9174 - auc: 0.9796 - fn: 75.0345 - fp: 43.8621 - loss: 0.0206 - precision: 0.9030 - recall: 0.8428 - tn: 912.0000 - tp: 402.8965 - val_accuracy: 0.8054 - val_auc: 0.8544 - val_fn: 71.0000 - val_fp: 58.0000 - val_loss: 0.1728 - val_precision: 0.7212 - val_recall: 0.6787 - val_tn: 384.0000 - val_tp: 150.0000 - learning_rate: 1.1089e-04\n",
            "Epoch 920/2000\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 157ms/step - accuracy: 0.9189 - auc: 0.9780 - fn: 71.7586 - fp: 46.6552 - loss: 0.0218 - precision: 0.8987 - recall: 0.8527 - tn: 909.2069 - tp: 406.1724 - val_accuracy: 0.8160 - val_auc: 0.8562 - val_fn: 68.0000 - val_fp: 54.0000 - val_loss: 0.1747 - val_precision: 0.7391 - val_recall: 0.6923 - val_tn: 388.0000 - val_tp: 153.0000 - learning_rate: 1.1089e-04\n",
            "Epoch 921/2000\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 160ms/step - accuracy: 0.9214 - auc: 0.9707 - fn: 73.0345 - fp: 48.1379 - loss: 0.0260 - precision: 0.9011 - recall: 0.8581 - tn: 907.7241 - tp: 404.8965 - val_accuracy: 0.8160 - val_auc: 0.8515 - val_fn: 69.0000 - val_fp: 53.0000 - val_loss: 0.1746 - val_precision: 0.7415 - val_recall: 0.6878 - val_tn: 389.0000 - val_tp: 152.0000 - learning_rate: 1.1089e-04\n",
            "Epoch 922/2000\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 181ms/step - accuracy: 0.9124 - auc: 0.9740 - fn: 78.5862 - fp: 47.6552 - loss: 0.0239 - precision: 0.8949 - recall: 0.8353 - tn: 908.2069 - tp: 399.3448 - val_accuracy: 0.8145 - val_auc: 0.8492 - val_fn: 70.0000 - val_fp: 53.0000 - val_loss: 0.1780 - val_precision: 0.7402 - val_recall: 0.6833 - val_tn: 389.0000 - val_tp: 151.0000 - learning_rate: 1.1089e-04\n",
            "Epoch 923/2000\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 159ms/step - accuracy: 0.9065 - auc: 0.9691 - fn: 75.1724 - fp: 53.5862 - loss: 0.0270 - precision: 0.8767 - recall: 0.8370 - tn: 902.2759 - tp: 402.7586 - val_accuracy: 0.8115 - val_auc: 0.8517 - val_fn: 70.0000 - val_fp: 55.0000 - val_loss: 0.1747 - val_precision: 0.7330 - val_recall: 0.6833 - val_tn: 387.0000 - val_tp: 151.0000 - learning_rate: 1.1089e-04\n",
            "Epoch 924/2000\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 159ms/step - accuracy: 0.9050 - auc: 0.9729 - fn: 81.3793 - fp: 55.1724 - loss: 0.0235 - precision: 0.8814 - recall: 0.8265 - tn: 900.6896 - tp: 396.5517 - val_accuracy: 0.8130 - val_auc: 0.8504 - val_fn: 68.0000 - val_fp: 56.0000 - val_loss: 0.1753 - val_precision: 0.7321 - val_recall: 0.6923 - val_tn: 386.0000 - val_tp: 153.0000 - learning_rate: 1.1089e-04\n",
            "Epoch 925/2000\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 164ms/step - accuracy: 0.9242 - auc: 0.9790 - fn: 70.4138 - fp: 45.0000 - loss: 0.0213 - precision: 0.9062 - recall: 0.8618 - tn: 910.8621 - tp: 407.5172 - val_accuracy: 0.8084 - val_auc: 0.8490 - val_fn: 71.0000 - val_fp: 56.0000 - val_loss: 0.1689 - val_precision: 0.7282 - val_recall: 0.6787 - val_tn: 386.0000 - val_tp: 150.0000 - learning_rate: 1.1089e-04\n",
            "Epoch 926/2000\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 174ms/step - accuracy: 0.9111 - auc: 0.9731 - fn: 72.0000 - fp: 50.4483 - loss: 0.0239 - precision: 0.8837 - recall: 0.8443 - tn: 905.4138 - tp: 405.9310 - val_accuracy: 0.8100 - val_auc: 0.8490 - val_fn: 69.0000 - val_fp: 57.0000 - val_loss: 0.1730 - val_precision: 0.7273 - val_recall: 0.6878 - val_tn: 385.0000 - val_tp: 152.0000 - learning_rate: 1.1089e-04\n",
            "Epoch 927/2000\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 159ms/step - accuracy: 0.9353 - auc: 0.9792 - fn: 56.3793 - fp: 34.1724 - loss: 0.0231 - precision: 0.9243 - recall: 0.8778 - tn: 921.6896 - tp: 421.5517 - val_accuracy: 0.8100 - val_auc: 0.8504 - val_fn: 68.0000 - val_fp: 58.0000 - val_loss: 0.1795 - val_precision: 0.7251 - val_recall: 0.6923 - val_tn: 384.0000 - val_tp: 153.0000 - learning_rate: 1.1089e-04\n",
            "Epoch 928/2000\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 179ms/step - accuracy: 0.9193 - auc: 0.9789 - fn: 62.1034 - fp: 43.6552 - loss: 0.0203 - precision: 0.8960 - recall: 0.8570 - tn: 912.2069 - tp: 415.8276 - val_accuracy: 0.8145 - val_auc: 0.8486 - val_fn: 67.0000 - val_fp: 56.0000 - val_loss: 0.1802 - val_precision: 0.7333 - val_recall: 0.6968 - val_tn: 386.0000 - val_tp: 154.0000 - learning_rate: 1.1089e-04\n",
            "Epoch 929/2000\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 158ms/step - accuracy: 0.9230 - auc: 0.9757 - fn: 70.0000 - fp: 48.3448 - loss: 0.0231 - precision: 0.9020 - recall: 0.8626 - tn: 907.5172 - tp: 407.9310 - val_accuracy: 0.8069 - val_auc: 0.8477 - val_fn: 72.0000 - val_fp: 56.0000 - val_loss: 0.1794 - val_precision: 0.7268 - val_recall: 0.6742 - val_tn: 386.0000 - val_tp: 149.0000 - learning_rate: 1.1089e-04\n",
            "Epoch 930/2000\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 157ms/step - accuracy: 0.9273 - auc: 0.9821 - fn: 65.5517 - fp: 46.2069 - loss: 0.0193 - precision: 0.9066 - recall: 0.8715 - tn: 909.6552 - tp: 412.3793 - val_accuracy: 0.8145 - val_auc: 0.8474 - val_fn: 69.0000 - val_fp: 54.0000 - val_loss: 0.1793 - val_precision: 0.7379 - val_recall: 0.6878 - val_tn: 388.0000 - val_tp: 152.0000 - learning_rate: 1.1089e-04\n",
            "Epoch 931/2000\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 180ms/step - accuracy: 0.9076 - auc: 0.9744 - fn: 79.5862 - fp: 50.6897 - loss: 0.0233 - precision: 0.8853 - recall: 0.8305 - tn: 905.1724 - tp: 398.3448 - val_accuracy: 0.8100 - val_auc: 0.8512 - val_fn: 69.0000 - val_fp: 57.0000 - val_loss: 0.1802 - val_precision: 0.7273 - val_recall: 0.6878 - val_tn: 385.0000 - val_tp: 152.0000 - learning_rate: 1.1089e-04\n",
            "Epoch 932/2000\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 159ms/step - accuracy: 0.9106 - auc: 0.9748 - fn: 73.0000 - fp: 51.7586 - loss: 0.0222 - precision: 0.8815 - recall: 0.8454 - tn: 904.1035 - tp: 404.9310 - val_accuracy: 0.8115 - val_auc: 0.8537 - val_fn: 69.0000 - val_fp: 56.0000 - val_loss: 0.1729 - val_precision: 0.7308 - val_recall: 0.6878 - val_tn: 386.0000 - val_tp: 152.0000 - learning_rate: 1.1089e-04\n",
            "Epoch 933/2000\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 158ms/step - accuracy: 0.9245 - auc: 0.9770 - fn: 72.1034 - fp: 40.5172 - loss: 0.0226 - precision: 0.9145 - recall: 0.8531 - tn: 915.3448 - tp: 405.8276 - val_accuracy: 0.8084 - val_auc: 0.8498 - val_fn: 71.0000 - val_fp: 56.0000 - val_loss: 0.1749 - val_precision: 0.7282 - val_recall: 0.6787 - val_tn: 386.0000 - val_tp: 150.0000 - learning_rate: 1.1089e-04\n",
            "Epoch 934/2000\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 163ms/step - accuracy: 0.9199 - auc: 0.9747 - fn: 69.2069 - fp: 49.0345 - loss: 0.0243 - precision: 0.8939 - recall: 0.8619 - tn: 906.8276 - tp: 408.7242 - val_accuracy: 0.8130 - val_auc: 0.8514 - val_fn: 69.0000 - val_fp: 55.0000 - val_loss: 0.1738 - val_precision: 0.7343 - val_recall: 0.6878 - val_tn: 387.0000 - val_tp: 152.0000 - learning_rate: 1.1089e-04\n",
            "Epoch 935/2000\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 177ms/step - accuracy: 0.9206 - auc: 0.9769 - fn: 68.1379 - fp: 47.8621 - loss: 0.0217 - precision: 0.8969 - recall: 0.8606 - tn: 908.0000 - tp: 409.7931 - val_accuracy: 0.8069 - val_auc: 0.8511 - val_fn: 70.0000 - val_fp: 58.0000 - val_loss: 0.1721 - val_precision: 0.7225 - val_recall: 0.6833 - val_tn: 384.0000 - val_tp: 151.0000 - learning_rate: 1.1089e-04\n",
            "Epoch 936/2000\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 158ms/step - accuracy: 0.9131 - auc: 0.9756 - fn: 71.5862 - fp: 41.6897 - loss: 0.0234 - precision: 0.8954 - recall: 0.8369 - tn: 914.1724 - tp: 406.3448 - val_accuracy: 0.8130 - val_auc: 0.8502 - val_fn: 67.0000 - val_fp: 57.0000 - val_loss: 0.1745 - val_precision: 0.7299 - val_recall: 0.6968 - val_tn: 385.0000 - val_tp: 154.0000 - learning_rate: 1.1089e-04\n",
            "Epoch 937/2000\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 180ms/step - accuracy: 0.9160 - auc: 0.9751 - fn: 71.4138 - fp: 47.2069 - loss: 0.0249 - precision: 0.8952 - recall: 0.8469 - tn: 908.6552 - tp: 406.5172 - val_accuracy: 0.8160 - val_auc: 0.8499 - val_fn: 66.0000 - val_fp: 56.0000 - val_loss: 0.1723 - val_precision: 0.7346 - val_recall: 0.7014 - val_tn: 386.0000 - val_tp: 155.0000 - learning_rate: 1.1089e-04\n",
            "Epoch 938/2000\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 179ms/step - accuracy: 0.9251 - auc: 0.9818 - fn: 69.4828 - fp: 41.8276 - loss: 0.0200 - precision: 0.9107 - recall: 0.8596 - tn: 914.0345 - tp: 408.4483 - val_accuracy: 0.8235 - val_auc: 0.8516 - val_fn: 61.0000 - val_fp: 56.0000 - val_loss: 0.1762 - val_precision: 0.7407 - val_recall: 0.7240 - val_tn: 386.0000 - val_tp: 160.0000 - learning_rate: 1.1089e-04\n",
            "Epoch 939/2000\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 175ms/step - accuracy: 0.9196 - auc: 0.9778 - fn: 70.8276 - fp: 46.7241 - loss: 0.0220 - precision: 0.8984 - recall: 0.8555 - tn: 909.1379 - tp: 407.1035 - val_accuracy: 0.8220 - val_auc: 0.8502 - val_fn: 62.0000 - val_fp: 56.0000 - val_loss: 0.1792 - val_precision: 0.7395 - val_recall: 0.7195 - val_tn: 386.0000 - val_tp: 159.0000 - learning_rate: 1.1089e-04\n",
            "Epoch 940/2000\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 161ms/step - accuracy: 0.9213 - auc: 0.9780 - fn: 68.4138 - fp: 44.8276 - loss: 0.0205 - precision: 0.9029 - recall: 0.8559 - tn: 911.0345 - tp: 409.5172 - val_accuracy: 0.8100 - val_auc: 0.8492 - val_fn: 68.0000 - val_fp: 58.0000 - val_loss: 0.1836 - val_precision: 0.7251 - val_recall: 0.6923 - val_tn: 384.0000 - val_tp: 153.0000 - learning_rate: 1.1089e-04\n",
            "Epoch 941/2000\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 165ms/step - accuracy: 0.9219 - auc: 0.9789 - fn: 72.1379 - fp: 43.4828 - loss: 0.0202 - precision: 0.9058 - recall: 0.8545 - tn: 912.3793 - tp: 405.7931 - val_accuracy: 0.8130 - val_auc: 0.8495 - val_fn: 66.0000 - val_fp: 58.0000 - val_loss: 0.1847 - val_precision: 0.7277 - val_recall: 0.7014 - val_tn: 384.0000 - val_tp: 155.0000 - learning_rate: 1.1089e-04\n",
            "Epoch 942/2000\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 160ms/step - accuracy: 0.9164 - auc: 0.9764 - fn: 71.7586 - fp: 46.9655 - loss: 0.0222 - precision: 0.8931 - recall: 0.8513 - tn: 908.8965 - tp: 406.1724 - val_accuracy: 0.8160 - val_auc: 0.8500 - val_fn: 66.0000 - val_fp: 56.0000 - val_loss: 0.1835 - val_precision: 0.7346 - val_recall: 0.7014 - val_tn: 386.0000 - val_tp: 155.0000 - learning_rate: 1.1089e-04\n",
            "Epoch 943/2000\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 176ms/step - accuracy: 0.9086 - auc: 0.9699 - fn: 72.9655 - fp: 52.8966 - loss: 0.0240 - precision: 0.8780 - recall: 0.8428 - tn: 902.9655 - tp: 404.9655 - val_accuracy: 0.8115 - val_auc: 0.8482 - val_fn: 67.0000 - val_fp: 58.0000 - val_loss: 0.1858 - val_precision: 0.7264 - val_recall: 0.6968 - val_tn: 384.0000 - val_tp: 154.0000 - learning_rate: 1.1089e-04\n",
            "Epoch 944/2000\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 182ms/step - accuracy: 0.9270 - auc: 0.9765 - fn: 64.1034 - fp: 43.8621 - loss: 0.0219 - precision: 0.9078 - recall: 0.8692 - tn: 912.0000 - tp: 413.8276 - val_accuracy: 0.8115 - val_auc: 0.8472 - val_fn: 68.0000 - val_fp: 57.0000 - val_loss: 0.1848 - val_precision: 0.7286 - val_recall: 0.6923 - val_tn: 385.0000 - val_tp: 153.0000 - learning_rate: 1.1089e-04\n",
            "Epoch 945/2000\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 178ms/step - accuracy: 0.9032 - auc: 0.9728 - fn: 74.9310 - fp: 52.7586 - loss: 0.0240 - precision: 0.8727 - recall: 0.8306 - tn: 903.1035 - tp: 403.0000 - val_accuracy: 0.8024 - val_auc: 0.8507 - val_fn: 71.0000 - val_fp: 60.0000 - val_loss: 0.1795 - val_precision: 0.7143 - val_recall: 0.6787 - val_tn: 382.0000 - val_tp: 150.0000 - learning_rate: 1.1089e-04\n",
            "Epoch 946/2000\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 158ms/step - accuracy: 0.9177 - auc: 0.9712 - fn: 71.8276 - fp: 46.5172 - loss: 0.0267 - precision: 0.8946 - recall: 0.8538 - tn: 909.3448 - tp: 406.1035 - val_accuracy: 0.8190 - val_auc: 0.8486 - val_fn: 68.0000 - val_fp: 52.0000 - val_loss: 0.1794 - val_precision: 0.7463 - val_recall: 0.6923 - val_tn: 390.0000 - val_tp: 153.0000 - learning_rate: 1.1089e-04\n",
            "Epoch 947/2000\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 176ms/step - accuracy: 0.9187 - auc: 0.9803 - fn: 69.3448 - fp: 44.0345 - loss: 0.0204 - precision: 0.8994 - recall: 0.8515 - tn: 911.8276 - tp: 408.5862 - val_accuracy: 0.8100 - val_auc: 0.8476 - val_fn: 71.0000 - val_fp: 55.0000 - val_loss: 0.1828 - val_precision: 0.7317 - val_recall: 0.6787 - val_tn: 387.0000 - val_tp: 150.0000 - learning_rate: 1.1089e-04\n",
            "Epoch 948/2000\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 179ms/step - accuracy: 0.9171 - auc: 0.9718 - fn: 70.7931 - fp: 45.4483 - loss: 0.0251 - precision: 0.8958 - recall: 0.8501 - tn: 910.4138 - tp: 407.1379 - val_accuracy: 0.8100 - val_auc: 0.8481 - val_fn: 69.0000 - val_fp: 57.0000 - val_loss: 0.1785 - val_precision: 0.7273 - val_recall: 0.6878 - val_tn: 385.0000 - val_tp: 152.0000 - learning_rate: 1.1089e-04\n",
            "Epoch 949/2000\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 158ms/step - accuracy: 0.9310 - auc: 0.9793 - fn: 56.8966 - fp: 37.9310 - loss: 0.0205 - precision: 0.9125 - recall: 0.8770 - tn: 917.9310 - tp: 421.0345 - val_accuracy: 0.8145 - val_auc: 0.8498 - val_fn: 68.0000 - val_fp: 55.0000 - val_loss: 0.1827 - val_precision: 0.7356 - val_recall: 0.6923 - val_tn: 387.0000 - val_tp: 153.0000 - learning_rate: 1.1089e-04\n",
            "Epoch 950/2000\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 158ms/step - accuracy: 0.9046 - auc: 0.9709 - fn: 75.3448 - fp: 51.5862 - loss: 0.0244 - precision: 0.8735 - recall: 0.8349 - tn: 904.2759 - tp: 402.5862 - val_accuracy: 0.8115 - val_auc: 0.8492 - val_fn: 69.0000 - val_fp: 56.0000 - val_loss: 0.1865 - val_precision: 0.7308 - val_recall: 0.6878 - val_tn: 386.0000 - val_tp: 152.0000 - learning_rate: 1.1089e-04\n",
            "Epoch 951/2000\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 165ms/step - accuracy: 0.9141 - auc: 0.9735 - fn: 74.2069 - fp: 48.0000 - loss: 0.0238 - precision: 0.8932 - recall: 0.8430 - tn: 907.8621 - tp: 403.7242 - val_accuracy: 0.8235 - val_auc: 0.8511 - val_fn: 65.0000 - val_fp: 52.0000 - val_loss: 0.1871 - val_precision: 0.7500 - val_recall: 0.7059 - val_tn: 390.0000 - val_tp: 156.0000 - learning_rate: 1.1089e-04\n",
            "Epoch 952/2000\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 176ms/step - accuracy: 0.9231 - auc: 0.9815 - fn: 67.5517 - fp: 44.3448 - loss: 0.0190 - precision: 0.9039 - recall: 0.8607 - tn: 911.5172 - tp: 410.3793 - val_accuracy: 0.8130 - val_auc: 0.8494 - val_fn: 69.0000 - val_fp: 55.0000 - val_loss: 0.1840 - val_precision: 0.7343 - val_recall: 0.6878 - val_tn: 387.0000 - val_tp: 152.0000 - learning_rate: 1.1089e-04\n",
            "Epoch 953/2000\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 175ms/step - accuracy: 0.9038 - auc: 0.9709 - fn: 81.7241 - fp: 54.8621 - loss: 0.0241 - precision: 0.8750 - recall: 0.8299 - tn: 901.0000 - tp: 396.2069 - val_accuracy: 0.8084 - val_auc: 0.8518 - val_fn: 70.0000 - val_fp: 57.0000 - val_loss: 0.1774 - val_precision: 0.7260 - val_recall: 0.6833 - val_tn: 385.0000 - val_tp: 151.0000 - learning_rate: 1.1089e-04\n",
            "Epoch 954/2000\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 178ms/step - accuracy: 0.9214 - auc: 0.9730 - fn: 69.6552 - fp: 41.6207 - loss: 0.0247 - precision: 0.9049 - recall: 0.8541 - tn: 914.2414 - tp: 408.2758 - val_accuracy: 0.8130 - val_auc: 0.8514 - val_fn: 68.0000 - val_fp: 56.0000 - val_loss: 0.1774 - val_precision: 0.7321 - val_recall: 0.6923 - val_tn: 386.0000 - val_tp: 153.0000 - learning_rate: 1.1089e-04\n",
            "Epoch 955/2000\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 162ms/step - accuracy: 0.9253 - auc: 0.9774 - fn: 66.0690 - fp: 41.2414 - loss: 0.0219 - precision: 0.9139 - recall: 0.8568 - tn: 914.6207 - tp: 411.8621 - val_accuracy: 0.8160 - val_auc: 0.8487 - val_fn: 66.0000 - val_fp: 56.0000 - val_loss: 0.1828 - val_precision: 0.7346 - val_recall: 0.7014 - val_tn: 386.0000 - val_tp: 155.0000 - learning_rate: 1.1089e-04\n",
            "Epoch 956/2000\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 158ms/step - accuracy: 0.9203 - auc: 0.9712 - fn: 70.2759 - fp: 42.6897 - loss: 0.0273 - precision: 0.9027 - recall: 0.8528 - tn: 913.1724 - tp: 407.6552 - val_accuracy: 0.8100 - val_auc: 0.8469 - val_fn: 70.0000 - val_fp: 56.0000 - val_loss: 0.1808 - val_precision: 0.7295 - val_recall: 0.6833 - val_tn: 386.0000 - val_tp: 151.0000 - learning_rate: 1.1089e-04\n",
            "Epoch 957/2000\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 176ms/step - accuracy: 0.9210 - auc: 0.9776 - fn: 71.5172 - fp: 42.3448 - loss: 0.0226 - precision: 0.9063 - recall: 0.8508 - tn: 913.5172 - tp: 406.4138 - val_accuracy: 0.8024 - val_auc: 0.8481 - val_fn: 72.0000 - val_fp: 59.0000 - val_loss: 0.1792 - val_precision: 0.7163 - val_recall: 0.6742 - val_tn: 383.0000 - val_tp: 149.0000 - learning_rate: 1.1089e-04\n",
            "Epoch 958/2000\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 165ms/step - accuracy: 0.9178 - auc: 0.9738 - fn: 72.6207 - fp: 44.8966 - loss: 0.0229 - precision: 0.9011 - recall: 0.8462 - tn: 910.9655 - tp: 405.3103 - val_accuracy: 0.8175 - val_auc: 0.8476 - val_fn: 67.0000 - val_fp: 54.0000 - val_loss: 0.1786 - val_precision: 0.7404 - val_recall: 0.6968 - val_tn: 388.0000 - val_tp: 154.0000 - learning_rate: 1.1089e-04\n",
            "Epoch 959/2000\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 176ms/step - accuracy: 0.9263 - auc: 0.9789 - fn: 66.9655 - fp: 38.6207 - loss: 0.0212 - precision: 0.9158 - recall: 0.8578 - tn: 917.2414 - tp: 410.9655 - val_accuracy: 0.8145 - val_auc: 0.8532 - val_fn: 66.0000 - val_fp: 57.0000 - val_loss: 0.1736 - val_precision: 0.7311 - val_recall: 0.7014 - val_tn: 385.0000 - val_tp: 155.0000 - learning_rate: 1.1089e-04\n",
            "Epoch 960/2000\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 175ms/step - accuracy: 0.9316 - auc: 0.9800 - fn: 60.1724 - fp: 41.1724 - loss: 0.0202 - precision: 0.9148 - recall: 0.8765 - tn: 914.6896 - tp: 417.7586 - val_accuracy: 0.8039 - val_auc: 0.8505 - val_fn: 69.0000 - val_fp: 61.0000 - val_loss: 0.1791 - val_precision: 0.7136 - val_recall: 0.6878 - val_tn: 381.0000 - val_tp: 152.0000 - learning_rate: 1.1089e-04\n",
            "Epoch 961/2000\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 179ms/step - accuracy: 0.9256 - auc: 0.9792 - fn: 65.7241 - fp: 43.0345 - loss: 0.0205 - precision: 0.9067 - recall: 0.8659 - tn: 912.8276 - tp: 412.2069 - val_accuracy: 0.8130 - val_auc: 0.8542 - val_fn: 67.0000 - val_fp: 57.0000 - val_loss: 0.1750 - val_precision: 0.7299 - val_recall: 0.6968 - val_tn: 385.0000 - val_tp: 154.0000 - learning_rate: 1.1089e-04\n",
            "Epoch 962/2000\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 175ms/step - accuracy: 0.9185 - auc: 0.9789 - fn: 66.7931 - fp: 48.1034 - loss: 0.0203 - precision: 0.8914 - recall: 0.8605 - tn: 907.7586 - tp: 411.1379 - val_accuracy: 0.8145 - val_auc: 0.8513 - val_fn: 66.0000 - val_fp: 57.0000 - val_loss: 0.1768 - val_precision: 0.7311 - val_recall: 0.7014 - val_tn: 385.0000 - val_tp: 155.0000 - learning_rate: 1.1089e-04\n",
            "Epoch 963/2000\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 161ms/step - accuracy: 0.9020 - auc: 0.9701 - fn: 80.1724 - fp: 54.1379 - loss: 0.0252 - precision: 0.8744 - recall: 0.8243 - tn: 901.7241 - tp: 397.7586 - val_accuracy: 0.8084 - val_auc: 0.8476 - val_fn: 69.0000 - val_fp: 58.0000 - val_loss: 0.1814 - val_precision: 0.7238 - val_recall: 0.6878 - val_tn: 384.0000 - val_tp: 152.0000 - learning_rate: 1.1089e-04\n",
            "Epoch 964/2000\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 166ms/step - accuracy: 0.9058 - auc: 0.9710 - fn: 77.6207 - fp: 47.6207 - loss: 0.0243 - precision: 0.8842 - recall: 0.8253 - tn: 908.2414 - tp: 400.3103 - val_accuracy: 0.8205 - val_auc: 0.8511 - val_fn: 65.0000 - val_fp: 54.0000 - val_loss: 0.1766 - val_precision: 0.7429 - val_recall: 0.7059 - val_tn: 388.0000 - val_tp: 156.0000 - learning_rate: 1.1089e-04\n",
            "Epoch 965/2000\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 174ms/step - accuracy: 0.9219 - auc: 0.9778 - fn: 65.0690 - fp: 44.2759 - loss: 0.0220 - precision: 0.8991 - recall: 0.8625 - tn: 911.5862 - tp: 412.8621 - val_accuracy: 0.8205 - val_auc: 0.8510 - val_fn: 64.0000 - val_fp: 55.0000 - val_loss: 0.1773 - val_precision: 0.7406 - val_recall: 0.7104 - val_tn: 387.0000 - val_tp: 157.0000 - learning_rate: 1.1089e-04\n",
            "Epoch 966/2000\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 174ms/step - accuracy: 0.9188 - auc: 0.9755 - fn: 70.6897 - fp: 46.2069 - loss: 0.0233 - precision: 0.8978 - recall: 0.8536 - tn: 909.6552 - tp: 407.2414 - val_accuracy: 0.8084 - val_auc: 0.8452 - val_fn: 72.0000 - val_fp: 55.0000 - val_loss: 0.1769 - val_precision: 0.7304 - val_recall: 0.6742 - val_tn: 387.0000 - val_tp: 149.0000 - learning_rate: 1.1089e-04\n",
            "Epoch 967/2000\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 165ms/step - accuracy: 0.8945 - auc: 0.9670 - fn: 83.7586 - fp: 59.1034 - loss: 0.0265 - precision: 0.8606 - recall: 0.8158 - tn: 896.7586 - tp: 394.1724 - val_accuracy: 0.8084 - val_auc: 0.8467 - val_fn: 71.0000 - val_fp: 56.0000 - val_loss: 0.1811 - val_precision: 0.7282 - val_recall: 0.6787 - val_tn: 386.0000 - val_tp: 150.0000 - learning_rate: 1.1089e-04\n",
            "Epoch 968/2000\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 175ms/step - accuracy: 0.9288 - auc: 0.9780 - fn: 63.3103 - fp: 38.8966 - loss: 0.0229 - precision: 0.9149 - recall: 0.8671 - tn: 916.9655 - tp: 414.6207 - val_accuracy: 0.8130 - val_auc: 0.8478 - val_fn: 71.0000 - val_fp: 53.0000 - val_loss: 0.1828 - val_precision: 0.7389 - val_recall: 0.6787 - val_tn: 389.0000 - val_tp: 150.0000 - learning_rate: 1.1089e-04\n",
            "Epoch 969/2000\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 174ms/step - accuracy: 0.9195 - auc: 0.9782 - fn: 69.4138 - fp: 43.9655 - loss: 0.0211 - precision: 0.8994 - recall: 0.8541 - tn: 911.8965 - tp: 408.5172 - val_accuracy: 0.8145 - val_auc: 0.8512 - val_fn: 66.0000 - val_fp: 57.0000 - val_loss: 0.1780 - val_precision: 0.7311 - val_recall: 0.7014 - val_tn: 385.0000 - val_tp: 155.0000 - learning_rate: 1.1089e-04\n",
            "Epoch 970/2000\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 178ms/step - accuracy: 0.9120 - auc: 0.9704 - fn: 72.6207 - fp: 53.4828 - loss: 0.0262 - precision: 0.8834 - recall: 0.8481 - tn: 902.3793 - tp: 405.3103 - val_accuracy: 0.8160 - val_auc: 0.8506 - val_fn: 66.0000 - val_fp: 56.0000 - val_loss: 0.1802 - val_precision: 0.7346 - val_recall: 0.7014 - val_tn: 386.0000 - val_tp: 155.0000 - learning_rate: 1.1089e-04\n",
            "Epoch 971/2000\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 164ms/step - accuracy: 0.9308 - auc: 0.9800 - fn: 63.2069 - fp: 37.5862 - loss: 0.0210 - precision: 0.9186 - recall: 0.8696 - tn: 918.2759 - tp: 414.7242 - val_accuracy: 0.8205 - val_auc: 0.8518 - val_fn: 65.0000 - val_fp: 54.0000 - val_loss: 0.1770 - val_precision: 0.7429 - val_recall: 0.7059 - val_tn: 388.0000 - val_tp: 156.0000 - learning_rate: 1.1089e-04\n",
            "Epoch 972/2000\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 160ms/step - accuracy: 0.9077 - auc: 0.9749 - fn: 79.7241 - fp: 48.6207 - loss: 0.0220 - precision: 0.8886 - recall: 0.8265 - tn: 907.2414 - tp: 398.2069 - val_accuracy: 0.8190 - val_auc: 0.8508 - val_fn: 65.0000 - val_fp: 55.0000 - val_loss: 0.1802 - val_precision: 0.7393 - val_recall: 0.7059 - val_tn: 387.0000 - val_tp: 156.0000 - learning_rate: 1.1089e-04\n",
            "Epoch 973/2000\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 159ms/step - accuracy: 0.9186 - auc: 0.9710 - fn: 70.6552 - fp: 47.3793 - loss: 0.0262 - precision: 0.8963 - recall: 0.8547 - tn: 908.4828 - tp: 407.2758 - val_accuracy: 0.8145 - val_auc: 0.8477 - val_fn: 67.0000 - val_fp: 56.0000 - val_loss: 0.1803 - val_precision: 0.7333 - val_recall: 0.6968 - val_tn: 386.0000 - val_tp: 154.0000 - learning_rate: 1.1089e-04\n",
            "Epoch 974/2000\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 178ms/step - accuracy: 0.9277 - auc: 0.9795 - fn: 63.5517 - fp: 39.9310 - loss: 0.0225 - precision: 0.9108 - recall: 0.8679 - tn: 915.9310 - tp: 414.3793 - val_accuracy: 0.8145 - val_auc: 0.8483 - val_fn: 70.0000 - val_fp: 53.0000 - val_loss: 0.1815 - val_precision: 0.7402 - val_recall: 0.6833 - val_tn: 389.0000 - val_tp: 151.0000 - learning_rate: 1.1089e-04\n",
            "Epoch 975/2000\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 182ms/step - accuracy: 0.9081 - auc: 0.9711 - fn: 78.1034 - fp: 54.3448 - loss: 0.0245 - precision: 0.8804 - recall: 0.8379 - tn: 901.5172 - tp: 399.8276 - val_accuracy: 0.8069 - val_auc: 0.8479 - val_fn: 72.0000 - val_fp: 56.0000 - val_loss: 0.1832 - val_precision: 0.7268 - val_recall: 0.6742 - val_tn: 386.0000 - val_tp: 149.0000 - learning_rate: 1.1089e-04\n",
            "Epoch 976/2000\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 175ms/step - accuracy: 0.9185 - auc: 0.9777 - fn: 72.0690 - fp: 42.5517 - loss: 0.0223 - precision: 0.9028 - recall: 0.8469 - tn: 913.3104 - tp: 405.8621 - val_accuracy: 0.8160 - val_auc: 0.8476 - val_fn: 67.0000 - val_fp: 55.0000 - val_loss: 0.1841 - val_precision: 0.7368 - val_recall: 0.6968 - val_tn: 387.0000 - val_tp: 154.0000 - learning_rate: 3.6926e-05\n",
            "Epoch 977/2000\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 181ms/step - accuracy: 0.9134 - auc: 0.9745 - fn: 71.6207 - fp: 50.4138 - loss: 0.0228 - precision: 0.8873 - recall: 0.8480 - tn: 905.4483 - tp: 406.3103 - val_accuracy: 0.8145 - val_auc: 0.8492 - val_fn: 66.0000 - val_fp: 57.0000 - val_loss: 0.1846 - val_precision: 0.7311 - val_recall: 0.7014 - val_tn: 385.0000 - val_tp: 155.0000 - learning_rate: 3.6926e-05\n",
            "Epoch 978/2000\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 166ms/step - accuracy: 0.9218 - auc: 0.9787 - fn: 70.0345 - fp: 42.4828 - loss: 0.0208 - precision: 0.9063 - recall: 0.8536 - tn: 913.3793 - tp: 407.8965 - val_accuracy: 0.8160 - val_auc: 0.8490 - val_fn: 64.0000 - val_fp: 58.0000 - val_loss: 0.1818 - val_precision: 0.7302 - val_recall: 0.7104 - val_tn: 384.0000 - val_tp: 157.0000 - learning_rate: 3.6926e-05\n",
            "Epoch 979/2000\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 1s/step - accuracy: 0.9205 - auc: 0.9775 - fn: 66.6897 - fp: 45.2069 - loss: 0.0213 - precision: 0.8982 - recall: 0.8588 - tn: 910.6552 - tp: 411.2414 - val_accuracy: 0.8145 - val_auc: 0.8474 - val_fn: 67.0000 - val_fp: 56.0000 - val_loss: 0.1810 - val_precision: 0.7333 - val_recall: 0.6968 - val_tn: 386.0000 - val_tp: 154.0000 - learning_rate: 3.6926e-05\n",
            "Epoch 980/2000\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 385ms/step - accuracy: 0.9344 - auc: 0.9842 - fn: 62.1724 - fp: 39.0690 - loss: 0.0178 - precision: 0.9197 - recall: 0.8801 - tn: 916.7931 - tp: 415.7586 - val_accuracy: 0.8190 - val_auc: 0.8488 - val_fn: 65.0000 - val_fp: 55.0000 - val_loss: 0.1828 - val_precision: 0.7393 - val_recall: 0.7059 - val_tn: 387.0000 - val_tp: 156.0000 - learning_rate: 3.6926e-05\n",
            "Epoch 981/2000\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 317ms/step - accuracy: 0.9426 - auc: 0.9851 - fn: 54.1034 - fp: 34.5517 - loss: 0.0173 - precision: 0.9298 - recall: 0.8952 - tn: 921.3104 - tp: 423.8276 - val_accuracy: 0.8175 - val_auc: 0.8501 - val_fn: 65.0000 - val_fp: 56.0000 - val_loss: 0.1826 - val_precision: 0.7358 - val_recall: 0.7059 - val_tn: 386.0000 - val_tp: 156.0000 - learning_rate: 3.6926e-05\n",
            "Epoch 982/2000\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 535ms/step - accuracy: 0.9322 - auc: 0.9843 - fn: 57.8966 - fp: 37.5862 - loss: 0.0182 - precision: 0.9141 - recall: 0.8794 - tn: 918.2759 - tp: 420.0345 - val_accuracy: 0.8190 - val_auc: 0.8509 - val_fn: 64.0000 - val_fp: 56.0000 - val_loss: 0.1831 - val_precision: 0.7371 - val_recall: 0.7104 - val_tn: 386.0000 - val_tp: 157.0000 - learning_rate: 3.6926e-05\n",
            "Epoch 983/2000\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 191ms/step - accuracy: 0.9143 - auc: 0.9772 - fn: 71.6552 - fp: 48.5172 - loss: 0.0217 - precision: 0.8902 - recall: 0.8476 - tn: 907.3448 - tp: 406.2758 - val_accuracy: 0.8160 - val_auc: 0.8512 - val_fn: 65.0000 - val_fp: 57.0000 - val_loss: 0.1822 - val_precision: 0.7324 - val_recall: 0.7059 - val_tn: 385.0000 - val_tp: 156.0000 - learning_rate: 3.6926e-05\n",
            "Epoch 984/2000\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 177ms/step - accuracy: 0.9175 - auc: 0.9774 - fn: 73.3103 - fp: 44.4483 - loss: 0.0206 - precision: 0.8990 - recall: 0.8477 - tn: 911.4138 - tp: 404.6207 - val_accuracy: 0.8160 - val_auc: 0.8506 - val_fn: 65.0000 - val_fp: 57.0000 - val_loss: 0.1843 - val_precision: 0.7324 - val_recall: 0.7059 - val_tn: 385.0000 - val_tp: 156.0000 - learning_rate: 3.6926e-05\n",
            "Epoch 985/2000\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 163ms/step - accuracy: 0.9249 - auc: 0.9786 - fn: 69.9655 - fp: 41.9310 - loss: 0.0222 - precision: 0.9113 - recall: 0.8582 - tn: 913.9310 - tp: 407.9655 - val_accuracy: 0.8220 - val_auc: 0.8510 - val_fn: 63.0000 - val_fp: 55.0000 - val_loss: 0.1827 - val_precision: 0.7418 - val_recall: 0.7149 - val_tn: 387.0000 - val_tp: 158.0000 - learning_rate: 3.6926e-05\n",
            "Epoch 986/2000\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 185ms/step - accuracy: 0.9262 - auc: 0.9793 - fn: 64.2414 - fp: 44.9655 - loss: 0.0208 - precision: 0.9063 - recall: 0.8682 - tn: 910.8965 - tp: 413.6897 - val_accuracy: 0.8220 - val_auc: 0.8501 - val_fn: 64.0000 - val_fp: 54.0000 - val_loss: 0.1826 - val_precision: 0.7441 - val_recall: 0.7104 - val_tn: 388.0000 - val_tp: 157.0000 - learning_rate: 3.6926e-05\n",
            "Epoch 987/2000\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 181ms/step - accuracy: 0.9223 - auc: 0.9793 - fn: 66.8276 - fp: 46.2069 - loss: 0.0211 - precision: 0.9008 - recall: 0.8619 - tn: 909.6552 - tp: 411.1035 - val_accuracy: 0.8220 - val_auc: 0.8499 - val_fn: 65.0000 - val_fp: 53.0000 - val_loss: 0.1841 - val_precision: 0.7464 - val_recall: 0.7059 - val_tn: 389.0000 - val_tp: 156.0000 - learning_rate: 3.6926e-05\n",
            "Epoch 988/2000\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 175ms/step - accuracy: 0.9259 - auc: 0.9767 - fn: 64.3793 - fp: 42.7241 - loss: 0.0222 - precision: 0.9085 - recall: 0.8649 - tn: 913.1379 - tp: 413.5517 - val_accuracy: 0.8190 - val_auc: 0.8483 - val_fn: 66.0000 - val_fp: 54.0000 - val_loss: 0.1826 - val_precision: 0.7416 - val_recall: 0.7014 - val_tn: 388.0000 - val_tp: 155.0000 - learning_rate: 3.6926e-05\n",
            "Epoch 989/2000\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 176ms/step - accuracy: 0.9311 - auc: 0.9827 - fn: 66.4138 - fp: 42.6207 - loss: 0.0190 - precision: 0.9158 - recall: 0.8735 - tn: 913.2414 - tp: 411.5172 - val_accuracy: 0.8145 - val_auc: 0.8493 - val_fn: 69.0000 - val_fp: 54.0000 - val_loss: 0.1813 - val_precision: 0.7379 - val_recall: 0.6878 - val_tn: 388.0000 - val_tp: 152.0000 - learning_rate: 3.6926e-05\n",
            "Epoch 990/2000\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 164ms/step - accuracy: 0.9168 - auc: 0.9777 - fn: 70.6552 - fp: 49.7241 - loss: 0.0211 - precision: 0.8907 - recall: 0.8555 - tn: 906.1379 - tp: 407.2758 - val_accuracy: 0.8145 - val_auc: 0.8495 - val_fn: 67.0000 - val_fp: 56.0000 - val_loss: 0.1824 - val_precision: 0.7333 - val_recall: 0.6968 - val_tn: 386.0000 - val_tp: 154.0000 - learning_rate: 3.6926e-05\n",
            "Epoch 991/2000\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 156ms/step - accuracy: 0.9243 - auc: 0.9780 - fn: 65.5862 - fp: 42.4138 - loss: 0.0212 - precision: 0.9040 - recall: 0.8649 - tn: 913.4483 - tp: 412.3448 - val_accuracy: 0.8190 - val_auc: 0.8500 - val_fn: 66.0000 - val_fp: 54.0000 - val_loss: 0.1829 - val_precision: 0.7416 - val_recall: 0.7014 - val_tn: 388.0000 - val_tp: 155.0000 - learning_rate: 3.6926e-05\n",
            "Epoch 992/2000\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 156ms/step - accuracy: 0.9266 - auc: 0.9800 - fn: 62.8276 - fp: 37.7586 - loss: 0.0214 - precision: 0.9112 - recall: 0.8639 - tn: 918.1035 - tp: 415.1035 - val_accuracy: 0.8160 - val_auc: 0.8524 - val_fn: 67.0000 - val_fp: 55.0000 - val_loss: 0.1826 - val_precision: 0.7368 - val_recall: 0.6968 - val_tn: 387.0000 - val_tp: 154.0000 - learning_rate: 3.6926e-05\n",
            "Epoch 993/2000\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 177ms/step - accuracy: 0.9319 - auc: 0.9810 - fn: 64.0000 - fp: 39.8276 - loss: 0.0200 - precision: 0.9184 - recall: 0.8733 - tn: 916.0345 - tp: 413.9310 - val_accuracy: 0.8175 - val_auc: 0.8506 - val_fn: 67.0000 - val_fp: 54.0000 - val_loss: 0.1801 - val_precision: 0.7404 - val_recall: 0.6968 - val_tn: 388.0000 - val_tp: 154.0000 - learning_rate: 3.6926e-05\n",
            "Epoch 994/2000\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 161ms/step - accuracy: 0.9216 - auc: 0.9754 - fn: 68.8621 - fp: 40.6207 - loss: 0.0222 - precision: 0.9048 - recall: 0.8549 - tn: 915.2414 - tp: 409.0690 - val_accuracy: 0.8190 - val_auc: 0.8503 - val_fn: 67.0000 - val_fp: 53.0000 - val_loss: 0.1810 - val_precision: 0.7440 - val_recall: 0.6968 - val_tn: 389.0000 - val_tp: 154.0000 - learning_rate: 3.6926e-05\n",
            "Epoch 995/2000\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 158ms/step - accuracy: 0.9331 - auc: 0.9808 - fn: 58.8276 - fp: 42.5172 - loss: 0.0202 - precision: 0.9134 - recall: 0.8830 - tn: 913.3448 - tp: 419.1035 - val_accuracy: 0.8220 - val_auc: 0.8508 - val_fn: 64.0000 - val_fp: 54.0000 - val_loss: 0.1811 - val_precision: 0.7441 - val_recall: 0.7104 - val_tn: 388.0000 - val_tp: 157.0000 - learning_rate: 3.6926e-05\n",
            "Epoch 996/2000\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 173ms/step - accuracy: 0.9198 - auc: 0.9728 - fn: 71.1379 - fp: 49.3793 - loss: 0.0263 - precision: 0.8963 - recall: 0.8586 - tn: 906.4828 - tp: 406.7931 - val_accuracy: 0.8220 - val_auc: 0.8509 - val_fn: 64.0000 - val_fp: 54.0000 - val_loss: 0.1804 - val_precision: 0.7441 - val_recall: 0.7104 - val_tn: 388.0000 - val_tp: 157.0000 - learning_rate: 3.6926e-05\n",
            "Epoch 997/2000\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 180ms/step - accuracy: 0.9196 - auc: 0.9782 - fn: 70.1034 - fp: 47.6552 - loss: 0.0211 - precision: 0.8976 - recall: 0.8567 - tn: 908.2069 - tp: 407.8276 - val_accuracy: 0.8190 - val_auc: 0.8509 - val_fn: 65.0000 - val_fp: 55.0000 - val_loss: 0.1811 - val_precision: 0.7393 - val_recall: 0.7059 - val_tn: 387.0000 - val_tp: 156.0000 - learning_rate: 3.6926e-05\n",
            "Epoch 998/2000\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 158ms/step - accuracy: 0.9272 - auc: 0.9844 - fn: 61.5517 - fp: 40.3793 - loss: 0.0179 - precision: 0.9091 - recall: 0.8685 - tn: 915.4828 - tp: 416.3793 - val_accuracy: 0.8205 - val_auc: 0.8514 - val_fn: 64.0000 - val_fp: 55.0000 - val_loss: 0.1823 - val_precision: 0.7406 - val_recall: 0.7104 - val_tn: 387.0000 - val_tp: 157.0000 - learning_rate: 3.6926e-05\n",
            "Epoch 999/2000\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 158ms/step - accuracy: 0.9134 - auc: 0.9747 - fn: 62.9655 - fp: 47.6552 - loss: 0.0230 - precision: 0.8821 - recall: 0.8543 - tn: 908.2069 - tp: 414.9655 - val_accuracy: 0.8235 - val_auc: 0.8504 - val_fn: 64.0000 - val_fp: 53.0000 - val_loss: 0.1824 - val_precision: 0.7476 - val_recall: 0.7104 - val_tn: 389.0000 - val_tp: 157.0000 - learning_rate: 3.6926e-05\n",
            "Epoch 1000/2000\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 181ms/step - accuracy: 0.9253 - auc: 0.9798 - fn: 66.3448 - fp: 42.0690 - loss: 0.0199 - precision: 0.9097 - recall: 0.8613 - tn: 913.7931 - tp: 411.5862 - val_accuracy: 0.8235 - val_auc: 0.8512 - val_fn: 64.0000 - val_fp: 53.0000 - val_loss: 0.1827 - val_precision: 0.7476 - val_recall: 0.7104 - val_tn: 389.0000 - val_tp: 157.0000 - learning_rate: 3.6926e-05\n",
            "Epoch 1001/2000\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 178ms/step - accuracy: 0.9301 - auc: 0.9786 - fn: 62.4483 - fp: 40.8966 - loss: 0.0206 - precision: 0.9151 - recall: 0.8712 - tn: 914.9655 - tp: 415.4828 - val_accuracy: 0.8235 - val_auc: 0.8513 - val_fn: 64.0000 - val_fp: 53.0000 - val_loss: 0.1823 - val_precision: 0.7476 - val_recall: 0.7104 - val_tn: 389.0000 - val_tp: 157.0000 - learning_rate: 3.6926e-05\n",
            "Epoch 1002/2000\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 158ms/step - accuracy: 0.9281 - auc: 0.9819 - fn: 66.0000 - fp: 41.3103 - loss: 0.0213 - precision: 0.9162 - recall: 0.8636 - tn: 914.5517 - tp: 411.9310 - val_accuracy: 0.8220 - val_auc: 0.8513 - val_fn: 65.0000 - val_fp: 53.0000 - val_loss: 0.1811 - val_precision: 0.7464 - val_recall: 0.7059 - val_tn: 389.0000 - val_tp: 156.0000 - learning_rate: 3.6926e-05\n",
            "Epoch 1003/2000\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 180ms/step - accuracy: 0.9168 - auc: 0.9742 - fn: 72.4483 - fp: 46.3448 - loss: 0.0234 - precision: 0.8966 - recall: 0.8482 - tn: 909.5172 - tp: 405.4828 - val_accuracy: 0.8220 - val_auc: 0.8512 - val_fn: 65.0000 - val_fp: 53.0000 - val_loss: 0.1806 - val_precision: 0.7464 - val_recall: 0.7059 - val_tn: 389.0000 - val_tp: 156.0000 - learning_rate: 3.6926e-05\n",
            "Epoch 1004/2000\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 179ms/step - accuracy: 0.9268 - auc: 0.9790 - fn: 65.7241 - fp: 42.1379 - loss: 0.0211 - precision: 0.9087 - recall: 0.8674 - tn: 913.7241 - tp: 412.2069 - val_accuracy: 0.8250 - val_auc: 0.8508 - val_fn: 63.0000 - val_fp: 53.0000 - val_loss: 0.1815 - val_precision: 0.7488 - val_recall: 0.7149 - val_tn: 389.0000 - val_tp: 158.0000 - learning_rate: 3.6926e-05\n",
            "Epoch 1005/2000\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 174ms/step - accuracy: 0.9214 - auc: 0.9777 - fn: 68.5517 - fp: 44.0345 - loss: 0.0225 - precision: 0.9037 - recall: 0.8553 - tn: 911.8276 - tp: 409.3793 - val_accuracy: 0.8220 - val_auc: 0.8514 - val_fn: 65.0000 - val_fp: 53.0000 - val_loss: 0.1809 - val_precision: 0.7464 - val_recall: 0.7059 - val_tn: 389.0000 - val_tp: 156.0000 - learning_rate: 3.6926e-05\n",
            "Epoch 1006/2000\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 159ms/step - accuracy: 0.9116 - auc: 0.9794 - fn: 71.9310 - fp: 43.9655 - loss: 0.0202 - precision: 0.8917 - recall: 0.8359 - tn: 911.8965 - tp: 406.0000 - val_accuracy: 0.8175 - val_auc: 0.8504 - val_fn: 66.0000 - val_fp: 55.0000 - val_loss: 0.1831 - val_precision: 0.7381 - val_recall: 0.7014 - val_tn: 387.0000 - val_tp: 155.0000 - learning_rate: 3.6926e-05\n",
            "Epoch 1007/2000\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 180ms/step - accuracy: 0.9347 - auc: 0.9780 - fn: 58.3793 - fp: 37.4483 - loss: 0.0225 - precision: 0.9201 - recall: 0.8805 - tn: 918.4138 - tp: 419.5517 - val_accuracy: 0.8100 - val_auc: 0.8487 - val_fn: 69.0000 - val_fp: 57.0000 - val_loss: 0.1811 - val_precision: 0.7273 - val_recall: 0.6878 - val_tn: 385.0000 - val_tp: 152.0000 - learning_rate: 3.6926e-05\n",
            "Epoch 1008/2000\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 159ms/step - accuracy: 0.9012 - auc: 0.9708 - fn: 80.9655 - fp: 50.9310 - loss: 0.0246 - precision: 0.8780 - recall: 0.8168 - tn: 904.9310 - tp: 396.9655 - val_accuracy: 0.8220 - val_auc: 0.8513 - val_fn: 65.0000 - val_fp: 53.0000 - val_loss: 0.1777 - val_precision: 0.7464 - val_recall: 0.7059 - val_tn: 389.0000 - val_tp: 156.0000 - learning_rate: 3.6926e-05\n",
            "Epoch 1009/2000\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 157ms/step - accuracy: 0.9353 - auc: 0.9808 - fn: 61.6552 - fp: 38.4138 - loss: 0.0198 - precision: 0.9219 - recall: 0.8802 - tn: 917.4483 - tp: 416.2758 - val_accuracy: 0.8205 - val_auc: 0.8518 - val_fn: 65.0000 - val_fp: 54.0000 - val_loss: 0.1793 - val_precision: 0.7429 - val_recall: 0.7059 - val_tn: 388.0000 - val_tp: 156.0000 - learning_rate: 3.6926e-05\n",
            "Epoch 1010/2000\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 178ms/step - accuracy: 0.9223 - auc: 0.9753 - fn: 67.3793 - fp: 45.7241 - loss: 0.0234 - precision: 0.9010 - recall: 0.8617 - tn: 910.1379 - tp: 410.5517 - val_accuracy: 0.8205 - val_auc: 0.8516 - val_fn: 65.0000 - val_fp: 54.0000 - val_loss: 0.1792 - val_precision: 0.7429 - val_recall: 0.7059 - val_tn: 388.0000 - val_tp: 156.0000 - learning_rate: 3.6926e-05\n",
            "Epoch 1011/2000\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 163ms/step - accuracy: 0.9151 - auc: 0.9742 - fn: 71.5862 - fp: 46.0690 - loss: 0.0236 - precision: 0.8957 - recall: 0.8435 - tn: 909.7931 - tp: 406.3448 - val_accuracy: 0.8190 - val_auc: 0.8501 - val_fn: 67.0000 - val_fp: 53.0000 - val_loss: 0.1802 - val_precision: 0.7440 - val_recall: 0.6968 - val_tn: 389.0000 - val_tp: 154.0000 - learning_rate: 3.6926e-05\n",
            "Epoch 1012/2000\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 174ms/step - accuracy: 0.9315 - auc: 0.9813 - fn: 64.6897 - fp: 41.7931 - loss: 0.0205 - precision: 0.9157 - recall: 0.8748 - tn: 914.0690 - tp: 413.2414 - val_accuracy: 0.8190 - val_auc: 0.8507 - val_fn: 65.0000 - val_fp: 55.0000 - val_loss: 0.1781 - val_precision: 0.7393 - val_recall: 0.7059 - val_tn: 387.0000 - val_tp: 156.0000 - learning_rate: 3.6926e-05\n",
            "Epoch 1013/2000\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 174ms/step - accuracy: 0.9176 - auc: 0.9800 - fn: 72.5517 - fp: 46.6897 - loss: 0.0204 - precision: 0.8995 - recall: 0.8476 - tn: 909.1724 - tp: 405.3793 - val_accuracy: 0.8235 - val_auc: 0.8535 - val_fn: 64.0000 - val_fp: 53.0000 - val_loss: 0.1779 - val_precision: 0.7476 - val_recall: 0.7104 - val_tn: 389.0000 - val_tp: 157.0000 - learning_rate: 3.6926e-05\n",
            "Epoch 1014/2000\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 180ms/step - accuracy: 0.9229 - auc: 0.9783 - fn: 71.0000 - fp: 44.8966 - loss: 0.0213 - precision: 0.9043 - recall: 0.8595 - tn: 910.9655 - tp: 406.9310 - val_accuracy: 0.8220 - val_auc: 0.8519 - val_fn: 64.0000 - val_fp: 54.0000 - val_loss: 0.1774 - val_precision: 0.7441 - val_recall: 0.7104 - val_tn: 388.0000 - val_tp: 157.0000 - learning_rate: 3.6926e-05\n",
            "Epoch 1015/2000\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 412ms/step - accuracy: 0.9276 - auc: 0.9786 - fn: 64.8276 - fp: 38.7931 - loss: 0.0217 - precision: 0.9137 - recall: 0.8646 - tn: 917.0690 - tp: 413.1035 - val_accuracy: 0.8205 - val_auc: 0.8525 - val_fn: 65.0000 - val_fp: 54.0000 - val_loss: 0.1789 - val_precision: 0.7429 - val_recall: 0.7059 - val_tn: 388.0000 - val_tp: 156.0000 - learning_rate: 3.6926e-05\n",
            "Epoch 1016/2000\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 503ms/step - accuracy: 0.9143 - auc: 0.9803 - fn: 71.8276 - fp: 46.1724 - loss: 0.0202 - precision: 0.8929 - recall: 0.8443 - tn: 909.6896 - tp: 406.1035 - val_accuracy: 0.8175 - val_auc: 0.8528 - val_fn: 66.0000 - val_fp: 55.0000 - val_loss: 0.1801 - val_precision: 0.7381 - val_recall: 0.7014 - val_tn: 387.0000 - val_tp: 155.0000 - learning_rate: 3.6926e-05\n",
            "Epoch 1017/2000\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 165ms/step - accuracy: 0.9143 - auc: 0.9740 - fn: 71.8621 - fp: 48.0000 - loss: 0.0235 - precision: 0.8919 - recall: 0.8455 - tn: 907.8621 - tp: 406.0690 - val_accuracy: 0.8235 - val_auc: 0.8514 - val_fn: 64.0000 - val_fp: 53.0000 - val_loss: 0.1810 - val_precision: 0.7476 - val_recall: 0.7104 - val_tn: 389.0000 - val_tp: 157.0000 - learning_rate: 3.6926e-05\n",
            "Epoch 1018/2000\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 181ms/step - accuracy: 0.9231 - auc: 0.9759 - fn: 68.3448 - fp: 42.7241 - loss: 0.0235 - precision: 0.9076 - recall: 0.8566 - tn: 913.1379 - tp: 409.5862 - val_accuracy: 0.8220 - val_auc: 0.8515 - val_fn: 66.0000 - val_fp: 52.0000 - val_loss: 0.1780 - val_precision: 0.7488 - val_recall: 0.7014 - val_tn: 390.0000 - val_tp: 155.0000 - learning_rate: 3.6926e-05\n",
            "Epoch 1019/2000\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 168ms/step - accuracy: 0.9150 - auc: 0.9764 - fn: 71.5172 - fp: 49.5517 - loss: 0.0218 - precision: 0.8903 - recall: 0.8497 - tn: 906.3104 - tp: 406.4138 - val_accuracy: 0.8220 - val_auc: 0.8513 - val_fn: 65.0000 - val_fp: 53.0000 - val_loss: 0.1773 - val_precision: 0.7464 - val_recall: 0.7059 - val_tn: 389.0000 - val_tp: 156.0000 - learning_rate: 3.6926e-05\n",
            "Epoch 1020/2000\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 176ms/step - accuracy: 0.9205 - auc: 0.9792 - fn: 70.3793 - fp: 44.9655 - loss: 0.0213 - precision: 0.9016 - recall: 0.8546 - tn: 910.8965 - tp: 407.5517 - val_accuracy: 0.8220 - val_auc: 0.8502 - val_fn: 65.0000 - val_fp: 53.0000 - val_loss: 0.1788 - val_precision: 0.7464 - val_recall: 0.7059 - val_tn: 389.0000 - val_tp: 156.0000 - learning_rate: 3.6926e-05\n",
            "Epoch 1021/2000\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 310ms/step - accuracy: 0.9427 - auc: 0.9831 - fn: 54.8276 - fp: 33.7931 - loss: 0.0198 - precision: 0.9303 - recall: 0.8949 - tn: 922.0690 - tp: 423.1035 - val_accuracy: 0.8235 - val_auc: 0.8505 - val_fn: 64.0000 - val_fp: 53.0000 - val_loss: 0.1787 - val_precision: 0.7476 - val_recall: 0.7104 - val_tn: 389.0000 - val_tp: 157.0000 - learning_rate: 3.6926e-05\n",
            "Epoch 1022/2000\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 236ms/step - accuracy: 0.9212 - auc: 0.9751 - fn: 66.6552 - fp: 40.4828 - loss: 0.0238 - precision: 0.9029 - recall: 0.8558 - tn: 915.3793 - tp: 411.2758 - val_accuracy: 0.8205 - val_auc: 0.8509 - val_fn: 65.0000 - val_fp: 54.0000 - val_loss: 0.1783 - val_precision: 0.7429 - val_recall: 0.7059 - val_tn: 388.0000 - val_tp: 156.0000 - learning_rate: 3.6926e-05\n",
            "Epoch 1023/2000\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 615ms/step - accuracy: 0.9259 - auc: 0.9788 - fn: 71.2069 - fp: 44.2414 - loss: 0.0214 - precision: 0.9120 - recall: 0.8608 - tn: 911.6207 - tp: 406.7242 - val_accuracy: 0.8220 - val_auc: 0.8520 - val_fn: 64.0000 - val_fp: 54.0000 - val_loss: 0.1791 - val_precision: 0.7441 - val_recall: 0.7104 - val_tn: 388.0000 - val_tp: 157.0000 - learning_rate: 3.6926e-05\n",
            "Epoch 1024/2000\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 651ms/step - accuracy: 0.9168 - auc: 0.9750 - fn: 69.4138 - fp: 47.8276 - loss: 0.0231 - precision: 0.8941 - recall: 0.8511 - tn: 908.0345 - tp: 408.5172 - val_accuracy: 0.8296 - val_auc: 0.8508 - val_fn: 62.0000 - val_fp: 51.0000 - val_loss: 0.1789 - val_precision: 0.7571 - val_recall: 0.7195 - val_tn: 391.0000 - val_tp: 159.0000 - learning_rate: 3.6926e-05\n",
            "Epoch 1025/2000\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 317ms/step - accuracy: 0.9352 - auc: 0.9824 - fn: 60.4138 - fp: 37.3103 - loss: 0.0197 - precision: 0.9210 - recall: 0.8809 - tn: 918.5517 - tp: 417.5172 - val_accuracy: 0.8235 - val_auc: 0.8505 - val_fn: 64.0000 - val_fp: 53.0000 - val_loss: 0.1774 - val_precision: 0.7476 - val_recall: 0.7104 - val_tn: 389.0000 - val_tp: 157.0000 - learning_rate: 3.6926e-05\n",
            "Epoch 1026/2000\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 397ms/step - accuracy: 0.9080 - auc: 0.9766 - fn: 72.6897 - fp: 50.1034 - loss: 0.0218 - precision: 0.8804 - recall: 0.8378 - tn: 905.7586 - tp: 405.2414 - val_accuracy: 0.8220 - val_auc: 0.8518 - val_fn: 64.0000 - val_fp: 54.0000 - val_loss: 0.1773 - val_precision: 0.7441 - val_recall: 0.7104 - val_tn: 388.0000 - val_tp: 157.0000 - learning_rate: 3.6926e-05\n",
            "Epoch 1027/2000\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 403ms/step - accuracy: 0.9283 - auc: 0.9793 - fn: 67.5172 - fp: 35.2414 - loss: 0.0213 - precision: 0.9218 - recall: 0.8575 - tn: 920.6207 - tp: 410.4138 - val_accuracy: 0.8205 - val_auc: 0.8524 - val_fn: 64.0000 - val_fp: 55.0000 - val_loss: 0.1779 - val_precision: 0.7406 - val_recall: 0.7104 - val_tn: 387.0000 - val_tp: 157.0000 - learning_rate: 3.6926e-05\n",
            "Epoch 1028/2000\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 1s/step - accuracy: 0.9150 - auc: 0.9740 - fn: 74.3103 - fp: 48.8966 - loss: 0.0233 - precision: 0.8944 - recall: 0.8448 - tn: 906.9655 - tp: 403.6207 - val_accuracy: 0.8190 - val_auc: 0.8528 - val_fn: 65.0000 - val_fp: 55.0000 - val_loss: 0.1780 - val_precision: 0.7393 - val_recall: 0.7059 - val_tn: 387.0000 - val_tp: 156.0000 - learning_rate: 3.6926e-05\n",
            "Epoch 1029/2000\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 548ms/step - accuracy: 0.9148 - auc: 0.9786 - fn: 74.5862 - fp: 47.9310 - loss: 0.0210 - precision: 0.8956 - recall: 0.8429 - tn: 907.9310 - tp: 403.3448 - val_accuracy: 0.8130 - val_auc: 0.8521 - val_fn: 69.0000 - val_fp: 55.0000 - val_loss: 0.1778 - val_precision: 0.7343 - val_recall: 0.6878 - val_tn: 387.0000 - val_tp: 152.0000 - learning_rate: 3.6926e-05\n",
            "Epoch 1030/2000\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 213ms/step - accuracy: 0.9065 - auc: 0.9729 - fn: 73.5172 - fp: 54.7586 - loss: 0.0229 - precision: 0.8743 - recall: 0.8405 - tn: 901.1035 - tp: 404.4138 - val_accuracy: 0.8145 - val_auc: 0.8521 - val_fn: 67.0000 - val_fp: 56.0000 - val_loss: 0.1783 - val_precision: 0.7333 - val_recall: 0.6968 - val_tn: 386.0000 - val_tp: 154.0000 - learning_rate: 3.6926e-05\n",
            "Epoch 1031/2000\n",
            "\u001b[1m12/28\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m14s\u001b[0m 895ms/step - accuracy: 0.9227 - auc: 0.9762 - fn: 29.5833 - fp: 21.1667 - loss: 0.0218 - precision: 0.8979 - recall: 0.8664 - tn: 394.8333 - tp: 178.4167"
          ]
        }
      ],
      "source": [
        "history = cnn_model.fit(X_train,y_train, epochs=2000, batch_size = 32,\n",
        "                        validation_data=(X_test, y_test), validation_batch_size = 32,\n",
        "                  callbacks=[early_stopping_cb,lr_scheduler1,checkpoint_cb])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "wbSLJg_5A0wo"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}